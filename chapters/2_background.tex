\documentclass[thesis]{subfiles}

\begin{document}

\chapter{Background}
\label{chapter:background}

% This is sort of OK. I think I have to break the narrative in this chapter anyway.
Before a discussion of \pyop3, it is useful to review some of the relevant background material.
We will first provide a mathematical motivation for mesh execution models using a common operation, \textit{finite element assembly}, as an example.
Then we will review\dots
Finally, we describe in more detail the core pieces of software that \pyop3 bases its abstractions upon: \pyop2, numpy and PETSc DMPlex.

\section{The finite element method}

% TODO: Rephrase
For a non-trivial example for when mesh loops (?) are required, we consider solving the Stokes equations using the \gls{fem}.
Our exposition will focus on the aspects of the computation that are relevant for \pyop3, for a more complete review of \gls{fem} we refer the reader to~\cite{brennerMathematicalTheoryFinite2008} and~\cite{larsonFiniteElementMethod2013}.

The Stokes equations are a linearisation of the Navier-Stokes equations and are used to describe fluid flow for laminar (slow and calm) media.
For domain $\Omega$ and boundary $\Gamma$, omitting any viscosity or forcing terms for simplicity, they are given by

\begin{subequations}
  \begin{align}
    - \Delta u + \nabla p &= 0 \quad \textrm{in} \ \Omega, \\
    %
    \nabla \cdot u &= 0 \quad \textrm{in} \ \Omega, \\
    %
    u &= g \quad \textrm{on} \ \Gamma.
  \end{align}
  %
  \label{eq:strong_stokes}
\end{subequations}

with $u$ the fluid velocity and $p$ the pressure.
We also prescribe Dirichlet boundary conditions for the velocity across the entire boundary, setting $u$ to the value of function $g$.
Since we have a coupled system of two variables ($u$ and $p$), we refer to the Stokes system as being a \textit{mixed} problem.

\subsection{Deriving a weak formulation}

For the finite element method we seek the solution to the \textit{variational}, or \textit{weak}, formulation of these equations.
These are obtained by multiplying each equation by a suitable \textit{test function} and integrating over the domain.
For \cref{eq:strong_stokes}, using $v$ and $q$ as the test functions, drawn from function spaces $\hat V$ and $Q$ respectively, and integrating by parts this gives

% taken from 
% https://nbviewer.org/github/firedrakeproject/firedrake/blob/master/docs/notebooks/06-pde-constrained-optimisation.ipynb
% and Larson and Bengzon (pg. 293)
\begin{subequations}
  \begin{align}
    \int \nabla u : \nabla v \, \textrm{d}\Omega
    - \int p \nabla \cdot v \, \textrm{d}\Omega
    - \int (\nabla u \cdot n) \cdot v \, \textrm{d}\Gamma
    - \int p n \cdot v \, \textrm{d}\Gamma
    &= 0
    &\forall \ v \in \hat V
    \label{eq:weak_stokes_extra_V} \\
    %
    \int q \, \nabla \cdot u \, \textrm{d}\Omega
    &= 0
    &\forall \ q \in Q.
    \label{eq:weak_stokes_extra_Q}
  \end{align}
  \label{eq:weak_stokes_extra}
\end{subequations}

From these weak forms it is now possible to classify the function spaces for $u$ and $p$.
For $u$, we already know that the space must be vector-valued, since it stores a velocity, and constrained to $g$ on the boundary.
\Cref{eq:weak_stokes_extra_V} further shows us that $u$ must have at least one weak derivative.
We can therefore say that $u \in V$ where

\begin{equation*}
  V = \{ \ v \in [H^1(\Omega)]^d : v |_{\Gamma} = g \ \}  \\
\end{equation*}

$p$ is scalar-valued, no derivatives of $p$ are present in the weak formulation, nor are any boundary conditions applied to it and so we can write that $p \in Q$ where

\begin{equation*}
  Q = \{ \ q \in L^2(\Omega) \ \}  \\
\end{equation*}

Since the values of $u$ at the boundary are already prescribed, the function space of the test function $v$ is defined to be zero at those nodes

\begin{equation*}
  \hat V = \{\ v \in [H^1(\Omega)]^d : v|_{\Gamma} = 0 \ \}.
\end{equation*}

This allows us to drop some terms from \cref{eq:weak_stokes_extra_V}, allowing us to state the final problem as follows:

\vspace{1em}

%TODO: Not sure how to format this best
Find $(u, p) \in V \times Q$ such that

\begin{subequations}
  \begin{align}
    \int \nabla u : \nabla v \, \textrm{d}\Omega
    - \int p \nabla \cdot v \, \textrm{d}\Omega
    &= 0
    &\forall \ v \in \hat V
    \label{eq:weak_stokes_V} \\
    %
    \int q \, \nabla \cdot u \, \textrm{d}\Omega
    &= 0
    &\forall \ q \in Q.
    \label{eq:weak_stokes_Q}
  \end{align}
  \label{eq:weak_stokes}
\end{subequations}

\subsection{Discretising the system of equations}

In order to solve this weak formulation using the finite element method we discretise the function spaces in use by replacing them with a finite dimensional equivalent:

\begin{equation*}
  V \to V_h \subset V,
  \quad
  \hat V \to \hat V_h \subset \hat V,
  \quad
  Q \to Q_h \subset Q.
\end{equation*}

Each of these discrete spaces is spanned by a set of basis functions so any function can be expressed as a linear combination of the basis functions and their coefficients.
For example, we can write the function $u_h \in V_h$ as

\begin{equation*}
  u_h = \Sigma^N_{i=1} \hat u_i \psi^{V_h}_i
\end{equation*}

for basis functions $\psi^{V_h}_i$ and coefficients $\hat u_i$.

Substituting these discrete function spaces back into \cref{eq:weak_stokes}, and discarding the basis coefficients for the arbitrary functions $v_h$ and $q_h$, we obtain the discrete problem:

\vspace{1em}

%TODO: Not sure how to format this best
Find $(\hat u, \hat p)$ such that

\begin{subequations}
  \begin{align}
    \int \hat u \nabla \psi^{V_h} : \nabla \psi^{\hat V_h} \, \textrm{d}\Omega
    - \int \hat p \psi^Q \nabla \cdot \psi^{\hat V_h} \, \textrm{d}\Omega
    &= 0
    &\forall \ \psi^{\hat V} \\
    %
    \int \psi^Q \, \nabla \cdot \hat u \psi^{V_h} \, \textrm{d}\Omega
    &= 0
    &\forall \ \psi^{Q}
  \end{align}
  \label{eq:weak_stokes_discrete}
\end{subequations}

This can be reformulated as the (saddle point) linear system

\begin{equation}
  \left (
  \begin{array}{c|c}
    \int \nabla \psi^{V_h} : \nabla \psi^{\hat V_h} \, \textrm{d}\Omega
    &
    - \int \psi^Q \nabla \cdot \psi^{\hat V_h} \, \textrm{d}\Omega \\
    \hline
    \int \psi^Q \, \nabla \cdot \psi^{V_h} \, \textrm{d}\Omega
    &
    0
  \end{array}
  \right )
  \left (
  \begin{array}{c}
    \hat u \\
    \hline
    \hat p
  \end{array}
  \right )
  =
  \left (
  \begin{array}{c}
    0 \\ \hline 0
  \end{array}
  \right )
  %
  \label{eq:stokes_linear_system}
\end{equation}

Solving the Stokes equations using the finite element method therefore boils down to constructing, or \textit{assembling}, the left-hand-side matrix and the, here trivial, right-hand-side vector before solving for the coefficients $\hat u$ and $\hat p$.

\subsection{Choosing a finite element pair}

\begin{figure}
  \begin{subfigure}{.3\textwidth}
    % include my own diagram, not from defelement - then my colouring is consisten
    % but use defelement numbering as we don't really care and it is consistent with the basis function sketches
    % \includegraphics[width=\textwidth]{element_Lagrange_2_dofs.pdf}
    \caption{P2, TODO}
  \end{subfigure}
  \begin{subfigure}{.68\textwidth}
    \begin{tabular}{c c c}
      \includegraphics[width=.3\textwidth]{element_Lagrange_2_dof0.pdf}
      &
      \includegraphics[width=.3\textwidth]{element_Lagrange_2_dof1.pdf}
      &
      \includegraphics[width=.3\textwidth]{element_Lagrange_2_dof2.pdf}
      \\
      \includegraphics[width=.3\textwidth]{element_Lagrange_2_dof3.pdf}
      &
      \includegraphics[width=.3\textwidth]{element_Lagrange_2_dof4.pdf}
      &
      \includegraphics[width=.3\textwidth]{element_Lagrange_2_dof5.pdf}
    \end{tabular}
    %
    \caption{P2 basis functions, TODO}
  \end{subfigure}
  %
  \caption{TODO, \cite{defelement}}
\end{figure}

% What do the basis functions we described above look like?
% * associated with topological entities (so shared between adjacent cells)
% * compact support, for this reason often called "hat functions"
% * reference Lagrange 2 figure 

% The basis functions are a consequence of the choice of *finite element*
% * Give the Ciarlet definition
% * Reference Lagrange 2 figure again and talk about functionals etc

% "The choice of basis functions used by the function spaces has significant implications for the convergence and stability of the model."
% * for Stokes "a good choice is..." use P3-DG2? SV? TH? whatever is discontinuous (and explain what that means)
% * must be a certain degree to be stable (P3?) (see papers about counting DoFs by multigrid man)
% * reference a figure showing the element pair

% This choice of finite element pair means that one would have, for a single element mesh, 36 (?) unknown basis coefficients (DoFs), and the matrix would have 36 rows and 36 columns (and would in fact be dense)
% * In memory these would typically be laid out as... (reference a figure)
%NOTE: No need to discuss numbering here because for a single cell it isn't a thing

\subsection{The assembly algorithm}

% Since the basis functions only have local support we only need to compute the interaction between a small number of basis functions, most values in the matrix will be zero (i.e. sparse)
% * So we loop over cells and compute interactions of basis functions on that cell, then we can incrementally add to the global matrix
% * We do something analogous for the global vector
% * Show as a pseudo-code algorithm
% * can show my pretty diagram now!

% On massively parallel machines we parallelise our computation by partitioning the mesh between processes
% * Basis functions whose support crosses into another process are stored in that processes "halo"
% * Show a simple diagram - continue to use triangles (and basis functions)
% * The global matrix is also partitioned, usually by row, so each process only sees a portion of it

%NOTE:I could perhaps talk about mesh renumbering here - I kind of want a "FEM optimisations" section to talk about it, and perhaps interleaving computation and communication?
% Or are those specific to the software?

% "Domain-specific languages"?
% "Domain-specific languages for array computations"?
% "Abstractions for array computations"?
% This section is really talking about compilers and JIT-ing
\section{Code generation and domain-specific languages for scientific computing}

% why is code generation useful?
% We need to be able to express problems in some platform
% agnostic language that gets compiled to different platforms and can
% apply platform specific optimisations. Needs to be fast and productive and portable.
% can be super fast!
% * Halide?
% * Spiral?
% * BLIS?
% * FFTW?

% NOTE: Not completely sure how to arrange the below bit

% inspector-executor model. cite Saltz and Strout
% two programs, an inspector that generates a schedule, and an executor that uses it. Executor
% is a transformed original program.
% these aim to improve data locality and parallelisation opportunities.
% important point is that I/E strategies utilise runtime information to generate optimal schedules
% this is very important for unstructured applications where the compilers would have a really hard time!
\cite{stroutSparsePolyhedralFramework2018} % review article
\cite{mirchandaneyPrinciplesRuntimeSupport1988} % old (general purpose) example
\cite{arenazInspectorExecutorAlgorithmIrregular2004} % fem example but specifically parallelisation
% perhaps also cite Luporini for sparse tiling? yes I think that would be good.
% Interesting note: composing inspector-executor transformations is difficult.
% see "The Sparse Polyhedral Framework: Composing Compiler-Generated Inspector-Executor Code"
% DSLs like loopy and pyop3 can make this easier to handle.
% mesh numbering is an example of an inspector-executor thing.
% so is determining core and owned to overlap communication and computation
% DSLs help a lot to implement this sort of thing because transformations can be a lot easier to
% express using a high-level representation.

% Therefore need a nice abstraction for expressing and reasoning about the problem: DSL

\subsection{Abstractions for array computations}

% There are a million and one compilers for handling arrays
% e.g. polyhedral model, TACO, Tiramisu, einsum notation

% however, they are not sufficient for our purposes because they all use N-dimensional array/tensor layouts.
% mesh data is more heterogeneous than that so for things to work need to discard information about the topological relations between the mesh and the data

% it can be made more complicated with things like TACO where the layers can differ, but still not sufficient as there are intra-layer differences
% also sparsity (SPF), ragged (AwkwardArray, PPMD), distributed (DistArray, Chapel)

\subsection{Abstractions for mesh-like data layouts}

% The following all fix this problem and can describe the right kind of data layouts
%NOTE: could try having a checklist of features?

% OP2: \cite{mudaligeOP2ActiveLibrary2012}
% PyOP2
% the simplest solution, use indirection maps
% works in parallel, not composable/expressive
% sophisticated overlapping of computation and communication
% does not need a mesh object, can use external software

% Liszt
% \cite{devitoLisztDomainSpecific2011}
% * dead project (since 2013)
% * works in parallel, but custom mesh etc so has to do its own partitioning etc
% * mesh is not dimension-independent
% * embedded in Scala
% * (needs a mesh)

% Simit
% https://simit-lang.org/
% \cite{kjolstadSimitLanguagePhysical2016}
% * dead project
% * C++ code
% * does not work on multi-core machines, does work with GPUs
% * hypergraph is like DMPlex, has a custom mesh implementation
% * stores data as "hypergraph sets with tensor fields" - associates data with topological entities
% * has "dual" representations of mesh data structures: as hypergraphs and as tensors. pyop3 effectively unifies the two
% * (needs a mesh - sort of)

% Ebb
% http://ebblang.org/
% * dead project
% \cite{bernsteinEbbDSLPhysical2016}
% uses a relational database model to describe mesh connectivity
% uses a layer model to separate data structure definition from simulation code
% * (doesn't need a mesh)
% * embedded in lua
% * not multi-core

% AoS-SoA etc? (taichi)
\textbf{Taichi} is a programming language embedded in C\+\+ for operating on complex data structures~\cite{huTaichiLanguageHighperformance2019}.
Just like \pyop3, Taichi declares data structures hierarchically and the data layout is kept distinct from the operations applied to them.
Taichi has no concept of a mesh, and it does not work on distributed machines.
% https://www.taichi-lang.org/
% very successful!

% summarise - these all have limitations so we will make a new one based on DMPlex and PyOP2

\section{An abstraction for unstructured meshes: PETSc DMPlex}

% generally introduce PETSc as well in a few sentences (matrices, vectors, solvers, massively parallel, GPU support)
% * DMPlex
  % * layouts with petscsection

% data layouts on meshes
  % stencils
    % stencils in dmplex, topological query language

% TODO: MUST talk about mesh renumbering here, also parallel stuff (SF)
% No, parallel can be later, just mention here that the mesh is distributed and
% point to the parallel chapter.
% Numbering can reference the FEM pseudo-code - we need cellwise data to be "close"

% \subsubsection{Representing data layouts with DMPlex}
%
% DMPlex represents a mesh as a set of points where the points are divided into \textit{strata} (cells, edges, vertices, etc).
% These points are connected in a graph (Hasse diagram) and a rich set of queries can be used to determine the right adjacencies needed for things like the finite element method.
%
% In order to associated data with these mesh points, a typical PETSc application will construct a PETSc \ccode{Section}.
% These are simple CSR-like (?) data structures that encode a data layout by associating a particular number of DoFs with each mesh point.
% Sections are a powerful tool for describing data layouts but they have a number of limitations:
%
% \begin{itemize}
%   \item
%     Sections are fully ragged.
%     They only store DoF information per point in a completely unstructured way and are incapable of knowing, say, that every cell in the mesh stores exactly one DoF.
%     This can prohibit the compiler from making certain optimisations (e.g. loop unrolling) that it would have been able to do were it to know of a constant loop extent.
%     Additionally, this variable size increases memory pressure as redundant arrays of constant sizes need to be streamed through memory.
%
%   \item
%     DoFs per point are treated as a flat array.
%     This means that shape information is lost for, say, vector-valued functions.
% \end{itemize}
%
% With PETSc/DMPlex, the P3 DoF layout would be represented as shown in Figure~\ref{???}.
% % figure showing PetscSection info

% End the section by showing some pseudocode for FEM assembly


\section{An execution model: PyOP2}
% and why OP2 not Liszt?
% why chosen? interop with PETSc, good for FEM, works in parallel...

% integrated with Firedrake (popular FEM lib)

% loopy
% PyOP2 limitations
% explain loopy's programming model of kernel plus transformations. It is fundamentally
% very similar to how high level mathematical DSLs like UFL work except for loops.

% \subsubsection{Data layouts in \pyop2}
%
% \pyop2 takes a very different approach to describing data layouts to DMPlex.
% Firstly, it has no conception of what a mesh is and it deals solely with \textit{sets} and \textit{mappings between sets}.
% The rich query language provided by DMPlex is therefore unavailable and the task of determining the right adjacency maps is passed to the user.
%


% TODO: I don't know where to put this bit? where we talk about N-dimensional arrays? could explain concepts of shape and indexing? Specific syntax can then be described in later sections...
\subsection{An interface for multi-dimensional data: numpy}

% (cite paper, search for "citing numpy")
% although not a JIT, numpy is important for introducing ergonomic ways of
% expressing array computations
% there are some numpy JIT options out there: JAX, pytato, pytorch?



\end{document}
