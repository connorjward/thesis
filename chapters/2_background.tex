\documentclass[thesis]{subfiles}

\begin{document}

\chapter{Foundations}

In this chapter we review a number of existing libraries whose designs served as inspiration for the abstractions underpinning \pyop3.
In order these are:
\pyop2, another mesh execution library and the direct precursor to \pyop3;
DMPlex, an unstructured mesh abstraction;
and numpy, the go-to library for representing structured data in Python.

\section{\pyop2}

% why chosen? interop with PETSc, good for FEM, works in parallel...

% integrated with Firedrake (popular FEM lib)

% loopy
% PyOP2 limitations
% explain loopy's programming model of kernel plus transformations. It is fundamentally
% very similar to how high level mathematical DSLs like UFL work except for loops.

% \subsubsection{Data layouts in \pyop2}
%
% \pyop2 takes a very different approach to describing data layouts to DMPlex.
% Firstly, it has no conception of what a mesh is and it deals solely with \textit{sets} and \textit{mappings between sets}.
% The rich query language provided by DMPlex is therefore unavailable and the task of determining the right adjacency maps is passed to the user.
%



% interleave computation and communication

% "in the past has been..." (Luporini), aim to recover some of this...
% inspector-executor model. cite Saltz and Strout
% two programs, an inspector that generates a schedule, and an executor that uses it. Executor
% is a transformed original program.
% these aim to improve data locality and parallelisation opportunities.
% important point is that I/E strategies utilise runtime information to generate optimal schedules
% this is very important for unstructured applications where the compilers would have a really hard time!
\cite{stroutSparsePolyhedralFramework2018} % review article
\cite{mirchandaneyPrinciplesRuntimeSupport1988} % old (general purpose) example
\cite{arenazInspectorExecutorAlgorithmIrregular2004} % fem example but specifically parallelisation
% perhaps also cite Luporini for sparse tiling? yes I think that would be good.
% Interesting note: composing inspector-executor transformations is difficult.
% see "The Sparse Polyhedral Framework: Composing Compiler-Generated Inspector-Executor Code"
% DSLs like loopy and pyop3 can make this easier to handle.
% mesh numbering is an example of an inspector-executor thing.
% so is determining core and owned to overlap communication and computation
% DSLs help a lot to implement this sort of thing because transformations can be a lot easier to
% express using a high-level representation.

% Therefore need a nice abstraction for expressing and reasoning about the problem: DSL

% NOTE: Need to explicit about how what we do needs DMPlex - I guess needs to unify the models
\section{DMPlex}

% generally introduce PETSc as well in a few sentences (matrices, vectors, solvers, massively parallel, GPU support)
% * DMPlex
  % * layouts with petscsection

% data layouts on meshes
  % stencils
    % stencils in dmplex, topological query language

% TODO: MUST talk about mesh renumbering here, also parallel stuff (SF)
% No, parallel can be later, just mention here that the mesh is distributed and
% point to the parallel chapter.
% Numbering can reference the FEM pseudo-code - we need cellwise data to be "close"

% \subsubsection{Representing data layouts with DMPlex}
%
% DMPlex represents a mesh as a set of points where the points are divided into \textit{strata} (cells, edges, vertices, etc).
% These points are connected in a graph (Hasse diagram) and a rich set of queries can be used to determine the right adjacencies needed for things like the finite element method.
%
% In order to associated data with these mesh points, a typical PETSc application will construct a PETSc \ccode{Section}.
% These are simple CSR-like (?) data structures that encode a data layout by associating a particular number of DoFs with each mesh point.
% Sections are a powerful tool for describing data layouts but they have a number of limitations:
%
% \begin{itemize}
%   \item
%     Sections are fully ragged.
%     They only store DoF information per point in a completely unstructured way and are incapable of knowing, say, that every cell in the mesh stores exactly one DoF.
%     This can prohibit the compiler from making certain optimisations (e.g. loop unrolling) that it would have been able to do were it to know of a constant loop extent.
%     Additionally, this variable size increases memory pressure as redundant arrays of constant sizes need to be streamed through memory.
%
%   \item
%     DoFs per point are treated as a flat array.
%     This means that shape information is lost for, say, vector-valued functions.
% \end{itemize}
%
% With PETSc/DMPlex, the P3 DoF layout would be represented as shown in Figure~\ref{???}.
% % figure showing PetscSection info

% End the section by showing some pseudocode for FEM assembly

\section{numpy}

% (cite paper, search for "citing numpy")
% although not a JIT, numpy is important for introducing ergonomic ways of
% expressing array computations
% there are some numpy JIT options out there: JAX, pytato, pytorch?



\end{document}
