@article{abdelfattahGPUAlgorithmsEfficient2021,
  title = {{{GPU}} Algorithms for {{Efficient Exascale Discretizations}}},
  author = {Abdelfattah, Ahmad and Barra, Valeria and Beams, Natalie and Bleile, Ryan and Brown, Jed and Camier, Jean-Sylvain and Carson, Robert and Chalmers, Noel and Dobrev, Veselin and Dudouit, Yohann and Fischer, Paul and Karakus, Ali and Kerkemeier, Stefan and Kolev, Tzanio and Lan, Yu-Hsiang and Merzari, Elia and Min, Misun and Phillips, Malachi and Rathnayake, Thilina and Rieben, Robert and Stitt, Thomas and Tomboulides, Ananias and Tomov, Stanimire and Tomov, Vladimir and Vargas, Arturo and Warburton, Tim and Weiss, Kenneth},
  date = {2021-12},
  journaltitle = {Parallel Computing},
  shortjournal = {Parallel Computing},
  volume = {108},
  pages = {102841},
  issn = {01678191},
  doi = {10.1016/j.parco.2021.102841},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167819121000879},
  urldate = {2024-03-04},
  abstract = {In this paper we describe the research and development activities in the Center for Efficient Exascale Discretization within the US Exascale Computing Project, targeting state-of-the-art high-order finite-element algorithms for high-order applications on GPU-accelerated platforms. We discuss the GPU developments in several components of the CEED software stack, including the libCEED, MAGMA, MFEM, libParanumal, and Nek projects. We report performance and capability improvements in several CEED-enabled applications on both NVIDIA and AMD GPU systems.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/7GS74WW3/Abdelfattah et al. - 2021 - GPU algorithms for Efficient Exascale Discretizati.pdf}
}

@report{adamsHPGMGBenchmarkRanking2014,
  title = {{{HPGMG}} 1.0: {{A Benchmark}} for {{Ranking High Performance Computing Systems}}},
  shorttitle = {{{HPGMG}} 1.0},
  author = {Adams, Mark and Brown, Jed and Shalf, John and Straalen, Brian Van and Strohmaier, Erich and Williams, Sam},
  date = {2014-05-05},
  number = {LBNL-6630E, 1131029},
  pages = {LBNL-6630E, 1131029},
  doi = {10.2172/1131029},
  url = {http://www.osti.gov/servlets/purl/1131029/},
  urldate = {2023-11-01},
  abstract = {This document provides an overview of the benchmark – HPGMG – for ranking large scale general purpose computers for use on the Top500 list [8]. We provide a rationale for the need for a replacement for the current metric HPL, some background of the Top500 list and the challenges of developing such a metric; we discuss our design philosophy and methodology, and an overview of the specification of the benchmark. The primary documentation with maintained details on the specification can be found at hpgmg.org and the Wiki and benchmark code itself can be found in the repository https://bitbucket.org/hpgmg/hpgmg.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/TA5BUXP4/Adams et al. - 2014 - HPGMG 1.0 A Benchmark for Ranking High Performanc.pdf}
}

@unpublished{adamsPETScCommunityInfrastructure2022,
  title = {The {{PETSc Community Is}} the {{Infrastructure}}},
  author = {Adams, Mark and Balay, Satish and Marin, Oana and McInnes, Lois Curfman and Mills, Richard Tran and Munson, Todd and Zhang, Hong and Zhang, Junchao and Brown, Jed and Eijkhout, Victor and Faibussowitsch, Jacob and Knepley, Matthew and Kong, Fande and Kruger, Scott and Sanan, Patrick and Smith, Barry F. and Zhang, Hong},
  date = {2022-01-03},
  eprint = {2201.00967},
  eprinttype = {arXiv},
  eprintclass = {cs},
  publisher = {arXiv},
  url = {http://arxiv.org/abs/2201.00967},
  urldate = {2022-05-25},
  abstract = {The communities who develop and support open source scientific software packages are crucial to the utility and success of such packages. Moreover, these communities form an important part of the human infrastructure that enables scientific progress. This paper discusses aspects of the PETSc (Portable Extensible Toolkit for Scientific Computation) community, its organization, and technical approaches that enable community members to help each other efficiently.},
  keywords = {Computer Science - Software Engineering},
  file = {/home/connor/OneDrive/AppData/Zotero/Adams et al_2022_The PETSc Community Is the Infrastructure.pdf;/home/connor/.local/share/zotero/storage/IQAKF925/2201.html}
}

@article{adamsSegmentalRefinementMultigrid2016,
  title = {Segmental {{Refinement}}: {{A Multigrid Technique}} for {{Data Locality}}},
  shorttitle = {Segmental {{Refinement}}},
  author = {Adams, Mark F. and Brown, Jed and Knepley, Matt and Samtaney, Ravi},
  date = {2016-01},
  journaltitle = {SIAM Journal on Scientific Computing},
  shortjournal = {SIAM J. Sci. Comput.},
  volume = {38},
  number = {4},
  eprint = {1406.7808},
  eprinttype = {arXiv},
  eprintclass = {math},
  pages = {C426-C440},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/140975127},
  url = {http://arxiv.org/abs/1406.7808},
  urldate = {2023-03-23},
  abstract = {We investigate a domain decomposed multigrid technique, segmental refinement, for solving general nonlinear elliptic boundary value problems. Brandt and Diskin first proposed this method in 1994; we continue this work by analytically and experimentally investigating its complexity. We confirm that communication of traditional parallel multigrid can be eliminated on fine grids with modest amounts of extra work and storage while maintaining the asymptotic exactness of full multigrid, although we observe a dependence on an additional parameter not considered in the original analysis. We present a communication complexity analysis that quantifies the communication costs ameliorated by segmental refinement and report performance results with up to 64K cores of a Cray XC30.},
  langid = {english},
  keywords = {Mathematics - Numerical Analysis},
  file = {/home/connor/.local/share/zotero/storage/IFUVDG6P/Adams et al. - 2016 - Segmental Refinement A Multigrid Technique for Da.pdf}
}

@article{agelekOrientingEdgesUnstructured2017,
  title = {On {{Orienting Edges}} of {{Unstructured Two-}} and {{Three-Dimensional Meshes}}},
  author = {Agelek, Rainer and Anderson, Michael and Bangerth, Wolfgang and Barth, William L.},
  date = {2017-07-24},
  journaltitle = {ACM Transactions on Mathematical Software},
  shortjournal = {ACM Trans. Math. Softw.},
  volume = {44},
  number = {1},
  pages = {1--22},
  issn = {0098-3500, 1557-7295},
  doi = {10.1145/3061708},
  url = {https://dl.acm.org/doi/10.1145/3061708},
  urldate = {2021-07-01},
  abstract = {Finite element codes typically use data structures that represent unstructured meshes as collections of cells, faces, and edges, each of which require associated coordinate systems. One then needs to store how the coordinate system of each edge relates to that of neighboring cells. However, we can simplify data structures and algorithms if we can a priori orient coordinate systems in such a way that the coordinate systems on the edges follow uniquely from those on the cells by rule.                            Such rules require that every unstructured mesh allow the assignment of directions to edges that satisfy the convention in adjacent cells. We show that the convention chosen for unstructured quadrilateral meshes in the               deal.II               library always allows to orient meshes. It can therefore be used to make codes simpler, faster, and less bug prone. We present an algorithm that orients meshes in               O               (               N               ) operations. We then show that consistent orientations are not always possible for 3D hexahedral meshes. Thus, cells generally need to store the direction of adjacent edges, but our approach also allows the characterization of cases where this is not necessary. The 3D extension of our algorithm either orients edges consistently, or aborts, both within               O               (               N               ) steps.},
  langid = {english},
  keywords = {deal.ii,orientation,quads},
  file = {/home/connor/.local/share/zotero/storage/SN89RIMP/Agelek et al_2017_On Orienting Edges of Unstructured Two- and Three-Dimensional Meshes.pdf}
}

@online{ahrensFinchSparseStructured2024,
  title = {Finch: {{Sparse}} and {{Structured Array Programming}} with {{Control Flow}}},
  shorttitle = {Finch},
  author = {Ahrens, Willow and Collin, Teodoro Fields and Patel, Radha and Deeds, Kyle and Hong, Changwan and Amarasinghe, Saman},
  date = {2024-04-25},
  eprint = {2404.16730},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2404.16730},
  urldate = {2024-05-03},
  abstract = {WILLOW AHRENS, MIT CSAIL, USA TEODORO FIELDS COLLIN, MIT CSAIL, USA RADHA PATEL, MIT CSAIL, USA KYLE DEEDS, University of Washington, USA CHANGWAN HONG, MIT CSAIL, USA SAMAN AMARASINGHE, MIT CSAIL, USA From FORTRAN to NumPy, arrays have revolutionized how we express computation. However, arrays in these, and almost all prominent systems, can only handle dense rectilinear integer grids. Real world arrays often contain underlying structure, such as sparsity, runs of repeated values, or symmetry. Support for structured data is fragmented and incomplete. Existing frameworks limit the array structures and program control flow they support to better simplify the problem. In this work, we propose a new programming language, Finch, which supports both flexible control flow and diverse data structures. Finch facilitates a programming model which resolves the challenges of computing over structured arrays by combining control flow and data structures into a common representation where they can be co-optimized. Finch automatically specializes control flow to data so that performance engineers can focus on experimenting with many algorithms. Finch supports a familiar programming language of loops, statements, ifs, breaks, etc., over a wide variety of array structures, such as sparsity, run-length-encoding, symmetry, triangles, padding, or blocks. Finch reliably utilizes the key properties of structure, such as structural zeros, repeated values, or clustered non-zeros. We show that this leads to dramatic speedups in operations such as SpMV and SpGEMM, image processing, graph analytics, and a high-level tensor operator fusion interface. CCS Concepts: • Software and its engineering → Control structures; Data types and structures; Imperative languages; • Mathematics of computing → Mathematical software.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Mathematical Software},
  file = {/home/connor/.local/share/zotero/storage/KVQ7BURW/Ahrens et al. - 2024 - Finch Sparse and Structured Array Programming wit.pdf}
}

@incollection{Alnaes2012a,
  title = {{{UFL}}: A Finite Element Form Language},
  booktitle = {Automated Solution of Differential Equations by the Finite Element Method, Volume 84 of Lecture Notes in Computational Science and Engineering},
  author = {Alnæs, Martin S.},
  editor = {Logg, Anders and Mardal, Kent-Andre and Wells, Garth N.},
  date = {2012},
  publisher = {Springer}
}

@article{AlnaesBlechta2015a,
  title = {The {{FEniCS}} Project Version 1.5},
  author = {Alnæs, Martin S. and Blechta, Jan and Hake, Johan and Johansson, August and Kehlet, Benjamin and Logg, Anders and Richardson, Chris and Ring, Johannes and Rognes, Marie E. and Wells, Garth N.},
  date = {2015},
  journaltitle = {Archive of Numerical Software},
  volume = {3},
  number = {100},
  doi = {10.11588/ans.2015.100.20553},
  page = {9-23}
}

@article{AlnaesLoggEtAl2009a,
  title = {Unified Framework for Finite Element Assembly},
  author = {Alnæs, Martin S. and Logg, Anders and Mardal, Kent-Andre and Skavhaug, Ola and Langtangen, Hans Petter},
  date = {2009},
  journaltitle = {International Journal of Computational Science and Engineering},
  volume = {4},
  number = {4},
  pages = {231--244},
  doi = {10.1504/IJCSE.2009.029160}
}

@incollection{AlnaesLoggEtAl2012a,
  title = {{{UFC}}: A Finite Element Code Generation Interface},
  booktitle = {Automated Solution of Differential Equations by the Finite Element Method, Volume 84 of Lecture Notes in Computational Science and Engineering},
  author = {Alnæs, Martin S. and Logg, Anders and Mardal, Kent-Andre},
  editor = {Logg, Anders and Mardal, Kent-Andre and Wells, Garth N.},
  date = {2012},
  publisher = {Springer}
}

@article{AlnaesMardal2010a,
  title = {On the Efficiency of Symbolic Computations Combined with Code Generation for Finite Element Methods},
  author = {Alnæs, Martin S. and Mardal, Kent-Andre},
  date = {2010},
  journaltitle = {ACM Transactions on Mathematical Software},
  volume = {37},
  number = {1},
  doi = {10.1145/1644001.1644007},
  num_pages = {26 pages}
}

@incollection{AlnaesMardal2012b,
  title = {{{SyFi}} and {{SFC}}: {{Symbolic}} Finite Elements and Form Compilation},
  booktitle = {Automated Solution of Differential Equations by the Finite Element Method, Volume 84 of Lecture Notes in Computational Science and Engineering},
  author = {Alnæs, Martin S. and Mardal, Kent-Andre},
  editor = {Logg, Anders and Mardal, Kent-Andre and Wells, Garth N.},
  date = {2012},
  publisher = {Springer}
}

@article{alnaesUnifiedFormLanguage2014a,
  title = {Unified {{Form Language}}: {{A}} Domain-Specific Language for Weak Formulations of Partial Differential Equations},
  author = {Alnæs, Martin S. and Logg, Anders and Ølgaard, Kristian B. and Rognes, Marie E. and Wells, Garth N.},
  date = {2014},
  journaltitle = {ACM Transactions on Mathematical Software},
  volume = {40},
  number = {2},
  eprint = {1211.4047},
  eprinttype = {arXiv},
  doi = {10.1145/2566630},
  keywords = {ufl},
  file = {/home/connor/Obsidian/30 Literature notes/Zotero/alnaesUnifiedFormLanguage2014 - Extracted Annotations (30042021, 164742)The library generates abstract syntax tree representations of variational p.md;/home/connor/Obsidian/30 Literature notes/Zotero/alnaesUnifiedFormLanguage2014-zotero.md;/home/connor/OneDrive/AppData/Zotero/Alnæs et al_2014_Unified form language.pdf}
}

@inproceedings{amdahlValiditySingleProcessor1967,
  title = {Validity of the Single Processor Approach to Achieving Large Scale Computing Capabilities},
  booktitle = {Proceedings of the {{April}} 18-20, 1967, Spring Joint Computer Conference on - {{AFIPS}} '67 ({{Spring}})},
  author = {Amdahl, Gene M.},
  date = {1967},
  pages = {483},
  publisher = {ACM Press},
  location = {Atlantic City, New Jersey},
  doi = {10.1145/1465482.1465560},
  url = {http://portal.acm.org/citation.cfm?doid=1465482.1465560},
  urldate = {2021-06-18},
  eventtitle = {The {{April}} 18-20, 1967, Spring Joint Computer Conference},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/9N8P4YRV/Amdahl - 1967 - Validity of the single processor approach to achie.pdf}
}

@article{amestoyMUMPSGeneralPurpose,
  title = {{{MUMPS}}: A General Purpose Distributed Memory Sparse Solver},
  author = {Amestoy, Patrick R and Duff, Iain S and L’Excellent, Jean-Yves and Koster, Jacko},
  abstract = {MUMPS is a software package for the multifrontal solution of large sparse linear systems on distributed memory computers. The matrices can be symmetric positive definite, general symmetric, or unsymmetric, and possibly rank deficient. MUMPS exploits parallelism coming from the sparsity in the matrix and parallelism available for dense matrices. Additionally, large computational tasks are divided into smaller subtasks to enhance parallelism. MUMPS uses a distributed dynamic scheduling technique that allows numerical pivoting and the migration of computational tasks to lightly loaded processors. Asynchronous communication is used to overlap communication with computation. In this paper, we report on recently integrated features and illustrate the present performance of the solver.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/2HUMBH4N/Amestoy et al. - MUMPS a general purpose distributed memory sparse.pdf}
}

@online{andrejHighperformanceFiniteElements2024,
  title = {High-Performance Finite Elements with {{MFEM}}},
  author = {Andrej, Julian and Atallah, Nabil and Bäcker, Jan-Phillip and Camier, John and Copeland, Dylan and Dobrev, Veselin and Dudouit, Yohann and Duswald, Tobias and Keith, Brendan and Kim, Dohyun and Kolev, Tzanio and Lazarov, Boyan and Mittal, Ketan and Pazner, Will and Petrides, Socratis and Shiraiwa, Syun'ichi and Stowell, Mark and Tomov, Vladimir},
  date = {2024-02-24},
  eprint = {2402.15940},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2402.15940},
  urldate = {2024-03-04},
  abstract = {The MFEM (Modular Finite Element Methods) library is a high-performance C++ library for finite element discretizations. MFEM supports numerous types of finite element methods and is the discretization engine powering many computational physics and engineering applications across a number of domains. This paper describes some of the recent research and development in MFEM, focusing on performance portability across leadership-class supercomputing facilities, including exascale supercomputers, as well as new capabilities and functionality, enabling a wider range of applications. Much of this work was undertaken as part of the Department of Energy’s Exascale Computing Project (ECP) in collaboration with the Center for Efficient Exascale Discretizations (CEED).},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Mathematical Software,Mathematics - Numerical Analysis},
  file = {/home/connor/.local/share/zotero/storage/3FYSGFAG/Andrej et al. - 2024 - High-performance finite elements with MFEM.pdf}
}

@incollection{arenazInspectorExecutorAlgorithmIrregular2004,
  title = {An {{Inspector-Executor Algorithm}} for {{Irregular Assignment Parallelization}}},
  booktitle = {Parallel and {{Distributed Processing}} and {{Applications}}},
  author = {Arenaz, Manuel and Touriño, Juan and Doallo, Ramón},
  editor = {Cao, Jiannong and Yang, Laurence T. and Guo, Minyi and Lau, Francis},
  editora = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Dough and Vardi, Moshe Y. and Weikum, Gerhard},
  editoratype = {redactor},
  date = {2004},
  volume = {3358},
  pages = {4--15},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-30566-8_4},
  url = {http://link.springer.com/10.1007/978-3-540-30566-8_4},
  urldate = {2023-11-27},
  abstract = {A loop with irregular assignment computations contains loopcarried output data dependences that can only be detected at run-time. In this paper, a load-balanced method based on the inspector-executor model is proposed to parallelize this loop pattern. The basic idea lies in splitting the iteration space of the sequential loop into sets of conflictfree iterations that can be executed concurrently on different processors. As will be demonstrated, this method outperforms existing techniques. Irregular access patterns with different load-balancing and reusability properties are considered in the experiments.},
  isbn = {978-3-540-24128-7 978-3-540-30566-8},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/KLL2FIQQ/Arenaz et al. - 2004 - An Inspector-Executor Algorithm for Irregular Assi.pdf}
}

@unpublished{arnoldDifferentialComplexesNumerical2002,
  title = {Differential Complexes and Numerical Stability},
  author = {Arnold, Douglas N.},
  date = {2002-11-30},
  eprint = {math/0212391},
  eprinttype = {arXiv},
  url = {http://arxiv.org/abs/math/0212391},
  urldate = {2022-03-18},
  abstract = {Differential complexes such as the de Rham complex have recently come to play an important role in the design and analysis of numerical methods for partial differential equations. The design of stable discretizations of systems of partial differential equations often hinges on capturing subtle aspects of the structure of the system in the discretization. In many cases the differential geometric structure captured by a differential complex has proven to be a key element, and a discrete differential complex which is appropriately related to the original complex is essential. This new geometric viewpoint has provided a unifying understanding of a variety of innovative numerical methods developed over recent decades and pointed the way to stable discretizations of problems for which none were previously known, and it appears likely to play an important role in attacking some currently intractable problems in numerical PDE.},
  keywords = {65N12,Mathematics - Numerical Analysis},
  file = {/home/connor/OneDrive/AppData/Zotero/Arnold_2002_Differential complexes and numerical stability.pdf;/home/connor/.local/share/zotero/storage/QKCGFEAX/0212391.html}
}

@article{arnoldFiniteElementExterior2006,
  title = {Finite Element Exterior Calculus, Homological Techniques, and Applications},
  author = {Arnold, Douglas N. and Falk, Richard S. and Winther, Ragnar},
  date = {2006-05},
  journaltitle = {Acta Numerica},
  shortjournal = {Acta Numerica},
  volume = {15},
  pages = {1--155},
  issn = {0962-4929, 1474-0508},
  doi = {10.1017/S0962492906210018},
  url = {https://www.cambridge.org/core/product/identifier/S0962492906210018/type/journal_article},
  urldate = {2022-03-18},
  abstract = {Finite element exterior calculus is an approach to the design and understanding of finite element discretizations for a wide variety of systems of partial differential equations. This approach brings to bear tools from differential geometry, algebraic topology, and homological algebra to develop discretizations which are compatible with the geometric, topological, and algebraic structures which underlie well-posedness of the PDE problem being solved. In the finite element exterior calculus, many finite element spaces are revealed as spaces of piecewise polynomial differential forms. These connect to each other in discrete subcomplexes of elliptic differential complexes, and are also related to the continuous elliptic complex through projections which commute with the complex differential. Applications are made to the finite element discretization of a variety of problems, including the Hodge Laplacian, Maxwell’s equations, the equations of elasticity, and elliptic eigenvalue problems, and also to preconditioners.},
  langid = {english},
  keywords = {\_tablet\_modified},
  file = {/home/connor/.local/share/zotero/storage/P6FPZHGC/Arnold et al_2006_Finite element exterior calculus, homological techniques, and applications.pdf}
}

@book{arnoldFiniteElementExterior2018,
  title = {Finite Element Exterior Calculus},
  author = {Arnold, Douglas N.},
  date = {2018},
  series = {{{CBMS-NSF}} Regional Conference Series in Applied Mathematics},
  publisher = {{Society for Industrial and Applied Mathematics}},
  location = {Philadelphia},
  url = {https://epubs-siam-org.iclibezp1.cc.ic.ac.uk/doi/book/10.1137/1.9781611975543},
  isbn = {978-1-61197-554-3},
  pagetotal = {1},
  keywords = {Calculus,Calculus of variations,Differential equations,Finite element method,Numerical solutions}
}

@article{arnoldPRECONDITIONINGDivAPPLICATIONS1997,
  title = {{{PRECONDITIONING IN H}} (Div) {{AND APPLICATIONS}}},
  author = {Arnold, Douglas N and Falk, Richard S and Winther, R},
  date = {1997},
  pages = {28},
  abstract = {We consider the solution of the system of linear algebraic equations which arises from the finite element discretization of boundary value problems associated to the differential operator I − grad div. The natural setting for such problems is in the Hilbert space H (div) and the variational formulation is based on the inner product in H (div). We show how to construct preconditioners for these equations using both domain decomposition and multigrid techniques. These preconditioners are shown to be spectrally equivalent to the inverse of the operator. As a consequence, they may be used to precondition iterative methods so that any given error reduction may be achieved in a finite number of iterations, with the number independent of the mesh discretization. We describe applications of these results to the efficient solution of mixed and least squares finite element approximations of elliptic boundary value problems.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/WBBF59PM/Arnold et al. - PRECONDITIONING IN H (div) AND APPLICATIONS.pdf}
}

@unpublished{baghdadiTiramisuPolyhedralCompiler2018,
  title = {Tiramisu: {{A Polyhedral Compiler}} for {{Expressing Fast}} and {{Portable Code}}},
  shorttitle = {Tiramisu},
  author = {Baghdadi, Riyadh and Ray, Jessica and Romdhane, Malek Ben and Del Sozzo, Emanuele and Akkas, Abdurrahman and Zhang, Yunming and Suriana, Patricia and Kamil, Shoaib and Amarasinghe, Saman},
  date = {2018-12-20},
  eprint = {1804.10694},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1804.10694},
  urldate = {2022-03-29},
  abstract = {This paper introduces Tiramisu, a polyhedral framework designed to generate high performance code for multiple platforms including multicores, GPUs, and distributed machines. Tiramisu introduces a scheduling language with novel extensions to explicitly manage the complexities that arise when targeting these systems. The framework is designed for the areas of image processing, stencils, linear algebra and deep learning. Tiramisu has two main features: it relies on a flexible representation based on the polyhedral model and it has a rich scheduling language allowing fine-grained control of optimizations. Tiramisu uses a four-level intermediate representation that allows full separation between the algorithms, loop transformations, data layouts, and communication. This separation simplifies targeting multiple hardware architectures with the same algorithm. We evaluate Tiramisu by writing a set of image processing, deep learning, and linear algebra benchmarks and compare them with state-of-the-art compilers and hand-tuned libraries. We show that Tiramisu matches or outperforms existing compilers and libraries on different hardware architectures, including multicore CPUs, GPUs, and distributed machines.},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Mathematical Software,Computer Science - Neural and Evolutionary Computing,Computer Science - Performance,Computer Science - Programming Languages},
  file = {/home/connor/OneDrive/AppData/Zotero/Baghdadi et al_2018_Tiramisu.pdf;/home/connor/.local/share/zotero/storage/YLUDT2UV/1804.html}
}

@article{bakerMeshGenerationArt2005,
  title = {Mesh Generation: {{Art}} or Science?},
  shorttitle = {Mesh Generation},
  author = {Baker, Timothy J.},
  date = {2005-01},
  journaltitle = {Progress in Aerospace Sciences},
  shortjournal = {Progress in Aerospace Sciences},
  volume = {41},
  number = {1},
  pages = {29--63},
  issn = {03760421},
  doi = {10.1016/j.paerosci.2005.02.002},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0376042105000114},
  urldate = {2022-08-11},
  abstract = {Mesh generation has evolved to the point where highly complicated domains can be covered by a variety of mesh types including hexahedral, tetrahedral and overset meshes. The application of these methods to computational aerodynamics has become a routine exercise and numerical predictions over complete aircraft now complement experimental results obtained from wind tunnels. This paper surveys the main developments that have taken place and traces the evolution of mesh generation over the last 35 years. This is followed by an assessement of the accuracy of Navier Stokes codes that are currently in use for predicting the drag of an aircraft at transonic cruise. The relationship between solution accuracy, mesh size and mesh type is examined in some detail and the implications for further research are discussed.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/N6M4TAKA/Baker - 2005 - Mesh generation Art or science.pdf}
}

@article{baloghOP2ClangSourcetoSourceTranslator2018,
  title = {{{OP2-Clang}}: {{A Source-to-Source Translator Using Clang}}/{{LLVM LibTooling}}},
  author = {Balogh, G D and Mudalige, G R and Reguly, I Z and Antao, S F and Bertolli, C},
  date = {2018},
  pages = {12},
  abstract = {Domain Specific Languages or Active Library frameworks have recently emerged as an important method for gaining performance portability, where an application can be efficiently executed on a wide range of HPC architectures without significant manual modifications. Embedded DSLs such as OP2, provides an API embedded in general purpose languages such as C/C++/Fortran. They rely on source-to-source translation and code refactorization to translate the higher-level API calls to platform specific parallel implementations. OP2 targets the solution of unstructured-mesh computations, where it can generate a variety of parallel implementations for execution on architectures such as CPUs, GPUs, distributed memory clusters and heterogeneous processors making use of a wide range of platform specific optimizations. Compiler tool-chains supporting source-to-source translation of code written in mainstream languages currently lack the capabilities to carry out such wide-ranging code transformations. Clang/LLVM’s Tooling library (LibTooling) has long been touted as having such capabilities but have only demonstrated its use in simple source refactoring tasks.},
  langid = {english},
  keywords = {clang,code-generation,llvm,op2,unstructured-mesh},
  file = {/home/connor/Obsidian/30 Literature notes/baloghOP2ClangSourcetoSourceTranslator2018 - Extracted Annotations (10052021, 132851)Domain Specific Languages or Active Library frameworks provide higher-level.md;/home/connor/Obsidian/30 Literature notes/baloghOP2ClangSourcetoSourceTranslator2018 - Summary.md;/home/connor/Obsidian/30 Literature notes/baloghOP2ClangSourcetoSourceTranslator2018-zotero.md;/home/connor/Obsidian/30 Literature notes/baloghOP2ClangSourcetoSourceTranslator2018.md;/home/connor/Obsidian/30 Literature notes/Zotero/baloghOP2ClangSourcetoSourceTranslator2018 - Extracted Annotations (10052021, 132851)Domain Specific Languages or Active Library frameworks provide higher-level.md;/home/connor/Obsidian/30 Literature notes/Zotero/baloghOP2ClangSourcetoSourceTranslator2018 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/baloghOP2ClangSourcetoSourceTranslator2018-zotero.md;/home/connor/OneDrive/AppData/Zotero/Balogh et al_2018_OP2-Clang.pdf}
}

@article{bangerthAlgorithmsDataStructures2011,
  title = {Algorithms and Data Structures for Massively Parallel Generic Adaptive Finite Element Codes},
  author = {Bangerth, Wolfgang and Burstedde, Carsten and Heister, Timo and Kronbichler, Martin},
  date = {2011-12},
  journaltitle = {ACM Transactions on Mathematical Software},
  shortjournal = {ACM Trans. Math. Softw.},
  volume = {38},
  number = {2},
  pages = {1--28},
  issn = {0098-3500, 1557-7295},
  doi = {10.1145/2049673.2049678},
  url = {https://dl.acm.org/doi/10.1145/2049673.2049678},
  urldate = {2022-08-22},
  abstract = {Today's largest supercomputers have 100,000s of processor cores and offer the potential to solve partial differential equations discretized by billions of unknowns. However, the complexity of scaling to such large machines and problem sizes has so far prevented the emergence of generic software libraries that support such computations, although these would lower the threshold of entry and enable many more applications to benefit from large-scale computing.             We are concerned with providing this functionality for mesh-adaptive finite element computations. We assume the existence of an “oracle” that implements the generation and modification of an adaptive mesh distributed across many processors, and that responds to queries about its structure. Based on querying the oracle, we develop scalable algorithms and data structures for generic finite element methods. Specifically, we consider the parallel distribution of mesh data, global enumeration of degrees of freedom, constraints, and postprocessing. Our algorithms remove the bottlenecks that typically limit large-scale adaptive finite element analyses.             We demonstrate scalability of complete finite element workflows on up to 16,384 processors. An implementation of the proposed algorithms, based on the open source software p4est as mesh oracle, is provided under an open source license through the widely used deal.II finite element software library.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/6AVUVVM4/Bangerth et al. - 2011 - Algorithms and data structures for massively paral.pdf}
}

@article{bangerthDataStructuresRequirements2009,
  title = {Data Structures and Requirements for {\emph{Hp}} Finite Element Software},
  author = {Bangerth, W. and Kayser-Herold, O.},
  date = {2009-03},
  journaltitle = {ACM Transactions on Mathematical Software},
  shortjournal = {ACM Trans. Math. Softw.},
  volume = {36},
  number = {1},
  pages = {1--31},
  issn = {0098-3500, 1557-7295},
  doi = {10.1145/1486525.1486529},
  url = {https://dl.acm.org/doi/10.1145/1486525.1486529},
  urldate = {2022-08-22},
  abstract = {Finite element methods approximate solutions of partial differential equations by restricting the problem to a finite dimensional function space. In               hp               adaptive finite element methods, one defines these discrete spaces by choosing different polynomial degrees for the shape functions defined on a locally refined mesh.                          Although this basic idea is quite simple, its implementation in algorithms and data structures is challenging. It has apparently not been documented in the literature in its most general form. Rather, most existing implementations appear to be for special combinations of finite elements, or for discontinuous Galerkin methods.                            In this article, we discuss generic data structures and algorithms used in the implementation of               hp               methods for arbitrary elements, and the complications and pitfalls one encounters. As a consequence, we list the information a description of a finite element has to provide to the generic algorithms for it to be used in an               hp               context. We support our claim that our reference implementation is efficient using numerical examples in two dimensions and three dimensions, and demonstrate that the               hp               -specific parts of the program do not dominate the total computing time. This reference implementation is also made available as part of the Open Source deal.II finite element library.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/2ZBUGU2B/Bangerth and Kayser-Herold - 2009 - Data structures and requirements for hp fin.pdf}
}

@misc{bankRefinementAlgorithmDynamic,
  title = {A {{Refinement Algorithm}} and {{Dynamic Data Structure}} for {{Finite Element Meshes}}},
  author = {Bank, Randolph E. and Sherman, Andrew H.},
  file = {/home/connor/.local/share/zotero/storage/AGJLSVQ4/tr80-159.pdf}
}

@unpublished{barralAnisotropicMeshAdaptation2016,
  title = {Anisotropic Mesh Adaptation in {{Firedrake}} with {{PETSc DMPlex}}},
  author = {Barral, Nicolas and Knepley, Matthew G. and Lange, Michael and Piggott, Matthew D. and Gorman, Gerard J.},
  date = {2016-10-31},
  eprint = {1610.09874},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/1610.09874},
  urldate = {2021-06-29},
  abstract = {Despite decades of research in this area, mesh adaptation capabilities are still rarely found in numerical simulation software. We postulate that the primary reason for this is lack of usability. Integrating mesh adaptation into existing software is difficult as nontrivial operators, such as error metrics and interpolation operators, are required, and integrating available adaptive remeshers is not straightforward. Our approach presented here is to first integrate Pragmatic, an anisotropic mesh adaptation library, into DMPlex, a PETSc object that manages unstructured meshes and their interactions with PETSc’s solvers and I/O routines. As PETSc is already widely used, this will make anisotropic mesh adaptation available to a much larger community. As a demonstration of this we describe the integration of anisotropic mesh adaptation into Firedrake, an automated Finite Element based system for the portable solution of partial differential equations which already uses PETSc solvers and I/O via DMPlex. We present a proof of concept of this integration with a three-dimensional advection test case.},
  langid = {english},
  keywords = {dmplex,firedrake,mesh-adaptation},
  file = {/home/connor/.local/share/zotero/storage/DIAHHUES/Barral et al. - 2016 - Anisotropic mesh adaptation in Firedrake with PETS.pdf}
}

@article{barthelsLinneaCompilerLinear,
  title = {Linnea: {{A Compiler}} for {{Linear Algebra Operations}}},
  author = {Barthels, Henrik},
  pages = {5},
  abstract = {The evaluation of linear algebra expressions is a central part of both languages for scientific computing such as Julia and Matlab, and libraries such as Eigen, Blaze, and NumPy. However, the existing strategies are still rather primitive. At present, the only way to achieve high performance is by handcoding algorithms using libraries such as BLAS and LAPACK, a task that requires extensive knowledge in linear algebra, numerical linear algebra and high-performance computing. We present Linnea, the prototype of a compiler that automates the translation of linear algebra expressions to an efficient sequence of calls to BLAS and LAPACK kernels. Initial results indicate that the algorithms generated by Linnea significantly outperform existing high-level languages by a factor of up to six.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/VQZ9L7B2/Barthels - Linnea A Compiler for Linear Algebra Operations.pdf}
}

@inproceedings{bastoulCodeGenerationPolyhedral2004,
  title = {Code Generation in the Polyhedral Model Is Easier than You Think},
  booktitle = {Proceedings. 13th {{International Conference}} on {{Parallel Architecture}} and {{Compilation Techniques}}, 2004. {{PACT}} 2004.},
  author = {Bastoul, C.},
  date = {2004},
  pages = {7--16},
  publisher = {IEEE},
  location = {Antibes Juan-les-Pins, France},
  doi = {10.1109/PACT.2004.1342537},
  url = {http://ieeexplore.ieee.org/document/1342537/},
  urldate = {2021-01-05},
  abstract = {Many advances in automatic parallelization and optimization have been achieved through the polyhedral model. It has been extensively shown that this computational model provides convenient abstractions to reason about and apply program transformations. Nevertheless, the complexity of code generation has long been a deterrent for using polyhedral representation in optimizing compilers. First, code generators have a hard time coping with generated code size and control overhead that may spoil theoretical benefits achieved by the transformations. Second, this step is usually time consuming, hampering the integration of the polyhedral framework in production compilers or feedback-directed, iterative optimization schemes. Moreover, current code generation algorithms only cover a restrictive set of possible transformation functions. This paper discusses a general transformation framework able to deal with non-unimodular, non-invertible, non-integral or even non-uniform functions. It presents several improvements to a state-of-the-art code generation algorithm. Two directions are explored: generated code size and code generator efficiency. Experimental evidence proves the ability of the improved method to handle real-life problems.},
  eventtitle = {Proceedings. 13th {{International Conference}} on {{Parallel Architecture}} and {{Compilation Techniques}}, 2004. {{PACT}} 2004.},
  isbn = {978-0-7695-2229-6},
  langid = {english},
  file = {/home/connor/Obsidian/30 Literature notes/bastoulCodeGenerationPolyhedral2004 - Summary.md;/home/connor/Obsidian/30 Literature notes/bastoulCodeGenerationPolyhedral2004-zotero.md;/home/connor/Obsidian/30 Literature notes/bastoulCodeGenerationPolyhedral2004.md;/home/connor/Obsidian/30 Literature notes/Zotero/bastoulCodeGenerationPolyhedral2004 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/bastoulCodeGenerationPolyhedral2004-zotero.md;/home/connor/OneDrive/AppData/Zotero/Bastoul_2004_Code generation in the polyhedral model is easier than you think.pdf}
}

@thesis{bauerLegionProgrammingDistributed2014,
  title = {Legion: {{Programming Distributed Heterogeneous Architectures}} with {{Logical Regions}}},
  author = {Bauer, Michael},
  date = {2014},
  file = {/home/connor/.local/share/zotero/storage/8KXMN8NI/out.pdf}
}

@inproceedings{bauerStructureSlicingExtending2014,
  title = {Structure {{Slicing}}: {{Extending Logical Regions}} with {{Fields}}},
  shorttitle = {Structure {{Slicing}}},
  booktitle = {{{SC14}}: {{International Conference}} for {{High Performance Computing}}, {{Networking}}, {{Storage}} and {{Analysis}}},
  author = {Bauer, Michael and Treichler, Sean and Slaughter, Elliott and Aiken, Alex},
  date = {2014-11},
  pages = {845--856},
  publisher = {IEEE},
  location = {New Orleans, LA, USA},
  doi = {10.1109/SC.2014.74},
  url = {http://ieeexplore.ieee.org/document/7013056/},
  urldate = {2022-09-02},
  abstract = {Applications on modern supercomputers are increasingly limited by the cost of data movement, but mainstream programming systems have few abstractions for describing the structure of a program’s data. Consequently, the burden of managing data movement, placement, and layout currently falls primarily upon the programmer.},
  eventtitle = {{{SC14}}: {{International Conference}} for {{High Performance Computing}}, {{Networking}}, {{Storage}} and {{Analysis}}},
  isbn = {978-1-4799-5500-8 978-1-4799-5499-5},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/8Z7J6RPD/Bauer et al. - 2014 - Structure Slicing Extending Logical Regions with .pdf}
}

@article{bazilevsIsogeometricAnalysisUsing2010,
  title = {Isogeometric Analysis Using {{T-splines}}},
  author = {Bazilevs, Y. and Calo, V.M. and Cottrell, J.A. and Evans, J.A. and Hughes, T.J.R. and Lipton, S. and Scott, M.A. and Sederberg, T.W.},
  date = {2010-01},
  journaltitle = {Computer Methods in Applied Mechanics and Engineering},
  shortjournal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {199},
  number = {5-8},
  pages = {229--263},
  issn = {00457825},
  doi = {10.1016/j.cma.2009.02.036},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0045782509000875},
  urldate = {2024-03-14},
  abstract = {We explore T-splines, a generalization of NURBS enabling local refinement, as a basis for isogeometric analysis. We review T-splines as a surface design methodology and then develop it for engineering analysis applications. We test T-splines on some elementary two-dimensional and three-dimensional fluid and structural analysis problems and attain good results in all cases. We summarize the current status of T-splines, their limitations, and future possibilities.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/966EXVXX/Bazilevs et al. - 2010 - Isogeometric analysis using T-splines.pdf}
}

@article{beiraodaveigaBASICPRINCIPLESVIRTUAL2013,
  title = {{{BASIC PRINCIPLES OF VIRTUAL ELEMENT METHODS}}},
  author = {Beirão Da Veiga, L. and Brezzi, F. and Cangiani, A. and Manzini, G. and Marini, L. D. and Russo, A.},
  date = {2013-01},
  journaltitle = {Mathematical Models and Methods in Applied Sciences},
  shortjournal = {Math. Models Methods Appl. Sci.},
  volume = {23},
  number = {01},
  pages = {199--214},
  issn = {0218-2025, 1793-6314},
  doi = {10.1142/S0218202512500492},
  url = {https://www.worldscientific.com/doi/abs/10.1142/S0218202512500492},
  urldate = {2021-10-22},
  abstract = {We present, on the simplest possible case, what we consider as the very basic features of the (brand new) virtual element method. As the readers will easily recognize, the virtual element method could easily be regarded as the ultimate evolution of the mimetic finite differences approach. However, in their last step they became so close to the traditional finite elements that we decided to use a different perspective and a different name. Now the virtual element spaces are just like the usual finite element spaces with the addition of suitable non-polynomial functions. This is far from being a new idea. See for instance the very early approach of E. Wachspress [A Rational Finite Element Basic (Academic Press, 1975)] or the more recent overview of T.-P. Fries and T. Belytschko [The extended/generalized finite element method: An overview of the method and its applications, Int. J. Numer. Methods Engrg.84 (2010) 253–304]. The novelty here is to take the spaces and the degrees of freedom in such a way that the elementary stiffness matrix can be computed without actually computing these non-polynomial functions, but just using the degrees of freedom. In doing that we can easily deal with complicated element geometries and/or higher-order continuity conditions (like C               1               , C               2               , etc.). The idea is quite general, and could be applied to a number of different situations and problems. Here however we want to be as clear as possible, and to present the simplest possible case that still gives the flavor of the whole idea.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/M6TVTMLU/Beirão Da Veiga et al. - 2013 - BASIC PRINCIPLES OF VIRTUAL ELEMENT METHODS.pdf}
}

@article{berceaStructureexploitingNumberingAlgorithm2016,
  title = {A Structure-Exploiting Numbering Algorithm for Finite Elements Onextruded Meshes, and Its Performance Evaluation in {{Firedrake}}},
  author = {Bercea, Gheorghe-Teodor and McRae, Andrew T. T. and Ham, David A. and Mitchell, Lawrence and Rathgeber, Florian and Nardi, Luigi and Luporini, Fabio and Kelly, Paul H. J.},
  date = {2016-10-27},
  journaltitle = {Geoscientific Model Development},
  shortjournal = {Geosci. Model Dev.},
  volume = {9},
  number = {10},
  pages = {3803--3815},
  issn = {1991-9603},
  doi = {10.5194/gmd-9-3803-2016},
  url = {https://gmd.copernicus.org/articles/9/3803/2016/},
  urldate = {2021-10-12},
  abstract = {We present a generic algorithm for numbering and then efficiently iterating over the data values attached to an extruded mesh. An extruded mesh is formed by replicating an existing mesh, assumed to be unstructured, to form layers of prismatic cells. Applications of extruded meshes include, but are not limited to, the representation of three-dimensional high aspect ratio domains employed by geophysical finite element simulations. These meshes are structured in the extruded direction. The algorithm presented here exploits this structure to avoid the performance penalty traditionally associated with unstructured meshes. We evaluate the implementation of this algorithm in the Firedrake finite element system on a range of low compute intensity operations which constitute worst cases for data layout performance exploration. The experiments show that having structure along the extruded direction enables the cost of the indirect data accesses to be amortized after 10–20 layers as long as the underlying mesh is well ordered. We characterize the resulting spatial and temporal reuse in a representative set of both continuous-Galerkin and discontinuous-Galerkin discretizations. On meshes with realistic numbers of layers the performance achieved is between 70 and 90 \% of a theoretical hardware-specific limit.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/H9FLANR7/Bercea et al_2016_A structure-exploiting numbering algorithm for finite elements onextruded.pdf}
}

@article{bergenMassivelyParallelMultigrid2006,
  title = {A {{Massively Parallel Multigrid Method}} for {{Finite Elements}}},
  author = {Bergen, B. and Gradl, T. and Hulsemann, F. and Rude, U.},
  date = {2006-11},
  journaltitle = {Computing in Science \& Engineering},
  shortjournal = {Comput. Sci. Eng.},
  volume = {8},
  number = {6},
  pages = {56--62},
  issn = {1521-9615},
  doi = {10.1109/MCSE.2006.102},
  url = {http://ieeexplore.ieee.org/document/1717316/},
  urldate = {2023-04-03},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/2DQ8R5FJ/Bergen et al. - 2006 - A Massively Parallel Multigrid Method for Finite E.pdf}
}

@unpublished{bernsteinDifferentiatingTensorLanguage2020,
  title = {Differentiating a {{Tensor Language}}},
  author = {Bernstein, Gilbert and Mara, Michael and Li, Tzu-Mao and Maclaurin, Dougal and Ragan-Kelley, Jonathan},
  date = {2020-08-25},
  eprint = {2008.11256},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2008.11256},
  urldate = {2022-04-19},
  abstract = {How does one compile derivatives of tensor programs, such that the resulting code is purely functional (hence easier to optimize and parallelize) and provably efficient relative to the original program? We show that naively differentiating tensor code---as done in popular systems like Tensorflow and PyTorch---can cause asymptotic slowdowns in pathological cases, violating the Cheap Gradients Principle. However, all existing automatic differentiation methods that guarantee this principle (for variable size data) do so by relying on += mutation through aliases/pointers---which complicates downstream optimization. We provide the first purely functional, provably efficient, adjoint/reverse-mode derivatives of array/tensor code by explicitly accounting for sparsity. We do this by focusing on the indicator function from Iverson's APL. We also introduce a new "Tensor SSA" normal form and a new derivation of reverse-mode automatic differentiation based on the universal property of inner-products.},
  keywords = {Computer Science - Graphics,Computer Science - Programming Languages},
  file = {/home/connor/OneDrive/AppData/Zotero/Bernstein et al_2020_Differentiating a Tensor Language.pdf;/home/connor/.local/share/zotero/storage/FEN7SNL3/2008.html}
}

@article{bernsteinEbbDSLPhysical2016,
  title = {Ebb: {{A DSL}} for {{Physical Simulation}} on {{CPUs}} and {{GPUs}}},
  shorttitle = {Ebb},
  author = {Bernstein, Gilbert Louis and Shah, Chinmayee and Lemire, Crystal and Devito, Zachary and Fisher, Matthew and Levis, Philip and Hanrahan, Pat},
  date = {2016-05-25},
  journaltitle = {ACM Transactions on Graphics},
  shortjournal = {ACM Trans. Graph.},
  volume = {35},
  number = {2},
  pages = {1--12},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/2892632},
  url = {https://dl.acm.org/doi/10.1145/2892632},
  urldate = {2022-03-28},
  abstract = {Designing programming environments for physical simulation is challenging because simulations rely on diverse algorithms and geometric domains. These challenges are compounded when we try to run efficiently on heterogeneous parallel architectures. We present Ebb, a Domain-Specific Language (DSL) for simulation, that runs efficiently on both CPUs and GPUs. Unlike previous DSLs, Ebb uses a three-layer architecture to separate (1) simulation code, (2) definition of data structures for geometric domains, and (3) runtimes supporting parallel architectures. Different geometric domains are implemented as libraries that use a common, unified, relational data model. By structuring the simulation framework in this way, programmers implementing simulations can focus on the physics and algorithms for each simulation without worrying about their implementation on parallel computers. Because the geometric domain libraries are all implemented using a common runtime based on relations, new geometric domains can be added as needed, without specifying the details of memory management, mapping to different parallel architectures, or having to expand the runtime’s interface.             We evaluate Ebb by comparing it to several widely used simulations, demonstrating comparable performance to handwritten GPU code where available, and surpassing existing CPU performance optimizations by up to 9 × when no GPU code exists.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/7IJQ65UP/Bernstein et al_2016_Ebb.pdf}
}

@unpublished{betteridgeCodeGenerationProductive2021,
  title = {Code Generation for Productive Portable Scalable Finite Element Simulation in {{Firedrake}}},
  author = {Betteridge, Jack D. and Farrell, Patrick E. and Ham, David A.},
  date = {2021-04-16},
  eprint = {2104.08012},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2104.08012},
  urldate = {2021-06-22},
  abstract = {Creating scalable, high performance PDE-based simulations requires a suitable combination of discretizations, differential operators, preconditioners and solvers. The required combination changes with the application and with the available hardware, yet software development time is a severely limited resource for most scientists and engineers. Here we demonstrate that generating simulation code from a high-level Python interface provides an effective mechanism for creating high performance simulations from very few lines of user code. We demonstrate that moving from one supercomputer to another can require significant algorithmic changes to achieve scalable performance, but that the code generation approach enables these algorithmic changes to be achieved with minimal development effort.},
  langid = {english},
  keywords = {Computer Science - Mathematical Software},
  file = {/home/connor/.local/share/zotero/storage/M3YLEMJ5/Betteridge et al_2021_Code generation for productive portable scalable finite element simulation in.pdf}
}

@thesis{betteridgeEfficientEllipticSolvers2019,
  title = {Efficient Elliptic Solvers for Higher Order {{DG}} Discretisations on Modern Architectures and Applications in Atmospheric Modelling},
  author = {Betteridge, Jack},
  date = {2019-11},
  institution = {University of Bath},
  abstract = {For problems in Numerical Weather Prediction (NWP), the time to produce a solution is a critical factor. Semi-implicit timestepping methods can speed up geophysical fluid dynam- ics simulations by taking larger timesteps than explicit methods. This is possible because they treat the fast (but physically less energetic) waves implicitly, and the timestep size is not restricted by the CFL condition for these waves. One disadvantage of this method is that an expensive linear solve must be performed at every timestep. However, using an effective preconditioner for an iterative method significantly reduces the computational cost of this solve, making a semi-implicit scheme faster overall. Higher order Discontinuous Galerkin (DG) methods are known for having high arith- metic intensity making them well suited for modern HPC hardware. For smooth solutions higher order DG methods can be particularly efficient since errors decrease with a power of the polynomial degree. However, the linear problems which arise in semi-implicit timestep- pers if DG methods are used for the spatial discretisation are difficult to precondition due to the large number of coupled degrees of freedom. This coupling arises since the numer- ical flux introduces off diagonal artificial diffusion terms. Those terms would result in a dense operator if the standard Schur complement reduction to an elliptic system is used. In this thesis we use a hybridised DG (HDG) method to eliminate the original coupling and instead couple the system of equations to a sparse operator on the trace space, which is easier to precondition. This is achieved by considering the numerical flux variables which only lie on the facets of the mesh. Recent work by Kang, Giraldo and Bui-Thanh[34] solves the resulting system with a direct method. However, this becomes impractical for high resolution simulations due to the cost of this direct solve. Instead, in this thesis, we solve the resulting system using a non-nested geometric multigrid technique. In this thesis we discretise and solve the non-linear shallow water equations, an im- portant model system in geophysical fluid dynamics, using both DG and HDG methods. We develop a bespoke non-nested multigrid preconditioner based on work by Gopalakr- ishnan and Tan [31] and implement it using Firedrake, a Python framework for solving finite element problems via code generation. Hybridisation is performed using the Slate language, which is a part of Firedrake. We demonstrate the effectiveness of our hybridised DG scheme with non-nested multigrid preconditioner for a range of semi-implicit IMEX timesteppers and show these provide significant improvement over traditional DG methods with the same timestepping.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/RKD89KM5/Betteridge_2019_Efficient elliptic solvers for higher order DG discretisations on modern.pdf}
}

@article{beyTetrahedralGridRefinement1995,
  title = {Tetrahedral Grid Refinement},
  author = {Bey, J.},
  date = {1995},
  pages = {24},
  abstract = {Zusammenfassung Tetrahedral Grid Refinement. We present a refinement algorithm for unstructured tetrahedral grids which generates possibly highly non-uniform but nevertheless consistent (closed) and stable triangulations. Therefore we first define some local regular and irregular refinement rules that are applied to single elements. The global refinement algorithm then describes how these local rules can be combined and rearranged in order to ensure consistency as well as stability. It is given in a rather general form and includes also grid coarsening.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/SQH3ECEG/Tetrahedral grid refinement.pdf}
}

@article{bientinesiTensorComputationsApplications,
  title = {Tensor {{Computations}}: {{Applications}} and {{Optimization}}},
  author = {Bientinesi, Paolo and Ham, David and Huang, Furong and Kelly, Paul H J},
  pages = {14},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/FKCFJCQ2/Bientinesi et al. - Tensor Computations Applications and Optimization.pdf}
}

@unpublished{bienzModelingDataMovement2021,
  title = {Modeling {{Data Movement Performance}} on {{Heterogeneous Architectures}}},
  author = {Bienz, Amanda and Olson, Luke N. and Gropp, William D. and Lockhart, Shelby},
  date = {2021-07-16},
  eprint = {2010.10378},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2010.10378},
  urldate = {2021-07-20},
  abstract = {The cost of data movement on parallel systems varies greatly with machine architecture, job partition, and nearby jobs. Performance models that accurately capture the cost of data movement provide a tool for analysis, allowing for communication bottlenecks to be pinpointed. Modern heterogeneous architectures yield increased variance in data movement as there are a number of viable paths for inter-GPU communication. In this paper, we present performance models for the various paths of inter-node communication on modern heterogeneous architectures, including the trade-off between GPUDirect communication and copying to CPUs. Furthermore, we present a novel optimization for inter-node communication based on these models, utilizing all available CPU cores per node. Finally, we show associated performance improvements for MPI collective operations.},
  langid = {english},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing}},
  file = {/home/connor/.local/share/zotero/storage/QHMIBTND/Bienz et al. - 2021 - Modeling Data Movement Performance on Heterogeneou.pdf}
}

@online{bisbasAutomatedMPICode2023,
  title = {Automated {{MPI}} Code Generation for Scalable Finite-Difference Solvers},
  author = {Bisbas, George and Nelson, Rhodri and Louboutin, Mathias and Kelly, Paul H. J. and Luporini, Fabio and Gorman, Gerard},
  date = {2023-12-20},
  eprint = {2312.13094},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2312.13094},
  urldate = {2024-01-03},
  abstract = {Partial differential equations (PDEs) are crucial in modelling diverse phenomena across scientific disciplines, including seismic and medical imaging, computational fluid dynamics, image processing, and neural networks. Solving these PDEs on a large scale is an intricate and time-intensive process that demands careful tuning. This paper introduces automated code-generation techniques specifically tailored for distributed memory parallelism (DMP) to solve explicit finite-difference (FD) stencils at scale, a fundamental challenge in numerous scientific applications. These techniques are implemented and integrated into the Devito DSL and compiler framework, a well-established solution for automating the generation of FD solvers based on a high-level symbolic math input. Users benefit from modelling simulations at a high-level symbolic abstraction and effortlessly harnessing HPC-ready distributed-memory parallelism without altering their source code. This results in drastic reductions both in execution time and developer effort. While the contributions of this work are implemented and integrated within the Devito framework, the DMP concepts and the techniques applied are generally applicable to any FD solvers. A comprehensive performance evaluation of Devito’s DMP via MPI demonstrates highly competitive weak and strong scaling on the Archer2 supercomputer, demonstrating the effectiveness of the proposed approach in meeting the demands of large-scale scientific simulations.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Mathematical Software,Computer Science - Performance},
  file = {/home/connor/.local/share/zotero/storage/MBKUP7AW/Bisbas et al. - 2023 - Automated MPI code generation for scalable finite-.pdf}
}

@online{bisbasSharedCompilationStack2024,
  title = {A Shared Compilation Stack for Distributed-Memory Parallelism in Stencil {{DSLs}}},
  author = {Bisbas, George and Lydike, Anton and Bauer, Emilien and Brown, Nick and Fehr, Mathieu and Mitchell, Lawrence and Rodriguez-Canal, Gabriel and Jamieson, Maurice and Kelly, Paul H. J. and Steuwer, Michel and Grosser, Tobias},
  date = {2024-04-02},
  eprint = {2404.02218},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2404.02218},
  urldate = {2024-04-05},
  abstract = {Domain Specific Languages (DSLs) increase programmer productivity and provide high performance. Their targeted abstractions allow scientists to express problems at a high level, providing rich details that optimizing compilers can exploit to target current- and next-generation supercomputers. The convenience and performance of DSLs come with significant development and maintenance costs. The siloed design of DSL compilers and the resulting inability to benefit from shared infrastructure cause uncertainties around longevity and the adoption of DSLs at scale. By tailoring the broadly-adopted MLIR compiler framework to HPC, we bring the same synergies that the machine learning community already exploits across their DSLs (e.g. Tensorflow, PyTorch) to the finite-difference stencil HPC community. We introduce new HPC-specific abstractions for message passing targeting distributed stencil computations. We demonstrate the sharing of common components across three distinct HPC stencil-DSL compilers: Devito, PSyclone, and the Open Earth Compiler, showing that our framework generates high-performance executables based upon a shared compiler ecosystem.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Mathematical Software},
  file = {/home/connor/.local/share/zotero/storage/EM54HCCK/Bisbas et al. - 2024 - A shared compilation stack for distributed-memory .pdf}
}

@article{bittencourtNonnestedMultigridMethods2001,
  title = {Nonnested Multigrid Methods for Linear Problems: {{Nonnested Multigrid Methods}} for {{Linear Problems}}},
  shorttitle = {Nonnested Multigrid Methods for Linear Problems},
  author = {Bittencourt, Marco L. and Douglas, Craig C. and Feijóo, Raúl A.},
  date = {2001-07},
  journaltitle = {Numerical Methods for Partial Differential Equations},
  shortjournal = {Numer. Methods Partial Differential Eq.},
  volume = {17},
  number = {4},
  pages = {313--331},
  issn = {0749159X},
  doi = {10.1002/num.1013},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/num.1013},
  urldate = {2021-11-30},
  abstract = {This paper presents an application of non-nested and unstructured multigrid methods to linear elastic problems. A variational formulation for transfer operators and some multigrid strategies, including adaptive algorithms, are presented. Expressions for the performance evaluation of multigrid strategies and its comparison with direct and preconditioned conjugate gradient algorithms are also presented. A C++ implementation of the multigrid algorithms and its quadtree and octree data structures are discussed. Some two and three dimensional elasticity examples are analyzed.},
  langid = {english},
  file = {/home/connor/OneDrive/AppData/Zotero/Bittencourt et al_2001_Nonnested multigrid methods for linear problems.pdf}
}

@article{boltenAlgebraicDescriptionAutomatic2017,
  title = {Algebraic Description and Automatic Generation of Multigrid Methods in {{SPIRAL}}},
  author = {Bolten, Matthias and Franchetti, Franz and Kelly, Paul H. J. and Lengauer, Christian and Mohr, Marcus},
  date = {2017-09-10},
  journaltitle = {Concurrency and Computation: Practice and Experience},
  shortjournal = {Concurrency Computat.: Pract. Exper.},
  volume = {29},
  number = {17},
  issn = {1532-0626, 1532-0634},
  doi = {10.1002/cpe.4105},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/cpe.4105},
  urldate = {2022-03-18},
  abstract = {SPIRAL is an autotuning, program generation and code synthesis system that offers a fully automatic generation of highly optimized target codes, customized for the specific execution platform at hand. Initially, SPIRAL was targeted at problem domains in digital signal processing, later also at basic linear algebra. We open SPIRAL up to a new, practically relevant and challenging domain: multigrid solvers. SPIRAL is driven by algebraic transformation rules. We specify a set of such rules for a simple multigrid solver with a Richardson smoother for a discretized square 2D Poisson equation with Dirichlet boundary conditions. We present the target code that SPIRAL generates in static single-assignment form and discuss its performance. While this example required no changes of or extensions to the SPIRAL system, more complex multigrid solvers may require small adaptations.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/FKZPGIQ5/Bolten et al. - 2017 - Algebraic description and automatic generation of .pdf}
}

@thesis{bouzianiDifferentiableProgrammingPDE2023,
  title = {Differentiable Programming across the {{PDE}} and {{Machine Learning}} Barrier},
  author = {Bouziani, Nacime},
  date = {2023},
  langid = {english},
  keywords = {\_tablet},
  file = {/home/connor/.local/share/zotero/storage/97D2MRT4/Bouziani_Differentiable programming across the PDE and Machine Learning barrier.pdf}
}

@online{bouzianiEscapingAbstractionForeign2021,
  title = {Escaping the Abstraction: A Foreign Function Interface for the {{Unified Form Language}} [{{UFL}}]},
  shorttitle = {Escaping the Abstraction},
  author = {Bouziani, Nacime and Ham, David A.},
  date = {2021-11-01},
  eprint = {2111.00945},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2111.00945},
  urldate = {2023-01-12},
  abstract = {High level domain specific languages for the finite element method underpin high productivity programming environments for simulations based on partial differential equations (PDE) while employing automatic code generation to achieve high performance. However, a limitation of this approach is that it does not support operators that are not directly expressible in the vector calculus. This is critical in applications where PDEs are not enough to accurately describe the physical problem of interest. The use of deep learning techniques have become increasingly popular in filling this knowledge gap, for example to include features not represented in the differential equations, or closures for unresolved spatiotemporal scales. We introduce an interface within the Firedrake finite element system that enables a seamless interface with deep learning models. This new feature composes with the automatic differentiation capabilities of Firedrake, enabling the automated solution of inverse problems. Our implementation interfaces with PyTorch and can be extended to other machine learning libraries. The resulting framework supports complex models coupling PDEs and deep learning whilst maintaining separation of concerns between application scientists and software experts.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Mathematical Software,Mathematics - Numerical Analysis},
  file = {/home/connor/.local/share/zotero/storage/H2LCS6Z2/Bouziani and Ham - 2021 - Escaping the abstraction a foreign function inter.pdf}
}

@online{bouzianiPhysicsdrivenMachineLearning2023,
  title = {Physics-Driven Machine Learning Models Coupling {{PyTorch}} and {{Firedrake}}},
  author = {Bouziani, Nacime and Ham, David A.},
  date = {2023-03-14},
  eprint = {2303.06871},
  eprinttype = {arXiv},
  eprintclass = {physics},
  url = {http://arxiv.org/abs/2303.06871},
  urldate = {2023-03-23},
  abstract = {Partial differential equations (PDEs) are central to describing and modelling complex physical systems that arise in many disciplines across science and engineering. However, in many realistic applications PDE modelling provides an incomplete description of the physics of interest. PDE-based machine learning techniques are designed to address this limitation. In this approach, the PDE is used as an inductive bias enabling the coupled model to rely on fundamental physical laws while requiring less training data. The deployment of high-performance simulations coupling PDEs and machine learning to complex problems necessitates the composition of capabilities provided by machine learning and PDE-based frameworks. We present a simple yet effective coupling between the machine learning framework PyTorch and the PDE system Firedrake that provides researchers, engineers and domain specialists with a high productive way of specifying coupled models while only requiring trivial changes to existing code.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Machine Learning,Computer Science - Mathematical Software,Mathematics - Numerical Analysis,Physics - Computational Physics},
  file = {/home/connor/.local/share/zotero/storage/HSTHEL6R/Bouziani and Ham - 2023 - Physics-driven machine learning models coupling Py.pdf}
}

@book{brennerMathematicalTheoryFinite2008,
  title = {The Mathematical Theory of Finite Element Methods},
  author = {Brenner, Susanne C. and Scott, Larkin Ridgway},
  date = {2008},
  series = {Texts in Applied Mathematics},
  edition = {Third edition},
  number = {15},
  publisher = {Springer},
  location = {New York, NY},
  isbn = {978-0-387-75934-0 978-0-387-75933-3},
  langid = {english},
  pagetotal = {397},
  annotation = {OCLC: 254557294},
  file = {/home/connor/Obsidian/30 Literature notes/brennerMathematicalTheoryFinite2008-zotero.md;/home/connor/Obsidian/30 Literature notes/brennerMathematicalTheoryFinite2008.md;/home/connor/Obsidian/30 Literature notes/Zotero/brennerMathematicalTheoryFinite2008-zotero.md;/home/connor/OneDrive/AppData/Zotero/Brenner_Scott_2008_The mathematical theory of finite element methods.pdf}
}

@book{briggsMultigridTutorial2000,
  title = {A Multigrid Tutorial},
  author = {Briggs, William L. and Henson, Van Emden and McCormick, S. F.},
  date = {2000},
  edition = {2nd ed},
  publisher = {{Society for Industrial and Applied Mathematics}},
  location = {Philadelphia, PA},
  isbn = {978-0-89871-462-3},
  pagetotal = {193},
  keywords = {{Differential equations, Partial},Multigrid methods (Numerical analysis),Numerical solutions},
  file = {/home/connor/.local/share/zotero/storage/4KMIXPUT/William L. Briggs, Van Emden Henson, Steve F. McCormick - A multigrid tutorial (2000, Society for Industrial and Applied Mathematics) - libgen.lc.djvu}
}

@article{brownLibCEEDFastAlgebra2021,
  title = {{{libCEED}}: {{Fast}} Algebra for High-Order Element-Based Discretizations},
  shorttitle = {{{libCEED}}},
  author = {Brown, Jed and Abdelfattah, Ahmad and Barra, Valeria and Beams, Natalie and Camier, Jean-Sylvain and Dobrev, Veselin and Dudouit, Yohann and Ghaffari, Leila and Kolev, Tzanio and Medina, David and Pazner, Will and Ratnayaka, Thilina and Thompson, Jeremy and Tomov, Stan},
  date = {2021-07-09},
  journaltitle = {Journal of Open Source Software},
  shortjournal = {JOSS},
  volume = {6},
  number = {63},
  pages = {2945},
  issn = {2475-9066},
  doi = {10.21105/joss.02945},
  url = {https://joss.theoj.org/papers/10.21105/joss.02945},
  urldate = {2022-02-04},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/XXQU6KYI/Brown et al_2021_libCEED.pdf}
}

@unpublished{brownPerformancePortableSolid2022,
  title = {Performance {{Portable Solid Mechanics}} via {{Matrix-Free}} \$p\$-{{Multigrid}}},
  author = {Brown, Jed and Barra, Valeria and Beams, Natalie and Ghaffari, Leila and Knepley, Matthew and Moses, William and Shakeri, Rezgar and Stengel, Karen and Thompson, Jeremy L. and Zhang, Junchao},
  date = {2022-04-04},
  eprint = {2204.01722},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2204.01722},
  urldate = {2022-04-06},
  abstract = {Finite element analysis of solid mechanics is a foundational tool of modern engineering, with low-order finite element methods and assembled sparse matrices representing the industry standard for implicit analysis. We use performance models and numerical experiments to demonstrate that high-order methods greatly reduce the costs to reach engineering tolerances while enabling effective use of GPUs. We demonstrate the reliability, efficiency, and scalability of matrix-free \$p\$-multigrid methods with algebraic multigrid coarse solvers through large deformation hyperelastic simulations of multiscale structures. We investigate accuracy, cost, and execution time on multi-node CPU and GPU systems for moderate to large models using AMD MI250X (OLCF Crusher), NVIDIA A100 (NERSC Perlmutter), and V100 (LLNL Lassen and OLCF Summit), resulting in order of magnitude efficiency improvements over a broad range of model properties and scales. We discuss efficient matrix-free representation of Jacobians and demonstrate how automatic differentiation enables rapid development of nonlinear material models without impacting debuggability and workflows targeting GPUs.},
  keywords = {{Computer Science - Computational Engineering, Finance, and Science},{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Mathematical Software,D.1.3,G.1.10,G.1.5,G.1.8,G.4,J.2,J.6,Mathematics - Numerical Analysis},
  file = {/home/connor/OneDrive/AppData/Zotero/Brown et al_2022_Performance Portable Solid Mechanics via Matrix-Free $p$-Multigrid.pdf;/home/connor/.local/share/zotero/storage/HAMAYWSG/2204.html}
}

@article{brownRuntimeExtensibilityAnything,
  title = {Run-Time Extensibility: Anything Less Is Unsustainable},
  author = {Brown, Jed and Knepley, Matthew G and Smith, Barry F},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/XQ9JS2NN/Brown et al. - Run-time extensibility anything less is unsustain.pdf}
}

@online{brownRuntimeExtensibilityLibrarization2014,
  title = {Run-Time Extensibility and Librarization of Simulation Software},
  author = {Brown, Jed and Knepley, Matthew G. and Smith, Barry F.},
  date = {2014-07-10},
  eprint = {1407.2905},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1407.2905},
  urldate = {2023-03-23},
  abstract = {Build-time configuration and environment assumptions are hampering progress and usability in scientific software. That which would be utterly unacceptable in non-scientific software somehow passes for the norm in scientific packages. The community needs reusable software packages that are easy use and flexible enough to accommodate next-generation simulation and analysis demands.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {{Computer Science - Computational Engineering, Finance, and Science},Computer Science - Mathematical Software,Computer Science - Software Engineering},
  file = {/home/connor/.local/share/zotero/storage/M9UQWRQ4/Brown et al. - 2014 - Run-time extensibility and librarization of simula.pdf}
}

@article{brownStarForestsParallel2011,
  title = {Star Forests as a Parallel Communication Model},
  author = {Brown, Jed},
  date = {2011-12-25},
  pages = {6},
  abstract = {Many useful communication patterns can be represented as communication of data between roots and leaves of a star forest. Such communication graphs are easy for a user to specify (by naming the root node for each leaf) and map naturally to one-sided communication primitives provided by the MPI-2 standard and due to be enhanced for MPI-3. If a two-sided representation of the graph is desired, it can easily be constructed. In this note, we describe the communication model, implementation in PETSc, and demonstrate algorithms using star forests.},
  langid = {english},
  file = {/home/connor/Obsidian/30 Literature notes/brownStarForestsParallel2011-zotero.md;/home/connor/Obsidian/30 Literature notes/brownStarForestsParallel2011.md;/home/connor/Obsidian/30 Literature notes/Zotero/brownStarForestsParallel2011-zotero.md;/home/connor/OneDrive/AppData/Zotero/Brown_2011_Star forests as a parallel communication model.pdf}
}

@article{bruneUnstructuredGeometricMultigrid2013,
  title = {Unstructured {{Geometric Multigrid}} in {{Two}} and {{Three Dimensions}} on {{Complex}} and {{Graded Meshes}}},
  author = {Brune, Peter R. and Knepley, Matthew G. and Scott, L. Ridgway},
  date = {2013-01},
  journaltitle = {SIAM Journal on Scientific Computing},
  shortjournal = {SIAM J. Sci. Comput.},
  volume = {35},
  number = {1},
  pages = {A173-A191},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/110827077},
  url = {http://epubs.siam.org/doi/10.1137/110827077},
  urldate = {2022-08-12},
  abstract = {The use of multigrid and related preconditioners with the finite element method is often limited by the difficulty of applying the algorithm effectively to a problem, especially when the domain has a complex shape or the mesh has adaptive refinement. We introduce a simplification of a general topologically motivated mesh coarsening algorithm for use in creating hierarchies of meshes for geometric unstructured multigrid methods. The connections between the guarantees of this technique and the quality criteria necessary for multigrid methods for nonquasi-uniform problems are noted. The implementation details, in particular those related to coarsening, remeshing, and interpolation, are discussed. Computational tests on pathological test cases from adaptive finite element methods show the performance of the technique.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/KBQXD4BB/Brune et al_2013_Unstructured Geometric Multigrid in Two and Three Dimensions on Complex and.pdf}
}

@book{buelerPETScPartialDifferential2020,
  title = {{{PETSc}} for Partial Differential Equations: {{Numerical}} Solutions in {{C}} and {{Python}}},
  author = {Bueler, Ed},
  date = {2020-01}
}

@book{bungartzSoftwareExascaleComputing2020,
  title = {Software for {{Exascale Computing}} - {{SPPEXA}} 2016-2019},
  editor = {Bungartz, Hans-Joachim and Reiz, Severin and Uekermann, Benjamin and Neumann, Philipp and Nagel, Wolfgang E.},
  date = {2020},
  series = {Lecture {{Notes}} in {{Computational Science}} and {{Engineering}}},
  volume = {136},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-47956-5},
  url = {http://link.springer.com/10.1007/978-3-030-47956-5},
  urldate = {2022-08-19},
  isbn = {978-3-030-47955-8 978-3-030-47956-5},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/XEK6AG67/Bungartz et al. - 2020 - Software for Exascale Computing - SPPEXA 2016-2019.pdf}
}

@unpublished{burnettPerformanceEvaluationMixedPrecision2021,
  title = {Performance {{Evaluation}} of {{Mixed-Precision Runge-Kutta Methods}}},
  author = {Burnett, Ben and Gottlieb, Sigal and Grant, Zachary J. and Heryudono, Alfa},
  date = {2021-07-07},
  eprint = {2107.03357},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2107.03357},
  urldate = {2021-07-08},
  abstract = {Additive Runge-Kutta methods designed for preserving highly accurate solutions in mixed-precision computation were proposed and analyzed in [8]. These specially designed methods use reduced precision for the implicit computations and full precision for the explicit computations. We develop a FORTRAN code to solve a nonlinear system of ordinary differential equations using the mixed precision additive Runge-Kutta (MP-ARK) methods on IBM POWER9 and Intel x86 64 chips. The convergence, accuracy, runtime, and energy consumption of these methods is explored. We show that these MP-ARK methods efficiently produce accurate solutions with significant reductions in runtime (and by extension energy consumption).},
  langid = {english},
  keywords = {Computer Science - Performance,Mathematics - Numerical Analysis},
  file = {/home/connor/.local/share/zotero/storage/UNKN3LLM/Burnett et al. - 2021 - Performance Evaluation of Mixed-Precision Runge-Ku.pdf}
}

@article{burnsDedalusFlexibleFramework2020,
  title = {Dedalus: {{A Flexible Framework}} for {{Numerical Simulations}} with {{Spectral Methods}}},
  shorttitle = {Dedalus},
  author = {Burns, Keaton J. and Vasil, Geoffrey M. and Oishi, Jeffrey S. and Lecoanet, Daniel and Brown, Benjamin P.},
  date = {2020-04-23},
  journaltitle = {Physical Review Research},
  shortjournal = {Phys. Rev. Research},
  volume = {2},
  number = {2},
  eprint = {1905.10388},
  eprinttype = {arXiv},
  eprintclass = {astro-ph, physics:physics},
  pages = {023068},
  issn = {2643-1564},
  doi = {10.1103/PhysRevResearch.2.023068},
  url = {http://arxiv.org/abs/1905.10388},
  urldate = {2024-05-13},
  abstract = {Numerical solutions of partial differential equations enable a broad range of scientific research. The Dedalus Project is a flexible, open-source, parallelized computational framework for solving general partial differential equations using spectral methods. Dedalus translates plain-text strings describing partial differential equations into efficient solvers. This paper details the numerical method that enables this translation, describes the design and implementation of the codebase, and illustrates its capabilities with a variety of example problems. The numerical method is a first-order generalized tau formulation that discretizes equations into banded matrices. This method is implemented with an object-oriented design. Classes for spectral bases and domains manage the discretization and automatic parallel distribution of variables. Discretized fields and mathematical operators are symbolically manipulated with a basic computer algebra system. Initial value, boundary value, and eigenvalue problems are efficiently solved using high-performance linear algebra, transform, and parallel communication libraries. Custom analysis outputs can also be specified in plain text and stored in self-describing portable formats. The performance of the code is evaluated with a parallel scaling benchmark and a comparison to a finite-volume code. The features and flexibility of the codebase are illustrated by solving several examples: the nonlinear Schrodinger equation on a graph, a supersonic magnetohydrodynamic vortex, quasigeostrophic flow, Stokes flow in a cylindrical annulus, normal modes of a radiative atmosphere, and diamagnetic levitation. The Dedalus code and the example problems are available online at http://dedalus-project.org/.},
  langid = {english},
  keywords = {Astrophysics - Instrumentation and Methods for Astrophysics,Physics - Computational Physics,Physics - Fluid Dynamics},
  file = {/home/connor/.local/share/zotero/storage/R2ZBKUNI/Burns et al. - 2020 - Dedalus A Flexible Framework for Numerical Simula.pdf}
}

@article{bursteddeP4estScalableAlgorithms2011,
  title = {P4est : {{Scalable Algorithms}} for {{Parallel Adaptive Mesh Refinement}} on {{Forests}} of {{Octrees}}},
  shorttitle = {P4est},
  author = {Burstedde, Carsten and Wilcox, Lucas C. and Ghattas, Omar},
  date = {2011-01},
  journaltitle = {SIAM Journal on Scientific Computing},
  shortjournal = {SIAM J. Sci. Comput.},
  volume = {33},
  number = {3},
  pages = {1103--1133},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/100791634},
  url = {http://epubs.siam.org/doi/10.1137/100791634},
  urldate = {2022-09-15},
  abstract = {We present scalable algorithms for parallel adaptive mesh refinement and coarsening (AMR), partitioning, and 2:1 balancing on computational domains composed of multiple connected two-dimensional quadtrees or three-dimensional octrees, referred to as a forest of octrees. By distributing the union of octants from all octrees in parallel, we combine the high scalability proven previously for adaptive single-octree algorithms with the geometric flexibility that can be achieved by arbitrarily connected hexahedral macromeshes, in which each macroelement is the root of an adapted octree. A key concept of our approach is an encoding scheme of the interoctree connectivity that permits arbitrary relative orientations between octrees. Based on this encoding we develop interoctree transformations of octants. These form the basis for high-level parallel octree algorithms, which are designed to interact with an application code such as a numerical solver for partial differential equations. We have implemented and tested these algorithms in the p4est software library. We demonstrate the parallel scalability of p4est on its own and in combination with two geophysics codes. Using p4est we generate and adapt multioctree meshes with up to 5.13 × 1011 octants on as many as 220,320 CPU cores and execute the 2:1 balance algorithm in less than 10 seconds per million octants per process.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/8ZWLZ679/Burstedde et al_2011_p4est.pdf}
}

@article{chanCollectiveCommunicationTheory2007,
  title = {Collective Communication: Theory, Practice, and Experience},
  shorttitle = {Collective Communication},
  author = {Chan, Ernie and Heimlich, Marcel and Purkayastha, Avi and Van De Geijn, Robert},
  date = {2007-09-10},
  journaltitle = {Concurrency and Computation: Practice and Experience},
  shortjournal = {Concurrency and Computation},
  volume = {19},
  number = {13},
  pages = {1749--1783},
  issn = {1532-0626, 1532-0634},
  doi = {10.1002/cpe.1206},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/cpe.1206},
  urldate = {2023-12-08},
  abstract = {We discuss the design and high-performance implementation of collective communications operations on distributed-memory computer architectures. Using a combination of known techniques (many of which were first proposed in the 1980s and early 1990s) along with careful exploitation of communication modes supported by MPI, we have developed implementations that have improved performance in most situations compared to those currently supported by public domain implementations of MPI such as MPICH. Performance results from a large Intel Xeon/Pentium 4 (R) processor cluster are included. Copyright © 2007 John Wiley \& Sons, Ltd.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/SWP2KU6M/Chan et al. - 2007 - Collective communication theory, practice, and ex.pdf}
}

@article{changComparativeStudyFinite2018,
  title = {Comparative {{Study}} of {{Finite Element Methods Using}} the {{Time-Accuracy-Size}}({{TAS}}) {{Spectrum Analysis}}},
  author = {Chang, Justin and Fabien, Maurice S. and Knepley, Matthew G. and Mills, Richard T.},
  date = {2018-01},
  journaltitle = {SIAM Journal on Scientific Computing},
  shortjournal = {SIAM J. Sci. Comput.},
  volume = {40},
  number = {6},
  pages = {C779-C802},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/18M1172260},
  url = {https://epubs.siam.org/doi/10.1137/18M1172260},
  urldate = {2020-11-26},
  abstract = {We present a performance analysis appropriate for comparing algorithms using different numerical discretizations. By taking into account the total time-to-solution, numerical accuracy with respect to an error norm, and the computation rate, a cost-benefit analysis can be performed to determine which algorithm and discretization are particularly suited for an application. This work extends the performance spectrum model in [J. Chang et al., Concurrency and Computation Practice and Experience, 30 (2017), e4401] for interpretation of hardware and algorithmic trade-offs in numerical PDE simulation. As a proof-of-concept, popular finite element software packages are used to illustrate this analysis for Poisson's equation.},
  langid = {english},
  keywords = {deal.ii,fenics,firedrake,strong-scaling,time-accuracy-size-analysis},
  file = {/home/connor/Obsidian/30 Literature notes/changComparativeStudyFinite2018-zotero.md;/home/connor/Obsidian/30 Literature notes/changComparativeStudyFinite2018.md;/home/connor/Obsidian/30 Literature notes/Zotero/changComparativeStudyFinite2018-zotero.md;/home/connor/OneDrive/AppData/Zotero/Chang et al_2018_Comparative Study of Finite Element Methods Using the Time-Accuracy-Size(TAS).pdf}
}

@article{changPerformanceSpectrumParallel2018,
  title = {A Performance Spectrum for Parallel Computational Frameworks That Solve {{PDEs}}},
  author = {Chang, J. and Nakshatrala, K.B. and Knepley, M.G. and Johnsson, L.},
  date = {2018-06-10},
  journaltitle = {Concurrency and Computation: Practice and Experience},
  shortjournal = {Concurrency Computat Pract Exper},
  volume = {30},
  number = {11},
  issn = {1532-0626, 1532-0634},
  doi = {10.1002/cpe.4401},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/cpe.4401},
  urldate = {2021-06-18},
  abstract = {Important computational physics problems are often large-scale in nature, and it is highly desirable to have robust and high performing computational frameworks that can quickly address these problems. However, it is no trivial task to determine whether a computational framework is performing efficiently or is scalable. The aim of this paper is to present various strategies for better understanding the performance of any parallel computational frameworks for solving PDEs. Important performance issues that negatively impact time-to-solution are discussed, and we propose a performance spectrum analysis that can enhance one's understanding of critical aforementioned performance issues. As proof of concept, we examine commonly used finite element simulation packages and software and apply the performance spectrum to quickly analyze the performance and scalability across various hardware platforms, software implementations, and numerical discretizations. It is shown that the proposed performance spectrum is a versatile performance model that is not only extendable to more complex PDEs such as hydrostatic ice sheet flow equations but also useful for understanding hardware performance in a massively parallel computing environment. Potential applications and future extensions of this work are also discussed.},
  langid = {english},
  keywords = {static-scaling},
  file = {/home/connor/.local/share/zotero/storage/6Z48IKPN/Chang et al. - 2018 - A performance spectrum for parallel computational .pdf}
}

@article{cheliniMOMMatrixOperations,
  title = {{{MOM}}: {{Matrix Operations}} in {{MLIR}}},
  author = {Chelini, Lorenzo and Barthels, Henrik and Bientinesi, Paolo and Copik, Marcin and Grosser, Tobias and Spampinato, Daniele G},
  pages = {3},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/BHJ6YTKM/Chelini et al. - MOM Matrix Operations in MLIR.pdf}
}

@unpublished{chenEffectiveGPUSharing2021,
  title = {Effective {{GPU Sharing Under Compiler Guidance}}},
  author = {Chen, Chao and Porter, Chris and Pande, Santosh},
  date = {2021-07-18},
  eprint = {2107.08538},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2107.08538},
  urldate = {2021-07-20},
  abstract = {Modern computing platforms tend to deploy multiple GPUs (2, 4, or more) on a single node to boost system performance, with each GPU having a large capacity in terms of global memory and streaming multiprocessors (SMs). GPUs are an expensive resource, and boosting utilization of GPUs without causing performance degradation of individual workloads is an important and challenging problem to be solved. Although services such as MPS provide the support for simultaneously executing multiple co-operative kernels on a single device, they do not solve the above problem for uncooperative1 kernels, MPS being oblivious to the resource needs of each kernel.},
  langid = {english},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing}},
  file = {/home/connor/.local/share/zotero/storage/CUGN58AX/Chen et al. - 2021 - Effective GPU Sharing Under Compiler Guidance.pdf}
}

@article{chouFormatAbstractionSparse2018,
  title = {Format Abstraction for Sparse Tensor Algebra Compilers},
  author = {Chou, Stephen and Kjolstad, Fredrik and Amarasinghe, Saman},
  date = {2018-10-24},
  journaltitle = {Proceedings of the ACM on Programming Languages},
  shortjournal = {Proc. ACM Program. Lang.},
  volume = {2},
  pages = {1--30},
  issn = {2475-1421},
  doi = {10.1145/3276493},
  url = {https://dl.acm.org/doi/10.1145/3276493},
  urldate = {2022-03-18},
  abstract = {This paper shows how to build a sparse tensor algebra compiler that is agnostic to tensor formats (data layouts). We develop an interface that describes formats in terms of their capabilities and properties, and show how to build a modular code generator where new formats can be added as plugins. We then describe six implementations of the interface that compose to form the dense, CSR/CSF, COO, DIA, ELL, and HASH tensor formats and countless variants thereof. With these implementations at hand, our code generator can generate code to compute any tensor algebra expression on any combination of the aforementioned formats.             To demonstrate our technique, we have implemented it in the taco tensor algebra compiler. Our modular code generator design makes it simple to add support for new tensor formats, and the performance of the generated code is competitive with hand-optimized implementations. Furthermore, by extending taco to support a wider range of formats specialized for different application and data characteristics, we can improve end-user application performance. For example, if input data is provided in the COO format, our technique allows computing a single matrix-vector multiplication directly with the data in COO, which is up to 3.6× faster than by first converting the data to CSR.},
  issue = {OOPSLA},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/367TEVET/Chou et al. - 2018 - Format abstraction for sparse tensor algebra compi.pdf}
}

@article{christiansenSmoothedProjectionsFinite2007,
  title = {Smoothed Projections in Finite Element Exterior Calculus},
  author = {Christiansen, Snorre H. and Winther, Ragnar},
  date = {2007-12-20},
  journaltitle = {Mathematics of Computation},
  shortjournal = {Math. Comp.},
  volume = {77},
  number = {262},
  pages = {813--830},
  issn = {0025-5718},
  doi = {10.1090/S0025-5718-07-02081-9},
  url = {http://www.ams.org/journal-getitem?pii=S0025-5718-07-02081-9},
  urldate = {2022-03-18},
  abstract = {The development of smoothed projections, constructed by combining the canonical interpolation operators defined from the degrees of freedom with a smoothing operator, has proved to be an effective tool in finite element exterior calculus. The advantage of these operators is that they are L2 bounded projections, and still they commute with the exterior derivative. In the present paper we generalize the construction of these smoothed projections, such that also non-quasi-uniform meshes and essential boundary conditions are covered. The new tool introduced here is a space-dependent smoothing operator that commutes with the exterior derivative.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/SB6GTBWF/Christiansen and Winther - 2007 - Smoothed projections in finite element exterior ca.pdf}
}

@book{ciarletElement2002,
  title = {The Finite Element Method for Elliptic Problems},
  author = {Ciarlet, Philippe G.},
  date = {2002},
  eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9780898719208},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9780898719208},
  url = {https://epubs.siam.org/doi/abs/10.1137/1.9780898719208},
  file = {/home/connor/OneDrive/AppData/Zotero/Ciarlet_2002_The finite element method for elliptic problems.pdf}
}

@incollection{cockburnStaticCondensationHybridization2016,
  title = {Static {{Condensation}}, {{Hybridization}}, and the {{Devising}} of the {{HDG Methods}}},
  booktitle = {Building {{Bridges}}: {{Connections}} and {{Challenges}} in {{Modern Approaches}} to {{Numerical Partial Differential Equations}}},
  author = {Cockburn, Bernardo},
  editor = {Barrenechea, Gabriel R. and Brezzi, Franco and Cangiani, Andrea and Georgoulis, Emmanuil H.},
  date = {2016},
  volume = {114},
  pages = {129--177},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-41640-3_5},
  url = {http://link.springer.com/10.1007/978-3-319-41640-3_5},
  urldate = {2022-02-18},
  abstract = {In this paper, we review and refine the main ideas for devising the so-called hybridizable discontinuous Galerkin (HDG) methods; we do that in the framework of steady-state diffusion problems. We begin by revisiting the classic techniques of static condensation of continuous finite element methods and that of hybridization of mixed methods, and show that they can be reinterpreted as discrete versions of a characterization of the associated exact solution in terms of solutions of Dirichlet boundary-value problems on each element of the mesh which are then patched together by transmission conditions across interelement boundaries. We then define the HDG methods associated to this characterization as those using discontinuous Galerkin (DG) methods to approximate the local Dirichlet boundary-value problems, and using weak impositions of the transmission conditions. We give simple conditions guaranteeing the existence and uniqueness of their approximate solutions, and show that, by their very construction, the HDG methods are amenable to static condensation. We do this assuming that the diffusivity tensor can be inverted; we also briefly discuss the case in which it cannot. We then show how a different characterization of the exact solution, gives rise to a different way of statically condensing an already known HDG method. We devote the rest of the paper to establishing bridges between the HDG methods and other methods (the old DG methods, the mixed methods, the staggered DG method and the so-called Weak Galerkin method) and to describing recent efforts for the construction of HDG methods (one for systematically obtaining superconvergent methods and another, quite different, which gives rise to optimally convergent methods). We end by providing a few bibliographical notes and by briefly describing ongoing work.},
  isbn = {978-3-319-41638-0 978-3-319-41640-3},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/5UWGU8UE/Cockburn - 2016 - Static Condensation, Hybridization, and the Devisi.pdf}
}

@article{cohenStableHigherOrder,
  title = {Stable Higher Order Triangular Finite Elements with Mass Lumping for the Wave Equation},
  author = {Cohen, G and Joly, P and Tordjman, N},
  pages = {10},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/SHGYAKXF/Cohen et al. - Stable higher order triangular finite elements wit.pdf}
}

@book{cooperLanguagesCompilersParallel2011,
  title = {Languages and {{Compilers}} for {{Parallel Computing}}},
  editor = {Cooper, Keith and Mellor-Crummey, John and Sarkar, Vivek},
  date = {2011},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {6548},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-19595-2},
  url = {http://link.springer.com/10.1007/978-3-642-19595-2},
  urldate = {2021-01-07},
  isbn = {978-3-642-19594-5 978-3-642-19595-2},
  langid = {english},
  file = {/home/connor/Obsidian/30 Literature notes/cooperLanguagesCompilersParallel2011-zotero.md;/home/connor/Obsidian/30 Literature notes/cooperLanguagesCompilersParallel2011.md;/home/connor/Obsidian/30 Literature notes/Zotero/cooperLanguagesCompilersParallel2011-zotero.md;/home/connor/OneDrive/AppData/Zotero/Cooper et al_2011_Languages and Compilers for Parallel Computing.pdf}
}

@article{cotterMixedFiniteElements2012,
  title = {Mixed Finite Elements for Numerical Weather Prediction},
  author = {Cotter, C.J. and Shipton, J.},
  date = {2012-08},
  journaltitle = {Journal of Computational Physics},
  shortjournal = {Journal of Computational Physics},
  volume = {231},
  number = {21},
  pages = {7076--7091},
  issn = {00219991},
  doi = {10.1016/j.jcp.2012.05.020},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999112002628},
  urldate = {2022-03-15},
  abstract = {We show how mixed finite element methods that satisfy the conditions of finite element exterior calculus can be used for the horizontal discretisation of dynamical cores for numerical weather prediction on pseudo-uniform grids. This family of mixed finite element methods can be thought of in the numerical weather prediction context as a generalisation of the popular polygonal C-grid finite difference methods. There are a few major advantages: the mixed finite element methods do not require an orthogonal grid, and they allow a degree of flexibility that can be exploited to ensure an appropriate ratio between the velocity and pressure degrees of freedom so as to avoid spurious mode branches in the numerical dispersion relation. These methods preserve several properties of the C-grid method when applied to linear barotropic wave propagation, namely: (a) energy conservation, (b) mass conservation, (c) no spurious pressure modes, and (d) steady geostrophic modes on the f-plane. We explain how these properties are preserved, and describe two examples that can be used on pseudo-uniform grids: the recently-developed modified RTk-Q(k-1) element pairs on quadrilaterals and the BDFM1-P1DG element pair on triangles. All of these mixed finite element methods have an exact 2:1 ratio of velocity degrees of freedom to pressure degrees of freedom. Finally we illustrate the properties with some numerical examples.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/DK5ZT6DI/Cotter_Shipton_2012_Mixed finite elements for numerical weather prediction.pdf}
}

@inproceedings{cuthillReducingBandwidthSparse1969,
  title = {Reducing the Bandwidth of Sparse Symmetric Matrices},
  booktitle = {Proceedings of the 1969 24th National Conference On   -},
  author = {Cuthill, E. and McKee, J.},
  date = {1969},
  pages = {157--172},
  publisher = {ACM Press},
  location = {Not Known},
  doi = {10.1145/800195.805928},
  url = {http://portal.acm.org/citation.cfm?doid=800195.805928},
  urldate = {2022-10-24},
  eventtitle = {The 1969 24th National Conference},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/CHT9DMK7/800195.805928.pdf}
}

@inproceedings{cytronEfficientMethodComputing1989,
  title = {An Efficient Method of Computing Static Single Assignment Form},
  booktitle = {Proceedings of the 16th {{ACM SIGPLAN-SIGACT}} Symposium on {{Principles}} of Programming Languages  - {{POPL}} '89},
  author = {Cytron, R. and Ferrante, J. and Rosen, B. K. and Wegman, M. N. and Zadeck, F. K.},
  date = {1989},
  pages = {25--35},
  publisher = {ACM Press},
  location = {Austin, Texas, United States},
  doi = {10.1145/75277.75280},
  url = {http://portal.acm.org/citation.cfm?doid=75277.75280},
  urldate = {2022-03-14},
  eventtitle = {The 16th {{ACM SIGPLAN-SIGACT}} Symposium},
  isbn = {978-0-89791-294-5},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/8RW2A3CM/Cytron et al_1989_An efficient method of computing static single assignment form.pdf}
}

@article{dalcinParallelDistributedComputing2011,
  title = {Parallel Distributed Computing Using {{Python}}},
  author = {Dalcin, Lisandro D. and Paz, Rodrigo R. and Kler, Pablo A. and Cosimo, Alejandro},
  date = {2011-09},
  journaltitle = {Advances in Water Resources},
  shortjournal = {Advances in Water Resources},
  volume = {34},
  number = {9},
  pages = {1124--1139},
  issn = {03091708},
  doi = {10.1016/j.advwatres.2011.04.013},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0309170811000777},
  urldate = {2021-06-17},
  abstract = {This work presents two software components aimed to relieve the costs of accessing high-performance parallel computing resources within a Python programming environment: MPI for Python and PETSc for Python.},
  langid = {english},
  keywords = {mpi4py,petsc,petsc4py},
  file = {/home/connor/.local/share/zotero/storage/ISGALFZJ/Dalcin et al. - 2011 - Parallel distributed computing using Python.pdf}
}

@online{dalcinPetIGAFrameworkHighPerformance2015,
  title = {{{PetIGA}}: {{A Framework}} for {{High-Performance Isogeometric Analysis}}},
  shorttitle = {{{PetIGA}}},
  author = {Dalcin, Lisandro and Collier, Nathan and Vignal, Philippe and Cortes, Adriano M. A. and Calo, V. M.},
  date = {2015-07-28},
  eprint = {1305.4452},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/1305.4452},
  urldate = {2024-06-20},
  abstract = {We present PetIGA, a code framework to approximate the solution of partial differential equations using isogeometric analysis. PetIGA can be used to assemble matrices and vectors which come from a Galerkin weak form, discretized with Non-Uniform Rational B-spline basis functions. We base our framework on PETSc, a high-performance library for the scalable solution of partial differential equations, which simplifies the development of large-scale scientific codes, provides a rich environment for prototyping, and separates parallelism from algorithm choice. We describe the implementation of PetIGA, and exemplify its use by solving a model nonlinear problem. To illustrate the robustness and flexibility of PetIGA, we solve some challenging nonlinear partial differential equations that include problems in both solid and fluid mechanics. We show strong scaling results on up to 4096 cores, which confirm the suitability of PetIGA for large scale simulations.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Mathematical Software,Mathematics - Numerical Analysis},
  file = {/home/connor/.local/share/zotero/storage/A4X8H8IR/Dalcin et al. - 2015 - PetIGA A Framework for High-Performance Isogeomet.pdf}
}

@article{darteComplexityLoopFusion2000,
  title = {On the Complexity of Loop Fusion},
  author = {Darte, Alain},
  date = {2000},
  journaltitle = {Parallel Computing},
  pages = {19},
  abstract = {Loop fusion is a program transformation that combines several loops into one. It is used in parallelizing compilers mainly for increasing the granularity of loops and for improving data reuse. The goal of this paper is to study, from a theoretical point of view, several variants of the loop fusion problem ± identifying polynomially solvable cases and NP-complete cases ± and to make the link between these problems and some scheduling problems that arise from completely dierent areas. We study, among others, the fusion of loops of dierent types, and the fusion of loops when combined with loop shifting. Ó 2000 Elsevier Science B.V. All rights reserved.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/ZUI9WUC2/Darte - 2000 - On the complexity of loop fusion.pdf}
}

@incollection{dasSlicingAnalysisIndirect1994,
  title = {Slicing Analysis and Indirect Accesses to Distributed Arrays},
  booktitle = {Languages and {{Compilers}} for {{Parallel Computing}}},
  author = {Das, Raja and Saltz, Joel and Hanxleden, Reinhard},
  editor = {Banerjee, Utpal and Gelernter, David and Nicolau, Alex and Padua, David},
  editora = {Goos, Gerhard and Hartmanis, Juris},
  editoratype = {redactor},
  date = {1994},
  volume = {768},
  pages = {152--168},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/3-540-57659-2_9},
  url = {http://link.springer.com/10.1007/3-540-57659-2_9},
  urldate = {2023-11-27},
  abstract = {An increasing fraction of the applications targeted by parallel computers makes heavy use of indirection arrays for indexing data arrays. Such irregular access patterns make it difficult for a compiler to generate efficient parallel code. Previously developed techniques addressing this problem are limited in that they are only applicable for a single level of indirection. However, many codes using sparse data structures access their data through multiple levels of indirection.},
  isbn = {978-3-540-57659-4 978-3-540-48308-3},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/EANPFJVI/Das et al. - 1994 - Slicing analysis and indirect accesses to distribu.pdf}
}

@inproceedings{deakinPerformancePortabilityDiverse2019,
  title = {Performance {{Portability}} across {{Diverse Computer Architectures}}},
  booktitle = {2019 {{IEEE}}/{{ACM International Workshop}} on {{Performance}}, {{Portability}} and {{Productivity}} in {{HPC}} ({{P3HPC}})},
  author = {Deakin, Tom and McIntosh-Smith, Simon and Price, James and Poenaru, Andrei and Atkinson, Patrick and Popa, Codrin and Salmon, Justin},
  date = {2019-11},
  pages = {1--13},
  publisher = {IEEE},
  location = {Denver, CO, USA},
  doi = {10.1109/P3HPC49587.2019.00006},
  url = {https://ieeexplore.ieee.org/document/8945642/},
  urldate = {2021-02-02},
  abstract = {Previous studies into performance portability have typically analysed a single application (and its various implementations) in isolation. In this study we explore the wider landscape of performance portability by considering a number of applications from across the space of dwarfs, written in multiple parallel programming models, and across a diverse set of architectures. We apply rigorous performance portability metrics, as defined by Pennycook et al [1]. We believe this is the broadest and most rigorous performance portability study to date, representing a far reaching exploration of the state of performance portability that is achievable today. We will present a summary of the performance portability of each application and programming model across our diverge range of twelve computer architectures, including six different server CPUs from five different vendors, five different GPUs from two different vendors, and one vector architecture. We will conclude with an analysis of the performance portability of key programming models in general, across different application spaces as well across differing architectures, allowing us to comment on more general performance portability principles.},
  eventtitle = {2019 {{IEEE}}/{{ACM International Workshop}} on {{Performance}}, {{Portability}} and {{Productivity}} in {{HPC}} ({{P3HPC}})},
  isbn = {978-1-72816-003-0},
  langid = {english},
  keywords = {cuda,kokkos,openacc,opencl,openmp,performance-portability},
  file = {/home/connor/Obsidian/30 Literature notes/deakinPerformancePortabilityDiverse2019 - Extracted Annotations (01062021, 114047)For this study, we use the following definition of performance portability.md;/home/connor/Obsidian/30 Literature notes/deakinPerformancePortabilityDiverse2019 - Summary.md;/home/connor/Obsidian/30 Literature notes/deakinPerformancePortabilityDiverse2019-zotero.md;/home/connor/Obsidian/30 Literature notes/deakinPerformancePortabilityDiverse2019.md;/home/connor/Obsidian/30 Literature notes/Zotero/deakinPerformancePortabilityDiverse2019 - Extracted Annotations (01062021, 114047)For this study, we use the following definition of performance portability.md;/home/connor/Obsidian/30 Literature notes/Zotero/deakinPerformancePortabilityDiverse2019 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/deakinPerformancePortabilityDiverse2019-zotero.md;/home/connor/OneDrive/AppData/Zotero/Deakin et al_2019_Performance Portability across Diverse Computer Architectures.pdf}
}

@misc{defelement,
  title = {{{DefElement}}: An Encyclopedia of Finite Element Definitions},
  author = {Scroggs, Matthew W. and others},
  date = {2024},
  url = {https://defelement.com}
}

@book{desupinskiEvolvingOpenMPEvolving2018,
  title = {Evolving {{OpenMP}} for {{Evolving Architectures}}: 14th {{International Workshop}} on {{OpenMP}}, {{IWOMP}} 2018, {{Barcelona}}, {{Spain}}, {{September}} 26–28, 2018, {{Proceedings}}},
  shorttitle = {Evolving {{OpenMP}} for {{Evolving Architectures}}},
  editor = {family=Supinski, given=Bronis R., prefix=de, useprefix=true and Valero-Lara, Pedro and Martorell, Xavier and Mateo Bellido, Sergi and Labarta, Jesus},
  date = {2018},
  series = {Lecture {{Notes}} in {{Computer Science}}},
  volume = {11128},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-98521-3},
  url = {http://link.springer.com/10.1007/978-3-319-98521-3},
  urldate = {2021-04-12},
  isbn = {978-3-319-98520-6 978-3-319-98521-3},
  langid = {english},
  file = {/home/connor/Obsidian/30 Literature notes/desupinskiEvolvingOpenMPEvolving2018 - Extracted Annotations (12042021, 140259).md;/home/connor/Obsidian/30 Literature notes/desupinskiEvolvingOpenMPEvolving2018 - Summary.md;/home/connor/Obsidian/30 Literature notes/desupinskiEvolvingOpenMPEvolving2018-zotero.md;/home/connor/Obsidian/30 Literature notes/desupinskiEvolvingOpenMPEvolving2018.md;/home/connor/Obsidian/30 Literature notes/Zotero/desupinskiEvolvingOpenMPEvolving2018 - Extracted Annotations (12042021, 140259).md;/home/connor/Obsidian/30 Literature notes/Zotero/desupinskiEvolvingOpenMPEvolving2018 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/desupinskiEvolvingOpenMPEvolving2018-zotero.md;/home/connor/OneDrive/AppData/Zotero/de Supinski et al_2018_Evolving OpenMP for Evolving Architectures.pdf}
}

@inproceedings{devitoLisztDomainSpecific2011,
  title = {Liszt: A Domain Specific Language for Building Portable Mesh-Based {{PDE}} Solvers},
  shorttitle = {Liszt},
  booktitle = {Proceedings of 2011 {{International Conference}} for {{High Performance Computing}}, {{Networking}}, {{Storage}} and {{Analysis}} on - {{SC}} '11},
  author = {DeVito, Zachary and Duraisamy, Karthik and Darve, Eric and Alonso, Juan and Hanrahan, Pat and Joubert, Niels and Palacios, Francisco and Oakley, Stephen and Medina, Montserrat and Barrientos, Mike and Elsen, Erich and Ham, Frank and Aiken, Alex},
  date = {2011},
  pages = {1},
  publisher = {ACM Press},
  location = {Seattle, Washington},
  doi = {10.1145/2063384.2063396},
  url = {http://dl.acm.org/citation.cfm?doid=2063384.2063396},
  urldate = {2021-06-03},
  abstract = {Heterogeneous computers with processors and accelerators are becoming widespread in scientific computing. However, it is difficult to program hybrid architectures and there is no commonly accepted programming model. Ideally, applications should be written in a way that is portable to many platforms, but providing this portability for general programs is a hard problem.},
  eventtitle = {2011 {{International Conference}} for {{High Performance Computing}}, {{Networking}}, {{Storage}} and {{Analysis}}},
  isbn = {978-1-4503-0771-0},
  langid = {english},
  keywords = {domain-specific-language,stencil-code,unstructured-mesh},
  file = {/home/connor/OneDrive/AppData/Zotero/DeVito et al_2011_Liszt.pdf}
}

@online{devitoOptDomainSpecific2017,
  title = {Opt: {{A Domain Specific Language}} for {{Non-linear Least Squares Optimization}} in {{Graphics}} and {{Imaging}}},
  shorttitle = {Opt},
  author = {DeVito, Zachary and Mara, Michael and Zollhöfer, Michael and Bernstein, Gilbert and Ragan-Kelley, Jonathan and Theobalt, Christian and Hanrahan, Pat and Fisher, Matthew and Nießner, Matthias},
  date = {2017-09-09},
  eprint = {1604.06525},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1604.06525},
  urldate = {2022-06-20},
  abstract = {Many graphics and vision problems can be expressed as non-linear least squares optimizations of objective functions over visual data, such as images and meshes. The mathematical descriptions of these functions are extremely concise, but their implementation in real code is tedious, especially when optimized for real-time performance on modern GPUs in interactive applications. In this work, we propose a new language, Opt (available under http://optlang.org), for writing these objective functions over image- or graph-structured unknowns concisely and at a high level. Our compiler automatically transforms these specifications into state-of-the-art GPU solvers based on Gauss-Newton or Levenberg-Marquardt methods. Opt can generate different variations of the solver, so users can easily explore tradeoffs in numerical precision, matrix-free methods, and solver approaches. In our results, we implement a variety of real-world graphics and vision applications. Their energy functions are expressible in tens of lines of code, and produce highly-optimized GPU solver implementations. These solver have performance competitive with the best published hand-tuned, application-specific GPU solvers, and orders of magnitude beyond a general-purpose auto-generated solver.},
  pubstate = {prepublished},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Graphics,Computer Science - Programming Languages},
  file = {/home/connor/OneDrive/AppData/Zotero/DeVito et al_2017_Opt.pdf;/home/connor/.local/share/zotero/storage/J39PNCF9/1604.html}
}

@article{douglasCacheOptimizationStructured,
  title = {Cache {{Optimization}} for {{Structured}} and {{Unstructured Grid Multigrid}}},
  author = {Douglas, Craig C and Hu, Jonathan and Kowarschik, Markus and Rüde, Ulrich and Weiss, Christian},
  abstract = {Many current computer designs employ caches and a hierarchical memory architecture. The speed of a code depends on how well the cache structure is exploited. The number of cache misses provides a better measure for comparing algorithms than the number of multiplies.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/AM2L682K/Douglas et al. - Cache Optimization for Structured and Unstructured.pdf}
}

@online{dwarkaStandaloneMultigridHelmholtz2023,
  title = {Stand-Alone {{Multigrid}} for {{Helmholtz Revisited}}: {{Towards Convergence Using Standard Components}}},
  shorttitle = {Stand-Alone {{Multigrid}} for {{Helmholtz Revisited}}},
  author = {Dwarka, Vandana and Vuik, Cornelis},
  date = {2023-08-25},
  eprint = {2308.13476},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2308.13476},
  urldate = {2023-09-04},
  abstract = {Getting standard multigrid to work efficiently for the high-frequency Helmholtz equation has been an open problem in applied mathematics for years. Much effort has been dedicated to finding solution methods which can use multigrid components to obtain solvers with a linear time complexity. In this work we present one among the first stand-alone multigrid solvers for the 2D Helmholtz equation using both a constant and non-constant wavenumber model problem. We use standard smoothing techniques and do not impose any restrictions on the number of grid points per wavelength on the coarse-grid. As a result we are able to obtain a full V- and W-cycle algorithm. The key features of the algorithm are the use of higher-order inter-grid transfer operators combined with a complex constant in the coarsening process. Using weighted-Jacobi smoothing, we obtain a solver which is h´independent and scales linearly with the wavenumber k. Numerical results using 1 to 5 GMRES(3) smoothing steps approach k´ and h´ independent convergence, when combined with the higher-order inter-grid transfer operators and a small or even zero complex shift. The proposed algorithm provides an important step towards the perpetuating branch of research in finding scalable solvers for challenging wave propagation problems.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {{65N55, 65F10, 65F15},G.1.8,Mathematics - Numerical Analysis},
  file = {/home/connor/.local/share/zotero/storage/D6IU4HQX/Dwarka and Vuik - 2023 - Stand-alone Multigrid for Helmholtz Revisited Tow.pdf}
}

@online{engwerFunctionSpaceBases2018,
  title = {Function Space Bases in the Dune-Functions Module},
  author = {Engwer, Christian and Gräser, Carsten and Müthing, Steffen and Sander, Oliver},
  date = {2018-06-25},
  eprint = {1806.09545},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1806.09545},
  urldate = {2023-09-18},
  abstract = {The dune-functions Dune module provides interfaces for functions and function space bases. It forms one abstraction level above grids, shape functions, and linear algebra, and provides infrastructure for full discretization frameworks like dune-pdelab and dune-fem. This document describes the function space bases provided by dune-functions. These are based on an abstract description of bases for product spaces as trees of simpler bases. From this description, many different numberings of degrees of freedom by multi-indices can be derived in a natural way. We describe the abstract concepts, document the programmer interface, and give a complete example program that solves the stationary Stokes equation using Taylor-Hood elements.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {68N99,Computer Science - Mathematical Software,Mathematics - Numerical Analysis},
  file = {/home/connor/.local/share/zotero/storage/RA8QV7H7/Engwer et al. - 2018 - Function space bases in the dune-functions module.pdf}
}

@article{erickson15CellComplexes,
  title = {15 {{Cell Complexes}}: {{Deﬁnitions}}},
  author = {Erickson, Jeff},
  journaltitle = {Computational Topology},
  pages = {6},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/UL2UI76H/Lehrer and Rex - 15 Cell Complexes Deﬁnitions.pdf}
}

@unpublished{ernstOpeningBlackBox2021,
  title = {Opening the {{Black Box}}: {{Performance Estimation}} during {{Code Generation}} for {{GPUs}}},
  shorttitle = {Opening the {{Black Box}}},
  author = {Ernst, Dominik and Hager, Georg and Holzer, Markus and Knorr, Matthias and Wellein, Gerhard},
  date = {2021-07-02},
  eprint = {2107.01143},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2107.01143},
  urldate = {2021-07-05},
  abstract = {Automatic code generation is frequently used to create implementations of algorithms specifically tuned to particular hardware and application parameters. The code generation process involves the selection of adequate code transformations, tuning parameters, and parallelization strategies. To cover the huge search space, code generation frameworks may apply time-intensive autotuning, exploit scenario-specific performance models, or treat performance as an intangible black box that must be described via machine learning.},
  langid = {english},
  keywords = {gpu,performance-tuning,roofline-model},
  file = {/home/connor/.local/share/zotero/storage/L63T2L9Z/Ernst et al_2021_Opening the Black Box.pdf}
}

@article{falgoutIntroductionAlgebraicMultigrid2006,
  title = {An Introduction to Algebraic Multigrid},
  author = {Falgout, R.D.},
  date = {2006-11},
  journaltitle = {Computing in Science \& Engineering},
  shortjournal = {Comput. Sci. Eng.},
  volume = {8},
  number = {6},
  pages = {24--33},
  issn = {1521-9615, 1558-366X},
  doi = {10.1109/MCSE.2006.105},
  url = {https://ieeexplore.ieee.org/document/1717312/},
  urldate = {2021-11-09},
  abstract = {Algebraic multigrid (AMG) solves linear systems based on multigrid principles, but in a way that only depends on the coefficients in the underlying matrix. The author begins with a basic introduction to AMG methods, and then describes some more recent advances and theoretical developments.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/YLZUST53/Falgout - 2006 - An introduction to algebraic multigrid.pdf}
}

@article{farrellAugmentedLagrangianPreconditioner2019,
  title = {An {{Augmented Lagrangian Preconditioner}} for the {{3D Stationary Incompressible Navier--Stokes Equations}} at {{High Reynolds Number}}},
  author = {Farrell, Patrick E. and Mitchell, Lawrence and Wechsung, Florian},
  date = {2019-01},
  journaltitle = {SIAM Journal on Scientific Computing},
  shortjournal = {SIAM J. Sci. Comput.},
  volume = {41},
  number = {5},
  pages = {A3073-A3096},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/18M1219370},
  url = {https://epubs.siam.org/doi/10.1137/18M1219370},
  urldate = {2022-10-11},
  abstract = {In [M. Benzi and M. A. Olshanskii, SIAM J. Sci. Comput., 28 (2006), pp. 2095--2113] a preconditioner of augmented Lagrangian type was presented for the two-dimensional stationary incompressible Navier--Stokes equations that exhibits convergence almost independent of Reynolds number. The algorithm relies on a highly specialized multigrid method involving a custom prolongation operator and for robustness requires the use of piecewise constant finite elements for the pressure. However, the prolongation operator and velocity element used do not directly extend to three dimensions: the local solves necessary in the prolongation operator do not satisfy the inf-sup condition. In this work we generalize the preconditioner to three dimensions, proposing alternative finite elements for the velocity and prolongation operators for which the preconditioner works robustly. The solver is effective at high Reynolds number: on a three-dimensional lid-driven cavity problem with approximately one billion degrees of freedom, the average number of Krylov iterations per Newton step varies from 4.5 at Re = 10 to 3 at Re = 1000 and 5 at Re = 5000.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/EBI3RWCC/Farrell et al. - 2019 - An Augmented Lagrangian Preconditioner for the 3D .pdf}
}

@article{farrellAutomatedDerivationAdjoint2013,
  title = {Automated Derivation of the Adjoint of High-Level Transient Finite Element Programs},
  author = {Farrell, Patrick E. and Ham, David A. and Funke, Simon F. and Rognes, Marie E.},
  date = {2013-01},
  journaltitle = {SIAM Journal on Scientific Computing},
  shortjournal = {SIAM J. Sci. Comput.},
  volume = {35},
  number = {4},
  eprint = {1204.5577},
  eprinttype = {arXiv},
  pages = {C369-C393},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/120873558},
  url = {http://arxiv.org/abs/1204.5577},
  urldate = {2021-02-11},
  abstract = {In this paper we demonstrate a new technique for deriving discrete adjoint and tangent linear models of finite element models. The technique is significantly more efficient and automatic than standard algorithmic differentiation techniques. The approach relies on a high-level symbolic representation of the forward problem. In contrast to developing a model directly in Fortran or C++, high-level systems allow the developer to express the variational problems to be solved in near-mathematical notation. As such, these systems have a key advantage: since the mathematical structure of the problem is preserved, they are more amenable to automated analysis and manipulation. The framework introduced here is implemented in a freely available software package named dolfin-adjoint, based on the FEniCS Project. Our approach to automated adjoint derivation relies on run-time annotation of the temporal structure of the model, and employs the FEniCS finite element form compiler to automatically generate the low-level code for the derived models. The approach requires only trivial changes to a large class of forward models, including complicated time-dependent nonlinear models. The adjoint model automatically employs optimal checkpointing schemes to mitigate storage requirements for nonlinear models, without any user management or intervention. Furthermore, both the tangent linear and adjoint models naturally work in parallel, without any need to differentiate through calls to MPI or to parse OpenMP directives. The generality, applicability and efficiency of the approach are demonstrated with examples from a wide range of scientific applications.},
  langid = {english},
  file = {/home/connor/Obsidian/30 Literature notes/farrellAutomatedDerivationAdjoint2013 - Extracted Annotations (31032021, 154119).md;/home/connor/Obsidian/30 Literature notes/farrellAutomatedDerivationAdjoint2013 - Summary.md;/home/connor/Obsidian/30 Literature notes/farrellAutomatedDerivationAdjoint2013-zotero.md;/home/connor/Obsidian/30 Literature notes/farrellAutomatedDerivationAdjoint2013.md;/home/connor/Obsidian/30 Literature notes/Zotero/farrellAutomatedDerivationAdjoint2013 - Extracted Annotations (31032021, 154119).md;/home/connor/Obsidian/30 Literature notes/Zotero/farrellAutomatedDerivationAdjoint2013 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/farrellAutomatedDerivationAdjoint2013-zotero.md;/home/connor/OneDrive/AppData/Zotero/Farrell et al_2013_Automated derivation of the adjoint of high-level transient finite element.pdf}
}

@article{farrellAutomatedDerivationAdjoint2013a,
  title = {Automated {{Derivation}} of the {{Adjoint}} of {{High-Level Transient Finite Element Programs}}},
  author = {Farrell, P. E. and Ham, D. A. and Funke, S. W. and Rognes, M. E.},
  date = {2013-01},
  journaltitle = {SIAM Journal on Scientific Computing},
  shortjournal = {SIAM J. Sci. Comput.},
  volume = {35},
  number = {4},
  pages = {C369-C393},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/120873558},
  url = {http://epubs.siam.org/doi/10.1137/120873558},
  urldate = {2022-11-15},
  abstract = {In this paper we demonstrate a new technique for deriving discrete adjoint and tangent linear models of finite element models. The technique is significantly more efficient and automatic than standard algorithmic differentiation techniques. The approach relies on a high-level symbolic representation of the forward problem. In contrast to developing a model directly in Fortran or C++, high-level systems allow the developer to express the variational problems to be solved in near-mathematical notation. As such, these systems have a key advantage: since the mathematical structure of the problem is preserved, they are more amenable to automated analysis and manipulation. The framework introduced here is implemented in a freely available software package named dolfin-adjoint, based on the FEniCS Project. Our approach to automated adjoint derivation relies on run-time annotation of the temporal structure of the model, and employs the FEniCS finite element form compiler to automatically generate the low-level code for the derived models. The approach requires only trivial changes to a large class of forward models, including complicated time-dependent nonlinear models. The adjoint model automatically employs optimal checkpointing schemes to mitigate storage requirements for nonlinear models, without any user management or intervention. Furthermore, both the tangent linear and adjoint models naturally work in parallel, without any need to differentiate through calls to MPI or to parse OpenMP directives. The generality, applicability and efficiency of the approach are demonstrated with examples from a wide range of scientific applications.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/WRGHH4RZ/Farrell et al_2013_Automated Derivation of the Adjoint of High-Level Transient Finite Element.pdf}
}

@article{farrellConservativeInterpolationUnstructured2009,
  title = {Conservative Interpolation between Unstructured Meshes via Supermesh Construction},
  author = {Farrell, P.E. and Piggott, M.D. and Pain, C.C. and Gorman, G.J. and Wilson, C.R.},
  date = {2009-07},
  journaltitle = {Computer Methods in Applied Mechanics and Engineering},
  shortjournal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {198},
  number = {33-36},
  pages = {2632--2642},
  issn = {00457825},
  doi = {10.1016/j.cma.2009.03.004},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0045782509001315},
  urldate = {2023-11-12},
  abstract = {Mesh adaptivity on unstructured meshes is a proven and popular tool for reducing the computational cost of numerical simulations. Unstructured meshes are often preferred in mesh adaptivity as they allow for greater geometric flexibility and arbitrary anisotropy in resolving simulation features. However, such mesh adaptivity suffers from a significant drawback: the interpolation errors caused by interpolating from the old mesh to the new mesh typically destroys conservation of quantities important to the physical accuracy of the simulation (e.g., density, volume fraction, tracer concentration, etc.). This work presents several globally conservative interpolation operators between general unstructured meshes via the construction of an intermediate supermesh. The construction of the supermesh is performed by transforming the problem to the input to a constrained meshing problem. The performance of the conservative interpolation operators are compared against interpolation using the underlying basis functions.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/E292FBMT/Farrell et al. - 2009 - Conservative interpolation between unstructured me.pdf}
}

@article{farrellConservativeInterpolationVolume2011,
  title = {Conservative Interpolation between Volume Meshes by Local {{Galerkin}} Projection},
  author = {Farrell, P.E. and Maddison, J.R.},
  date = {2011-01},
  journaltitle = {Computer Methods in Applied Mechanics and Engineering},
  shortjournal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {200},
  number = {1-4},
  pages = {89--100},
  issn = {00457825},
  doi = {10.1016/j.cma.2010.07.015},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0045782510002276},
  urldate = {2023-11-12},
  abstract = {The problem of interpolating between discrete fields arises frequently in computational physics. The obvious approach, consistent interpolation, has several drawbacks such as suboptimality, non-conservation, and unsuitability for use with discontinuous discretisations. An alternative, Galerkin projection, remedies these deficiencies; however, its implementation has proven very challenging. This paper presents an algorithm for the local implementation of Galerkin projection of discrete fields between meshes. This algorithm extends naturally to three dimensions and is very efficient.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/VLCT2TXI/Farrell and Maddison - 2011 - Conservative interpolation between volume meshes b.pdf}
}

@unpublished{farrellIrksomeAutomatingRunge2020,
  title = {Irksome: {{Automating Runge--Kutta}} Time-Stepping for Finite Element Methods},
  shorttitle = {Irksome},
  author = {Farrell, Patrick E. and Kirby, Robert C. and Marchena-Menendez, Jorge},
  date = {2020-06-29},
  eprint = {2006.16282},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2006.16282},
  urldate = {2020-11-25},
  abstract = {While implicit Runge–Kutta methods possess high order accuracy and important stability properties, implementation difficulties and the high expense of solving the coupled algebraic system at each time step are frequently cited as impediments. We present Irksome, a high-level library for manipulating UFL (Unified Form Language) expressions of semidiscrete variational forms to obtain UFL expressions for the coupled Runge–Kutta stage equations at each time step. Irksome works with the Firedrake package to enable the efficient solution of the resulting coupled algebraic systems. Numerical examples confirm the efficacy of the software and our solver techniques for various problems.},
  langid = {english},
  file = {/home/connor/Obsidian/30 Literature notes/farrellIrksomeAutomatingRunge2020-zotero.md;/home/connor/Obsidian/30 Literature notes/farrellIrksomeAutomatingRunge2020.md;/home/connor/Obsidian/30 Literature notes/Zotero/farrellIrksomeAutomatingRunge2020-zotero.md;/home/connor/OneDrive/AppData/Zotero/Farrell et al_2020_Irksome.pdf}
}

@article{farrellPCPATCHSoftwareTopological2021,
  title = {{{PCPATCH}}: {{Software}} for the {{Topological Construction}} of {{Multigrid Relaxation Methods}}},
  shorttitle = {{{PCPATCH}}},
  author = {Farrell, Patrick E. and Knepley, Matthew G. and Mitchell, Lawrence and Wechsung, Florian},
  date = {2021-06-25},
  journaltitle = {ACM Transactions on Mathematical Software},
  shortjournal = {ACM Trans. Math. Softw.},
  volume = {47},
  number = {3},
  pages = {1--22},
  issn = {0098-3500, 1557-7295},
  doi = {10.1145/3445791},
  url = {https://dl.acm.org/doi/10.1145/3445791},
  urldate = {2021-10-28},
  abstract = {Effective relaxation methods are necessary for good multigrid convergence. For many equations, standard Jacobi and Gauß–Seidel are inadequate, and more sophisticated space decompositions are required; examples include problems with semidefinite terms or saddle point structure. In this article, we present a unifying software abstraction, PCPATCH, for the topological construction of space decompositions for multigrid relaxation methods. Space decompositions are specified by collecting topological entities in a mesh (such as all vertices or faces) and applying a construction rule (such as taking all degrees of freedom in the cells around each entity). The software is implemented in PETSc and facilitates the elegant expression of a wide range of schemes merely by varying solver options at runtime. In turn, this allows for the very rapid development of fast solvers for difficult problems.},
  langid = {english},
  file = {/home/connor/OneDrive/AppData/Zotero/Farrell et al_2021_PCPATCH.pdf}
}

@incollection{feautrierAutomaticParallelizationPolytope1996,
  title = {Automatic Parallelization in the Polytope Model},
  booktitle = {The {{Data Parallel Programming Model}}},
  author = {Feautrier, Paul},
  editor = {Perrin, Guy-René and Darte, Alain},
  editora = {Goos, Gerhard and Hartmanis, Juris and Leeuwen, Jan},
  editoratype = {redactor},
  date = {1996},
  volume = {1132},
  pages = {79--103},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/3-540-61736-1_44},
  url = {http://link.springer.com/10.1007/3-540-61736-1_44},
  urldate = {2021-01-06},
  abstract = {The aim of this paper is to explain the importance of polytope and polyhedra in automatic parallelization. We show that the semantics of parallel programs is best described geometrically, as properties of sets of integral points in n-dimensional spaces, where n is related to the maximum nesting depth of DO loops. The needed properties translate nicely to properties of polyhedra, for which many algorithms have been designed for the needs of optimization and operation research. We show how these ideas apply to scheduling, placement and parallel code generation.},
  isbn = {978-3-540-61736-5 978-3-540-70646-5},
  langid = {english},
  file = {/home/connor/Obsidian/30 Literature notes/feautrierAutomaticParallelizationPolytope1996 - Summary.md;/home/connor/Obsidian/30 Literature notes/feautrierAutomaticParallelizationPolytope1996-zotero.md;/home/connor/Obsidian/30 Literature notes/feautrierAutomaticParallelizationPolytope1996.md;/home/connor/Obsidian/30 Literature notes/Zotero/feautrierAutomaticParallelizationPolytope1996 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/feautrierAutomaticParallelizationPolytope1996-zotero.md;/home/connor/OneDrive/AppData/Zotero/Feautrier_1996_Automatic parallelization in the polytope model.pdf}
}

@unpublished{fegadeCoRaTensorCompiler2022,
  title = {The {{CoRa Tensor Compiler}}: {{Compilation}} for {{Ragged Tensors}} with {{Minimal Padding}}},
  shorttitle = {The {{CoRa Tensor Compiler}}},
  author = {Fegade, Pratik and Chen, Tianqi and Gibbons, Phillip B. and Mowry, Todd C.},
  date = {2022-03-21},
  eprint = {2110.10221},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2110.10221},
  urldate = {2022-03-29},
  abstract = {There is often variation in the shape and size of input data used for deep learning. In many cases, such data can be represented using tensors with non-uniform shapes, or ragged tensors. Due to limited and non-portable support for efficient execution on ragged tensors, current deep learning frameworks generally use techniques such as padding and masking to make the data shapes uniform and then offload the computations to optimized kernels for dense tensor algebra. Such techniques can, however, lead to a lot of wasted computation and therefore, a loss in performance. This paper presents CoRa, a tensor compiler that allows users to easily generate efficient code for ragged tensor operators targeting a wide range of CPUs and GPUs. Evaluating CoRa on a variety of operators on ragged tensors as well as on an encoder layer of the transformer model, we find that CoRa (i)performs competitively with hand-optimized implementations of the operators and the transformer encoder and (ii) achieves, over PyTorch, a 1.6X geomean speedup for the encoder on an Nvidia GPU and a 1.86X geomean speedup for the multi-head attention module used in transformers on an ARM CPU.},
  keywords = {Computer Science - Machine Learning},
  file = {/home/connor/OneDrive/AppData/Zotero/Fegade et al_2022_The CoRa Tensor Compiler.pdf;/home/connor/.local/share/zotero/storage/2VSFB2BM/2110.html}
}

@online{fehlingAlgorithmsParallelGeneric2022,
  title = {Algorithms for {{Parallel Generic}} \$hp\$-Adaptive {{Finite Element Software}}},
  author = {Fehling, Marc and Bangerth, Wolfgang},
  date = {2022-06-13},
  eprint = {2206.06512},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2206.06512},
  urldate = {2022-08-22},
  abstract = {The \$hp\$-adaptive finite element method (FEM) - where one independently chooses the mesh size (\$h\$) and polynomial degree (\$p\$) to be used on each cell - has long been known to have better theoretical convergence properties than either \$h\$- or \$p\$-adaptive methods alone. However, it is not widely used, owing at least in parts to the difficulty of the underlying algorithms and the lack of widely usable implementations. This is particularly true when used with continuous finite elements. Herein, we discuss algorithms that are necessary for a comprehensive and generic implementation of \$hp\$-adaptive finite element methods on distributed-memory, parallel machines. In particular, we will present a multi-stage algorithm for the unique enumeration of degrees of freedom (DoFs) suitable for continuous finite element spaces, describe considerations for weighted load balancing, and discuss the transfer of variable size data between processes. We illustrate the performance of our algorithms with numerical examples, and demonstrate that they scale reasonably up to at least 16,384 Message Passing Interface (MPI) processes. We provide a reference implementation of our algorithms as part of the open-source library deal.II.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Mathematical Software,G.1.8,G.4,Mathematics - Numerical Analysis},
  file = {/home/connor/.local/share/zotero/storage/TZ57B9PX/Fehling and Bangerth - 2022 - Algorithms for Parallel Generic $hp$-adaptive Fini.pdf}
}

@unpublished{fenics2021-kulkarni,
  title = {{{UFL}} to {{GPU}}: {{Generating}} near Roofline Actions Kernels},
  author = {Kulkarni, Kaushik and Kloeckner, Andreas},
  namea = {Baratta, Igor and Dokken, Jørgen S. and Richarson, Chris and Scroggs, Matthew W.},
  nameatype = {collaborator},
  date = {2021},
  doi = {10.6084/m9.figshare.14495301},
  url = {http://mscroggs.github.io/fenics2021/talks/kulkarni.html},
  keywords = {gpu,pyop2,ufl}
}

@manual{FiredrakeUserManual,
  type = {manual},
  title = {Firedrake User Manual},
  author = {Ham, David A. and Kelly, Paul H. J. and Mitchell, Lawrence and Cotter, Colin J. and Kirby, Robert C. and Sagiyama, Koki and Bouziani, Nacime and Vorderwuelbecke, Sophia and Gregory, Thomas J. and Betteridge, Jack and Shapero, Daniel R. and Nixon-Hill, Reuben W. and Ward, Connor J. and Farrell, Patrick E. and Brubeck, Pablo D. and Marsden, India and Gibson, Thomas H. and Homolya, Miklós and Sun, Tianjiao and McRae, Andrew T. T. and Luporini, Fabio and Gregory, Alastair and Lange, Michael and Funke, Simon W. and Rathgeber, Florian and Bercea, Gheorghe-Teodor and Markall, Graham R.},
  date = {2023-05},
  edition = {First edition},
  publisher = {{Imperial College London and University of Oxford and Baylor University and University of Washington}},
  doi = {10.25561/104839}
}

@unpublished{fischerScalabilityHighPerformancePDE2020,
  title = {Scalability of {{High-Performance PDE Solvers}}},
  author = {Fischer, Paul and Min, Misun and Rathnayake, Thilina and Dutta, Som and Kolev, Tzanio and Dobrev, Veselin and Camier, Jean-Sylvain and Kronbichler, Martin and Warburton, Tim and Swirydowicz, Kasia and Brown, Jed},
  date = {2020-04-14},
  eprint = {2004.06722},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2004.06722},
  urldate = {2022-02-04},
  abstract = {Performance tests and analyses are critical to effective HPC software development and are central components in the design and implementation of computational algorithms for achieving faster simulations on existing and future computing architectures for large-scale application problems. In this paper, we explore performance and space-time trade-offs for important compute-intensive kernels of large-scale numerical solvers for PDEs that govern a wide range of physical applications. We consider a sequence of PDEmotivated bake-off problems designed to establish best practices for efficient high-order simulations across a variety of codes and platforms. We measure peak performance (degrees of freedom per second) on a fixed number of nodes and identify effective code optimization strategies for each architecture. In addition to peak performance, we identify the minimum time to solution at 80\% parallel efficiency. The performance analysis is based on spectral and p-type finite elements but is equally applicable to a broad spectrum of numerical PDE discretizations, including finite difference, finite volume, and h-type finite elements.},
  langid = {english},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},35-04,Computer Science - Performance,D.0,F.2,G.2,G.4,I.6},
  file = {/home/connor/.local/share/zotero/storage/RVAVCUKN/Fischer et al_2020_Scalability of High-Performance PDE Solvers.pdf}
}

@software{fredericksonBenfredPyspy2021,
  title = {Benfred/Py-Spy},
  author = {Frederickson, Ben},
  date = {2021-06-28T09:38:21Z},
  origdate = {2018-08-01T02:22:15Z},
  url = {https://github.com/benfred/py-spy},
  urldate = {2021-06-28},
  abstract = {Sampling profiler for Python programs},
  keywords = {performance-analysis,profiler,profiling,python}
}

@article{frigoDesignImplementationFFTW32005,
  title = {The {{Design}} and {{Implementation}} of {{FFTW3}}},
  author = {Frigo, M. and Johnson, S.G.},
  date = {2005-02},
  journaltitle = {Proceedings of the IEEE},
  shortjournal = {Proc. IEEE},
  volume = {93},
  number = {2},
  pages = {216--231},
  issn = {0018-9219},
  doi = {10.1109/JPROC.2004.840301},
  url = {http://ieeexplore.ieee.org/document/1386650/},
  urldate = {2022-03-26},
  abstract = {FFTW is an implementation of the discrete Fourier transform (DFT) that adapts to the hardware in order to maximize performance. This paper shows that such an approach can yield an implementation that is competitive with handoptimized libraries, and describes the software structure that makes our current FFTW3 version flexible and adaptive. We further discuss a new algorithm for real-data DFTs of prime size, a new way of implementing DFTs by means of machine-specific “SIMD” instructions, and how a special-purpose compiler can derive optimized implementations of the discrete cosine and sine transforms automatically from a DFT algorithm.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/7QG5S5A6/Frigo and Johnson - 2005 - The Design and Implementation of FFTW3.pdf}
}

@inproceedings{fringsMassivelyParallelLoading2013,
  title = {Massively Parallel Loading},
  booktitle = {Proceedings of the 27th International {{ACM}} Conference on {{International}} Conference on Supercomputing - {{ICS}} '13},
  author = {Frings, Wolfgang and Ahn, Dong H. and LeGendre, Matthew and Gamblin, Todd and family=Supinski, given=Bronis R., prefix=de, useprefix=true and Wolf, Felix},
  date = {2013},
  pages = {389},
  publisher = {ACM Press},
  location = {Eugene, Oregon, USA},
  doi = {10.1145/2464996.2465020},
  url = {http://dl.acm.org/citation.cfm?doid=2464996.2465020},
  urldate = {2021-07-20},
  abstract = {Dynamic linking has many advantages for managing large code bases, but dynamically linked applications have not typically scaled well on high performance computing systems. Splitting a monolithic executable into many dynamic shared object (DSO) files decreases compile time for large codes, reduces runtime memory requirements by allowing modules to be loaded and unloaded as needed, and allows common DSOs to be shared among many executables. However, launching an executable that depends on many DSOs causes a flood of file system operations at program start-up, when each process in the parallel application loads its dependencies. At large scales, this operation has an effect similar to a site-wide denial-of-service attack, as even large parallel file systems struggle to service so many simultaneous requests. In this paper, we present Spindle, a novel approach to parallel loading that coordinates simultaneous file system operations with a scalable network of cache server processes. Our approach is transparent to user applications. We extend the GNU loader, which is used in Linux as well as proprietary operating systems, to limit the number of simultaneous file system operations, quickly loading DSOs without thrashing the file system. Our experiments show that our prototype implementation has a low overhead and increases the scalability of Pynamic, a benchmark that stresses the dynamic loader, by a factor of 20.},
  eventtitle = {The 27th International {{ACM}} Conference},
  isbn = {978-1-4503-2130-3},
  langid = {english},
  keywords = {filesystem,parallel-loading},
  file = {/home/connor/.local/share/zotero/storage/GM3MP2H5/Frings et al_2013_Massively parallel loading.pdf}
}

@article{funkeFrameworkAutomatedPDEconstrained,
  title = {A Framework for Automated {{PDE-constrained}} Optimisation},
  author = {Funke, S W and Farrell, P E},
  journaltitle = {ACM Transactions on Mathematical Software},
  pages = {28},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/PMGXSMLZ/Funke_Farrell_A framework for automated PDE-constrained optimisation.pdf}
}

@article{gebremedhinIntroductionAlgorithmicDifferentiation2020,
  title = {An Introduction to Algorithmic Differentiation},
  author = {Gebremedhin, Assefaw H. and Walther, Andrea},
  date = {2020-01},
  journaltitle = {WIREs Data Mining and Knowledge Discovery},
  shortjournal = {WIREs Data Mining Knowl Discov},
  volume = {10},
  number = {1},
  issn = {1942-4787, 1942-4795},
  doi = {10.1002/widm.1334},
  url = {https://onlinelibrary.wiley.com/doi/10.1002/widm.1334},
  urldate = {2023-05-26},
  abstract = {Algorithmic differentiation (AD), also known as automatic differentiation, is a technology for accurate and efficient evaluation of derivatives of a function given as a computer model. The evaluations of such models are essential building blocks in numerous scientific computing and data analysis applications, including optimization, parameter identification, sensitivity analysis, uncertainty quantification, nonlinear equation solving, and integration of differential equations. We provide an introduction to AD and present its basic ideas and techniques, some of its most important results, the implementation paradigms it relies on, the connection it has to other domains including machine learning and parallel computing, and a few of the major open problems in the area. Topics we discuss include: forward mode and reverse mode of AD, higher-order derivatives, operator overloading and source transformation, sparsity exploitation, checkpointing, cross-country mode, and differentiating iterative processes.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/F6LH2ZXM/Gebremedhin and Walther - 2020 - An introduction to algorithmic differentiation.pdf}
}

@book{gibsonCompatibleFiniteElement2019,
  title = {Compatible {{Finite Element Methods}} for {{Geophysical Flows}}: {{Automation}} and {{Implementation Using Firedrake}}},
  shorttitle = {Compatible {{Finite Element Methods}} for {{Geophysical Flows}}},
  author = {Gibson, Thomas H. and McRae, Andrew T.T. and Cotter, Colin J. and Mitchell, Lawrence and Ham, David A.},
  date = {2019},
  series = {Mathematics of {{Planet Earth}}},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-23957-2},
  url = {http://link.springer.com/10.1007/978-3-030-23957-2},
  urldate = {2020-03-09},
  isbn = {978-3-030-23956-5 978-3-030-23957-2},
  langid = {english},
  file = {/home/connor/Obsidian/30 Literature notes/gibsonCompatibleFiniteElement2019-zotero.md;/home/connor/Obsidian/30 Literature notes/gibsonCompatibleFiniteElement2019.md;/home/connor/Obsidian/30 Literature notes/Zotero/gibsonCompatibleFiniteElement2019-zotero.md;/home/connor/OneDrive/AppData/Zotero/Gibson et al_2019_Compatible Finite Element Methods for Geophysical Flows.pdf}
}

@article{gibsonSlateExtendingFiredrake2020,
  title = {Slate: Extending {{Firedrake}}'s Domain-Specific Abstraction to Hybridized Solvers for Geoscience and Beyond},
  shorttitle = {Slate},
  author = {Gibson, Thomas H. and Mitchell, Lawrence and Ham, David A. and Cotter, Colin J.},
  date = {2020-02-25},
  journaltitle = {Geoscientific Model Development},
  shortjournal = {Geosci. Model Dev.},
  volume = {13},
  number = {2},
  pages = {735--761},
  issn = {1991-9603},
  doi = {10.5194/gmd-13-735-2020},
  url = {https://gmd.copernicus.org/articles/13/735/2020/},
  urldate = {2020-11-26},
  abstract = {Within the finite element community, discontinuous Galerkin (DG) and mixed finite element methods have become increasingly popular in simulating geophysical flows. However, robust and efficient solvers for the resulting saddle point and elliptic systems arising from these discretizations continue to be an ongoing challenge. One possible approach for addressing this issue is to employ a method known as hybridization, where the discrete equations are transformed such that classic static condensation and local post-processing methods can be employed. However, it is challenging to implement hybridization as performant parallel code within complex models whilst maintaining a separation of concerns between applications scientists and software experts. In this paper, we introduce a domain-specific abstraction within the Firedrake finite element library that permits the rapid execution of these hybridization techniques within a code-generating framework. The resulting framework composes naturally with Firedrake’s solver environment, allowing for the implementation of hybridization and static condensation as runtime-configurable preconditioners via the Python interface to the Portable, Extensible Toolkit for Scientific Computation (PETSc), petsc4py. We provide examples derived from second-order elliptic problems and geophysical fluid dynamics. In addition, we demonstrate that hybridization shows great promise for improving the performance of solvers for mixed finite element discretizations of equations related to large-scale geophysical flows.},
  langid = {english},
  keywords = {slate},
  file = {/home/connor/Obsidian/30 Literature notes/gibsonSlateExtendingFiredrake2020 - Extracted Annotations (10022021, 111239).md;/home/connor/Obsidian/30 Literature notes/gibsonSlateExtendingFiredrake2020-zotero.md;/home/connor/Obsidian/30 Literature notes/gibsonSlateExtendingFiredrake2020.md;/home/connor/Obsidian/30 Literature notes/Zotero/gibsonSlateExtendingFiredrake2020 - Extracted Annotations (10022021, 111239).md;/home/connor/Obsidian/30 Literature notes/Zotero/gibsonSlateExtendingFiredrake2020-zotero.md;/home/connor/OneDrive/AppData/Zotero/Gibson et al_2020_Slate.pdf}
}

@inproceedings{gilesAnalyticalStudyLoop2012,
  title = {An {{Analytical Study}} of {{Loop Tiling}} for a {{Large-Scale Unstructured Mesh Application}}},
  booktitle = {2012 {{SC Companion}}: {{High Performance Computing}}, {{Networking Storage}} and {{Analysis}}},
  author = {Giles, M.B. and Mudalige, G. R. and Bertolli, C. and Kelly, Paul H. J. and Laszlo, E. and Reguly, I.},
  date = {2012-11},
  pages = {477--482},
  publisher = {IEEE},
  location = {Salt Lake City, UT},
  doi = {10.1109/SC.Companion.2012.68},
  url = {http://ieeexplore.ieee.org/document/6495850/},
  urldate = {2021-02-02},
  abstract = {Increasingly, the main bottleneck limiting performance on emerging multi-core and many-core processors is the movement of data between its different cores and main memory. As the number of cores increases, more and more data needs to be exchanged with memory to keep them fully utilized. This critical bottleneck is already limiting the utility of processors and our ability to leverage increased parallelism to achieve higher performance. On the other hand, considerable computer science research exists on tiling techniques (also known as sparse tiling), for reducing data transfers. Such work demonstrates how the increasing memory bottleneck could be avoided but the difficulty has been in extending these ideas to real-world applications. These algorithms quickly become highly complicated, and it has be very difficult to for a compiler to automatically detect the opportunities and implement the execution strategy. Focusing on the unstructured mesh application class, in this paper, we present a preliminary analytical investigation into the performance benefits of tiling (or loop-blocking) algorithms on a realworld industrial CFD application. We analytically estimate the reductions in communications or memory accesses for the main parallel loops in this application and predict quantitatively the performance benefits that can be gained on modern multi-core and many core hardware. The analysis demonstrates that in general a factor of four reduction in data movement can be achieved by tiling parallel loops. A major part of the savings come from contraction of temporary or transient data arrays that need not be written back to main memory, by holding them in the last level cache (LLC) of modern processors.},
  eventtitle = {2012 {{SC Companion}}: {{High Performance Computing}}, {{Networking}}, {{Storage}} and {{Analysis}} ({{SCC}})},
  isbn = {978-0-7695-4956-9 978-1-4673-6218-4},
  langid = {english},
  keywords = {op2,sparse-tiling,unstructured-mesh},
  file = {/home/connor/Obsidian/30 Literature notes/Zotero/gilesAnalyticalStudyLoop2012 - Extracted Annotations (14042021, 141744).md;/home/connor/Obsidian/30 Literature notes/Zotero/gilesAnalyticalStudyLoop2012 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/gilesAnalyticalStudyLoop2012-zotero.md;/home/connor/OneDrive/AppData/Zotero/Giles et al_2012_An Analytical Study of Loop Tiling for a Large-Scale Unstructured Mesh.pdf}
}

@article{gilesPerformanceAnalysisOP22011,
  title = {Performance Analysis of the {{OP2}} Framework on Many-Core Architectures},
  author = {Giles, M. B. and Mudalige, G. R. and Sharif, Z. and Markall, G. and Kelly, Paul H. J.},
  date = {2011-03-29},
  journaltitle = {ACM SIGMETRICS Performance Evaluation Review},
  shortjournal = {SIGMETRICS Perform. Eval. Rev.},
  volume = {38},
  number = {4},
  pages = {9--15},
  issn = {0163-5999},
  doi = {10.1145/1964218.1964221},
  url = {https://dl.acm.org/doi/10.1145/1964218.1964221},
  urldate = {2021-06-01},
  abstract = {We present a performance analysis and benchmarking study of the OP2 “active” library, which provides an abstraction framework for the solution of parallel unstructured mesh applications. OP2 aims to decouple the scientific specification of the application from its parallel implementation, achieving code longevity and near-optimal performance through re-targeting the back-end to different hardware.},
  langid = {english},
  file = {/home/connor/Obsidian/30 Literature notes/gilesPerformanceAnalysisOP22011.md;/home/connor/Obsidian/30 Literature notes/Zotero/gilesPerformanceAnalysisOP22011-zotero.md;/home/connor/OneDrive/AppData/Zotero/Giles et al_2011_Performance analysis of the OP2 framework on many-core architectures.pdf}
}

@article{girolamiStatisticalFiniteElement2021,
  title = {The Statistical Finite Element Method ({{statFEM}}) for Coherent Synthesis of Observation Data and Model Predictions},
  author = {Girolami, Mark and Febrianto, Eky and Yin, Ge and Cirak, Fehmi},
  date = {2021-03},
  journaltitle = {Computer Methods in Applied Mechanics and Engineering},
  shortjournal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {375},
  eprint = {1905.06391},
  eprinttype = {arXiv},
  pages = {113533},
  issn = {00457825},
  doi = {10.1016/j.cma.2020.113533},
  url = {http://arxiv.org/abs/1905.06391},
  urldate = {2021-09-16},
  abstract = {The increased availability of observation data from engineering systems in operation poses the question of how to incorporate this data into finite element models. To this end, we propose a novel statistical construction of the finite element method that provides the means of synthesising measurement data and finite element models. The Bayesian statistical framework is adopted to treat all the uncertainties present in the data, the mathematical model and its finite element discretisation. From the outset, we postulate a data-generating model which additively decomposes data into a finite element, a model misspecification and a noise component. Each of the components may be uncertain and is considered as a random variable with a respective prior probability density. The prior of the finite element component is given by a conventional stochastic forward problem. The prior probabilities of the model misspecification and measurement noise, without loss of generality, are assumed to have zero-mean and known covariance structure. Our proposed statistical model is hierarchical in the sense that each of the three random components may depend on non-observable random hyperparameters. Because of the hierarchical structure of the statistical model, Bayes rule is applied on three different levels in turn to infer the posterior densities of the three random components and hyperparameters. On level one, we determine the posterior densities of the finite element component and the true system response using the prior finite element density given by the forward problem and the data likelihood. On the next level, we infer the hyperparameter posterior densities from their respective priors and the marginal likelihood of the first inference problem. Finally, on level three we use Bayes rule to choose the most suitable finite element model in light of the observed data by computing the model posteriors.},
  keywords = {Mathematics - Numerical Analysis,Statistics - Methodology},
  file = {/home/connor/OneDrive/AppData/Zotero/Girolami et al_2021_The statistical finite element method (statFEM) for coherent synthesis of.pdf;/home/connor/.local/share/zotero/storage/YIL37U4A/1905.html}
}

@unpublished{gomez-lunaBenchmarkingNewParadigm2021,
  title = {Benchmarking a {{New Paradigm}}: {{An Experimental Analysis}} of a {{Real Processing-in-Memory Architecture}}},
  shorttitle = {Benchmarking a {{New Paradigm}}},
  author = {Gómez-Luna, Juan and Hajj, Izzat El and Fernandez, Ivan and Giannoula, Christina and Oliveira, Geraldo F. and Mutlu, Onur},
  date = {2021-05-14},
  eprint = {2105.03814},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2105.03814},
  urldate = {2021-05-18},
  abstract = {Many modern workloads, such as neural networks, databases, and graph processing, are fundamentally memory-bound. For such workloads, the data movement between main memory and CPU cores imposes a significant overhead in terms of both latency and energy. A major reason is that this communication happens through a narrow bus with high latency and limited bandwidth, and the low data reuse in memory-bound workloads is insufficient to amortize the cost of main memory access. Fundamentally addressing this data movement bottleneck requires a paradigm where the memory system assumes an active role in computing by integrating processing capabilities. This paradigm is known as processing-in-memory (PIM). Recent research explores different forms of PIM architectures, motivated by the emergence of new 3D-stacked memory technologies that integrate memory with a logic layer where processing elements can be easily placed. Past works evaluate these architectures in simulation or, at best, with simplified hardware prototypes. In contrast, the UPMEM company has designed and manufactured the first publicly-available real-world PIM architecture. This paper provides the first comprehensive analysis of the first publicly-available real-world PIM architecture. We make two key contributions. First, we conduct an experimental characterization of the UPMEM-based PIM system using microbenchmarks to assess various architecture limits such as compute throughput and memory bandwidth, yielding new insights. Second, we present PrIM, a benchmark suite of 16 workloads from different application domains (e.g., linear algebra, databases, graph processing, neural networks, bioinformatics).},
  langid = {english},
  keywords = {processing-in-memory},
  file = {/home/connor/Obsidian/30 Literature notes/gomez-lunaBenchmarkingNewParadigm2021 - Comment Our open source software is being prepared and will be released in July 2021.md;/home/connor/Obsidian/30 Literature notes/gomez-lunaBenchmarkingNewParadigm2021 - Summary.md;/home/connor/Obsidian/30 Literature notes/gomez-lunaBenchmarkingNewParadigm2021-zotero.md;/home/connor/Obsidian/30 Literature notes/gomez-lunaBenchmarkingNewParadigm2021.md;/home/connor/Obsidian/30 Literature notes/Zotero/gomez-lunaBenchmarkingNewParadigm2021 - Comment Our open source software is being prepared and will be released in July 2021.md;/home/connor/Obsidian/30 Literature notes/Zotero/gomez-lunaBenchmarkingNewParadigm2021 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/gomez-lunaBenchmarkingNewParadigm2021-zotero.md;/home/connor/OneDrive/AppData/Zotero/Gómez-Luna et al_2021_Benchmarking a New Paradigm.pdf}
}

@online{grossPEP703Making,
  title = {{{PEP}} 703 – {{Making}} the {{Global Interpreter Lock Optional}} in {{CPython}}},
  author = {Gross, Sam},
  url = {https://peps.python.org/pep-0703/},
  abstract = {CPython’s global interpreter lock (“GIL”) prevents multiple threads from executing Python code at the same time. The GIL is an obstacle to using multi-core CPUs from Python efficiently. This PEP proposes adding a build configuration (--disable-gil) to CPython to let it run Python code without the global interpreter lock and with the necessary changes needed to make the interpreter thread-safe.}
}

@article{gustafsonReevaluatingAmdahlLaw1988,
  title = {Reevaluating {{Amdahl}}'s Law},
  author = {Gustafson, John L.},
  date = {1988-05},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {31},
  number = {5},
  pages = {532--533},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/42411.42415},
  url = {https://dl.acm.org/doi/10.1145/42411.42415},
  urldate = {2021-06-18},
  langid = {english},
  keywords = {weak-scaling},
  file = {/home/connor/.local/share/zotero/storage/N9KIZWIJ/Gustafson - 1988 - Reevaluating Amdahl's law.pdf}
}

@article{guzmanScottVogeliusFiniteElements2018,
  title = {The {{Scott-Vogelius}} Finite Elements Revisited},
  author = {Guzmán, Johnny and Scott, L. Ridgway},
  date = {2018-04-16},
  journaltitle = {Mathematics of Computation},
  shortjournal = {Math. Comp.},
  volume = {88},
  number = {316},
  pages = {515--529},
  issn = {0025-5718, 1088-6842},
  doi = {10.1090/mcom/3346},
  url = {https://www.ams.org/mcom/2019-88-316/S0025-5718-2018-03346-4/},
  urldate = {2024-06-17},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/6RMCRHSN/Guzman and Scott - 2017 - The Scott-Vogelius finite elements revisited.pdf}
}

@article{hamAutomatedShapeDifferentiation2019,
  title = {Automated Shape Differentiation in the {{Unified Form Language}}},
  author = {Ham, David A. and Mitchell, Lawrence and Paganini, Alberto and Wechsung, Florian},
  date = {2019-11},
  journaltitle = {Structural and Multidisciplinary Optimization},
  shortjournal = {Struct Multidisc Optim},
  volume = {60},
  number = {5},
  pages = {1813--1820},
  issn = {1615-147X, 1615-1488},
  doi = {10.1007/s00158-019-02281-z},
  url = {http://link.springer.com/10.1007/s00158-019-02281-z},
  urldate = {2021-09-29},
  abstract = {We discuss automating the calculation of weak shape derivatives in the Unified Form Language (ACM TOMS 40(2):9:1–9:37 2014) by introducing an appropriate additional step in the pullback from physical to reference space that computes Gaˆteaux derivatives with respect to the coordinate field. We illustrate the ease of use with several examples.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/ZH8P7DLP/Ham et al_2019_Automated shape differentiation in the Unified Form Language.pdf}
}

@online{hamEfficientNtoMCheckpointing2024,
  title = {Efficient {{N-to-M Checkpointing Algorithm}} for {{Finite Element Simulations}}},
  author = {Ham, David A. and Hapla, Vaclav and Knepley, Matthew G. and Mitchell, Lawrence and Sagiyama, Koki},
  date = {2024-01-11},
  eprint = {2401.05868},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2401.05868},
  urldate = {2024-01-17},
  abstract = {In this work, we introduce a new algorithm for N-to-M checkpointing in finite element simulations. This new algorithm allows efficient saving/loading of functions representing physical quantities associated with the mesh representing the physical domain. Specifically, the algorithm allows for using different numbers of parallel processes for saving and loading, allowing for restarting and post-processing on the process count appropriate to the given phase of the simulation and other conditions. For demonstration, we implemented this algorithm in PETSc, the Portable, Extensible Toolkit for Scientific Computation, and added a convenient high-level interface into Firedrake, a system for solving partial differential equations using finite element methods. We evaluated our new implementation by saving and loading data involving 8.2 billion finite element degrees of freedom using 8,192 parallel processes on ARCHER2, the UK National Supercomputing Service.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Mathematical Software},
  file = {/home/connor/.local/share/zotero/storage/5T33UASW/Ham et al. - 2024 - Efficient N-to-M Checkpointing Algorithm for Finit.pdf}
}

@inproceedings{hammondMPIApplicationBinary2023,
  title = {{{MPI Application Binary Interface Standardization}}},
  booktitle = {Proceedings of the 30th {{European MPI Users}}' {{Group Meeting}}},
  author = {Hammond, Jeff and Dalcin, Lisandro and Schnetter, Erik and PéRache, Marc and Besnard, Jean-Baptiste and Brown, Jed and Gadeschi, Gonzalo Brito and Byrne, Simon and Schuchart, Joseph and Zhou, Hui},
  date = {2023-09-11},
  pages = {1--12},
  publisher = {ACM},
  location = {Bristol United Kingdom},
  doi = {10.1145/3615318.3615319},
  url = {https://dl.acm.org/doi/10.1145/3615318.3615319},
  urldate = {2023-11-01},
  abstract = {MPI is the most widely used interface for high-performance computing (HPC) workloads. Its success lies in its embrace of libraries and ability to evolve while maintaining backward compatibility for older codes, enabling them to run on new architectures for many years. In this paper, we propose a new level of MPI compatibility: a standard Application Binary Interface (ABI). We review the history of MPI implementation ABIs, identify the constraints from the MPI standard and ISO C, and summarize recent efforts to develop a standard ABI for MPI. We provide the current proposal from the MPI Forum’s ABI working group, which has been prototyped both within MPICH and as an independent abstraction layer called Mukautuva. We also list several use cases that would benefit from the definition of an ABI while outlining the remaining constraints.},
  eventtitle = {{{EUROMPI}} '23: 30th {{European MPI Users}}' {{Group Meeting}}},
  isbn = {9798400709135},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/IBHTLZCC/Hammond et al. - 2023 - MPI Application Binary Interface Standardization.pdf}
}

@online{hamUFLDualSpaces2021,
  title = {{{UFL Dual Spaces}}, a Proposal},
  author = {Ham, David A.},
  date = {2021-01-13},
  eprint = {2101.05158},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2101.05158},
  urldate = {2023-01-16},
  abstract = {This white paper highlights current limitations in the algebraic closure Unified Form Language (UFL). UFL currently represents forms over finite element spaces, however finite element problems naturally result in objects in the dual to a finite element space, and operators mapping between primal and dual finite element spaces. This document sketches the relevant mathematical areas and proposes changes to the UFL language to support dual spaces as first class types in UFL.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Mathematical Software},
  file = {/home/connor/.local/share/zotero/storage/FCRBA7HD/Ham - 2021 - UFL Dual Spaces, a proposal.pdf}
}

@article{haplaFullyParallelMesh2021,
  title = {Fully {{Parallel Mesh I}}/{{O}} Using {{PETSc DMPlex}} with an {{Application}} to {{Waveform Modeling}}},
  author = {Hapla, Vaclav and Knepley, Matthew G. and Afanasiev, Michael and Boehm, Christian and family=Driel, given=Martin, prefix=van, useprefix=true and Krischer, Lion and Fichtner, Andreas},
  date = {2021-01},
  journaltitle = {SIAM Journal on Scientific Computing},
  shortjournal = {SIAM J. Sci. Comput.},
  volume = {43},
  number = {2},
  eprint = {2004.08729},
  eprinttype = {arXiv},
  pages = {C127-C153},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/20M1332748},
  url = {http://arxiv.org/abs/2004.08729},
  urldate = {2021-06-04},
  abstract = {Large-scale PDE simulations using high-order finite-element methods on unstructured meshes are an indispensable tool in science and engineering. The widely used open-source PETSc library offers an efficient representation of generic unstructured meshes within its DMPlex module. This paper details our recent implementation of parallel mesh reading and topological interpolation (computation of edges and faces from a cell-vertex mesh) into DMPlex. We apply these developments to seismic wave propagation scenarios on Mars as an example application. The principal motivation is to overcome single-node memory limits and reach mesh sizes which were impossible before. Moreover, we demonstrate that scalability of I/O and topological interpolation goes beyond 12’000 cores, and memory-imposed limits on mesh size vanish.},
  langid = {english},
  keywords = {{65-04, 65Y05, 65M50, 05C90, 35L05},Computer Science - Mathematical Software,Mathematics - Numerical Analysis},
  file = {/home/connor/.local/share/zotero/storage/69Y9SU8Z/Hapla et al. - 2021 - Fully Parallel Mesh IO using PETSc DMPlex with an.pdf}
}

@online{harperCompressionReducedRepresentation2023,
  title = {Compression and {{Reduced Representation Techniques}} for {{Patch-Based Relaxation}}},
  author = {Harper, Graham and Tuminaro, Ray},
  date = {2023-05-31},
  eprint = {2306.10025},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2306.10025},
  urldate = {2024-07-16},
  abstract = {Patch-based relaxation refers to a family of methods for solving linear systems which partitions the matrix into smaller pieces often corresponding to groups of adjacent degrees of freedom residing within patches of the computational domain. The two most common families of patch-based methods are block-Jacobi and Schwarz methods, where the former typically corresponds to non-overlapping domains and the later implies some overlap. We focus on cases where each patch consists of the degrees of freedom within a finite element method mesh cell. Patch methods often capture complex local physics much more effectively than simpler point-smoothers such as Jacobi; however, forming, inverting, and applying each patch can be prohibitively expensive in terms of both storage and computation time. To this end, we propose several approaches for performing analysis on these patches and constructing a reduced representation. The compression techniques rely on either matrix norm comparisons or unsupervised learning via a clustering approach. We illustrate how it is frequently possible to retain/factor less than 5\% of all patches and still develop a method that converges with the same number of iterations or slightly more than when all patches are stored/factored.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Mathematics - Numerical Analysis},
  file = {/home/connor/.local/share/zotero/storage/ZQDCKLBQ/Harper and Tuminaro - 2023 - Compression and Reduced Representation Techniques .pdf}
}

@article{harrellEffectivePerformancePortability2018,
  title = {Effective {{Performance Portability}}},
  author = {Harrell, Stephen Lien and Kitson, Joy and Bird, Robert and Pennycook, Simon John and Sewall, Jason and Jacobsen, Doug and Asanza, David Neill and Hsu, Abigail and Cabada, Hector Carrillo and Kim, Heesoo and Robey, Robert},
  date = {2018},
  pages = {13},
  abstract = {Exascale computing brings with it diverse machine architectures and programming approaches which challenge application developers. Applications need to perform well on a wide range of architectures while simultaneously minimizing development and maintenance overheads. In order to alleviate these costs, developers have begun leveraging portability frameworks to maximize both the code shared between platforms and the performance of the application. We explore the effectiveness of several such frameworks through applying them to small production codes. Throughout the process, we apply a logging tool to gather data on the development process. We use this information to develop metrics of application development productivity, which can be used to holistically assess how productively a performanceportable application was developed.},
  langid = {english},
  file = {/home/connor/Obsidian/30 Literature notes/Zotero/harrellEffectivePerformancePortability2018 - Extracted Annotations (05052021, 155912).md;/home/connor/Obsidian/30 Literature notes/Zotero/harrellEffectivePerformancePortability2018 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/harrellEffectivePerformancePortability2018-zotero.md;/home/connor/OneDrive/AppData/Zotero/Harrell et al_2018_Effective Performance Portability.pdf}
}

@book{hatcherAlgebraicTopology2002,
  title = {Algebraic Topology},
  author = {Hatcher, Allen},
  date = {2002},
  publisher = {Cambridge University Press},
  location = {Cambridge ; New York},
  isbn = {978-0-521-79160-1 978-0-521-79540-1},
  pagetotal = {544},
  keywords = {Algebraic topology},
  file = {/home/connor/.local/share/zotero/storage/CMMW593U/Hatcher_2002_Algebraic topology.pdf}
}

@article{hawkinsDataRepresentationSynthesis,
  title = {Data {{Representation Synthesis}}},
  author = {Hawkins, Peter and Aiken, Alex and Fisher, Kathleen and Rinard, Martin and Sagiv, Mooly},
  pages = {12},
  abstract = {We consider the problem of specifying combinations of data structures with complex sharing in a manner that is both declarative and results in provably correct code. In our approach, abstract data types are specified using relational algebra and functional dependencies. We describe a language of decompositions that permit the user to specify different concrete representations for relations, and show that operations on concrete representations soundly implement their relational specification. It is easy to incorporate data representations synthesized by our compiler into existing systems, leading to code that is simpler, correct by construction, and comparable in performance to the code it replaces.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/3MWTMFQR/Hawkins et al_Data Representation Synthesis.pdf}
}

@inproceedings{heineckeLIBXSMMAcceleratingSmall2016,
  title = {{{LIBXSMM}}: {{Accelerating Small Matrix Multiplications}} by {{Runtime Code Generation}}},
  shorttitle = {{{LIBXSMM}}},
  booktitle = {{{SC}} '16: {{Proceedings}} of the {{International Conference}} for {{High Performance Computing}}, {{Networking}}, {{Storage}} and {{Analysis}}},
  author = {Heinecke, Alexander and Henry, Greg and Hutchinson, Maxwell and Pabst, Hans},
  date = {2016-11},
  pages = {981--991},
  issn = {2167-4337},
  doi = {10.1109/SC.2016.83},
  abstract = {Many modern highly scalable scientific simulations packages rely on small matrix multiplications as their main computational engine. Math libraries or compilers are unlikely to provide the best possible kernel performance. To address this issue, we present a library which provides high performance small matrix multiplications targeting all recent x86 vector instruction set extensions up to Intel AVX-512. Our evaluation proves that speed-ups of more than 10× are possible depending on the CPU and application. These speed-ups are achieved by a combination of several novel technologies. We use a code generator which has a built-in architectural model to create code which runs well without requiring an auto-tuning phase. Since such code is very specialized we leverage just-in-time compilation to only build the required kernel variant at runtime. To keep ease-of-use, overhead, and kernel management under control we accompany our library with a BLAS-compliant frontend which features a multi-level code-cache hierarchy.},
  eventtitle = {{{SC}} '16: {{Proceedings}} of the {{International Conference}} for {{High Performance Computing}}, {{Networking}}, {{Storage}} and {{Analysis}}},
  keywords = {Algorithms,Block CSR,code generation,FEM,Indexes,JIT compilation,Kernel,Libraries,Runtime,SEM,Small GEMM,Sparse matrices},
  file = {/home/connor/OneDrive/AppData/Zotero/Heinecke et al_2016_LIBXSMM.pdf;/home/connor/.local/share/zotero/storage/CQU8EZVA/7877162.html}
}

@article{hernandezStructurepreservingNeuralNetworks2021,
  title = {Structure-Preserving Neural Networks},
  author = {Hernández, Quercus and Badias, Alberto and Gonzalez, David and Chinesta, Francisco and Cueto, Elias},
  date = {2021-02},
  journaltitle = {Journal of Computational Physics},
  shortjournal = {Journal of Computational Physics},
  volume = {426},
  eprint = {2004.04653},
  eprinttype = {arXiv},
  pages = {109950},
  issn = {00219991},
  doi = {10.1016/j.jcp.2020.109950},
  url = {http://arxiv.org/abs/2004.04653},
  urldate = {2022-03-18},
  abstract = {We develop a method to learn physical systems from data that employs feedforward neural networks and whose predictions comply with the first and second principles of thermodynamics. The method employs a minimum amount of data by enforcing the metriplectic structure of dissipative Hamiltonian systems in the form of the so-called General Equation for the Non-Equilibrium ReversibleIrreversible Coupling, GENERIC [M. Grmela and H.C Oettinger (1997). Dynamics and thermodynamics of complex fluids. I. Development of a general formalism. Phys. Rev. E. 56 (6): 6620–6632]. The method does not need to enforce any kind of balance equation, and thus no previous knowledge on the nature of the system is needed. Conservation of energy and dissipation of entropy in the prediction of previously unseen situations arise as a natural by-product of the structure of the method. Examples of the performance of the method are shown that comprise conservative as well as dissipative systems, discrete as well as continuous ones.},
  langid = {english},
  keywords = {Computer Science - Machine Learning,Physics - Computational Physics,Statistics - Machine Learning},
  file = {/home/connor/.local/share/zotero/storage/S8KVRW57/Hernández et al. - 2021 - Structure-preserving neural networks.pdf}
}

@article{HoffmanJanssonEtAl2012a,
  title = {Unicorn: {{Parallel}} Adaptive Finite Element Simulation of Turbulent Flow and Fluid-Structure Interaction for Deforming Domains and Complex Geometry},
  author = {Hoffman, Johan and Jansson, Johan and family=Abreu, given=Rodrigo V., prefix=de, useprefix=true and Degirmenci, Cem and Jansson, Niclas and Müller, Kaspar and Nazarov, Murtazo and Spühler, Jeanette H.},
  date = {2012},
  journaltitle = {Computer and Fluids},
  volume = {in press}
}

@incollection{HoffmanJanssonEtAl2012a,
  title = {Unicorn: A Unified Continuum Mechanics Solver},
  booktitle = {Automated Solution of Differential Equations by the Finite Element Method, Volume 84 of Lecture Notes in Computational Science and Engineering},
  author = {Hoffman, Johan and Jansson, Johan and Degirmenci, Cem and Jansson, Niclas and Nazarov, Murtazo},
  editor = {Logg, Anders and Mardal, Kent-Andre and Wells, Garth N.},
  date = {2012},
  publisher = {Springer}
}

@incollection{HoffmanJanssonEtAl2012b,
  title = {Turbulent Flow and {{Fluid}}–Structure Interaction},
  booktitle = {Automated Solution of Differential Equations by the Finite Element Method, Volume 84 of Lecture Notes in Computational Science and Engineering},
  author = {Hoffman, Johan and Jansson, Johan and Jansson, Niclas and Johnson, C. and family=Abreu, given=Rodrigo V., prefix=de, useprefix=true},
  editor = {Logg, Anders and Mardal, Kent-Andre and Wells, Garth N.},
  date = {2012},
  publisher = {Springer}
}

@thesis{holkeScalableAlgorithmsParallel2018,
  title = {Scalable Algorithms for Parallel Tree-based Adaptive Mesh Refinement with General Element Types},
  author = {Holke, Johannes},
  date = {2018},
  langid = {ngerman},
  file = {/home/connor/.local/share/zotero/storage/HPILTEVL/Holke_2018_Scalable Algorithms for Parallel Tree-based Adaptive Mesh Refinement with.pdf}
}

@thesis{homolyaCodeGenerationTechniques2018,
  title = {On Code Generation Techniques for Finite Elements},
  author = {Homolya, Miklós},
  namea = {Ham, David and Mitchell, Lawrence and Imperial College London},
  nameatype = {collaborator},
  date = {2018-01},
  institution = {Imperial College London},
  url = {http://spiral.imperial.ac.uk/handle/10044/1/62636},
  urldate = {2021-10-08},
  abstract = {Efficient numerical solvers for partial differential equations are critical to vast fields of engineering and scientific research, including weather and climate prediction. State-of-the-art finite element discretisations, although offering many desirable properties, are often difficult to implement. Consequently, many developers of complicated finite element discretisations use code generation based software platforms. The form compiler is a key component of such software: it takes a high-level description of the weak form of partial differential equations and produces low-level code that carries out the finite element assembly. This thesis presents a novel, multi-stage code generation framework for the finite element method, implemented in the Two-Stage Form Compiler (TSFC). A core idea of TSFC is the introduction of a tensor algebra language as its intermediate representation. This creates a clean separation between the implementation of finite element objects and geometric terms as well as the problem of efficient code generation for tensor algebra expressions, which enables the maintenance of the structure of the input expression longer in the compiler pipeline than previous form compilers, and thus helps to facilitate the application of optimisations at the highest possible level of abstraction. The intermediate language is also proven to be a suitable medium and level of abstraction for numerous optimisations, including the expression and exploitation of structure intrinsic to some finite elements. This includes sum factorisation on cuboid cells for continuous, discontinuous, H(div) and H(curl) conforming elements. My experiments confirm optimal algorithmic complexity for high-order finite element assembly. This is achieved through several novel contributions: the introduction of a more powerful interface between the form compiler and the library providing the finite elements; a more abstract, smarter library of finite elements that explicitly communicates the structure of elements; and form compiler algorithms to automatically exploit this exposed structure.},
  file = {/home/connor/.local/share/zotero/storage/DEKMBKRQ/Homolya_2018_On code generation techniques for finite elements.pdf}
}

@unpublished{homolyaExposingExploitingStructure2017,
  title = {Exposing and Exploiting Structure: Optimal Code Generation for High-Order Finite Element Methods},
  shorttitle = {Exposing and Exploiting Structure},
  author = {Homolya, Miklós and Kirby, Robert C. and Ham, David A.},
  date = {2017-11-07},
  eprint = {1711.02473},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1711.02473},
  urldate = {2021-08-27},
  abstract = {Code generation based software platforms, such as Firedrake, have become popular tools for developing complicated finite element discretisations of partial differential equations. We extended the code generation infrastructure in Firedrake with optimisations that can exploit the structure inherent to some finite elements. This includes sum factorisation on cuboid cells for continuous, discontinuous, H(div) and H(curl) conforming elements. Our experiments confirm optimal algorithmic complexity for high-order finite element assembly. This is achieved through several novel contributions: the introduction of a more powerful interface between the form compiler and the library providing the finite elements; a more abstract, smarter library of finite elements called FInAT that explicitly communicates the structure of elements; and form compiler algorithms to automatically exploit this exposed structure.},
  keywords = {fiat,finat,finite-element-tabulation,firedrake,gem,tsfc},
  file = {/home/connor/OneDrive/AppData/Zotero/Homolya et al_2017_Exposing and exploiting structure.pdf;/home/connor/.local/share/zotero/storage/UUGBSVMS/1711.html}
}

@article{homolyaParallelEdgeOrientation2016,
  title = {A {{Parallel Edge Orientation Algorithm}} for {{Quadrilateral Meshes}}},
  author = {Homolya, M. and Ham, D. A.},
  date = {2016-01},
  journaltitle = {SIAM Journal on Scientific Computing},
  shortjournal = {SIAM J. Sci. Comput.},
  volume = {38},
  number = {5},
  pages = {S48-S61},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/15M1021325},
  url = {http://epubs.siam.org/doi/10.1137/15M1021325},
  urldate = {2021-06-29},
  abstract = {One approach to achieving correct finite element assembly is to ensure that the local orientation of facets relative to each cell in the mesh is consistent with the global orientation of that facet. Rognes et al. have shown how to achieve this for any mesh composed of simplex elements, and deal.II contains a serial algorithm for constructing a consistent orientation of any quadrilateral mesh of an orientable manifold. The core contribution of this paper is the extension of this algorithm for distributed memory parallel computers, which facilitates its seamless application as part of a parallel simulation system. Furthermore, our analysis establishes a link between the well-known Union-Find algorithm and the construction of a consistent orientation of a quadrilateral mesh. As a result, existing work on the parallelization of the Union-Find algorithm can be easily adapted to construct further parallel algorithms for mesh orientations.},
  langid = {english},
  keywords = {firedrake,orientation,quads},
  file = {/home/connor/.local/share/zotero/storage/2RJV2TDJ/Homolya and Ham - 2016 - A Parallel Edge Orientation Algorithm for Quadrila.pdf}
}

@article{homolyaTSFCStructurePreservingForm2018,
  title = {{{TSFC}}: {{A Structure-Preserving Form Compiler}}},
  shorttitle = {{{TSFC}}},
  author = {Homolya, Miklós and Mitchell, Lawrence and Luporini, Fabio and Ham, David A.},
  date = {2018-01},
  journaltitle = {SIAM Journal on Scientific Computing},
  shortjournal = {SIAM J. Sci. Comput.},
  volume = {40},
  number = {3},
  pages = {C401-C428},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/17M1130642},
  url = {https://epubs.siam.org/doi/10.1137/17M1130642},
  urldate = {2021-04-14},
  abstract = {A form compiler takes a high-level description of the weak form of partial differential equations and produces low-level code that carries out the finite element assembly. In this paper we present the Two-Stage Form Compiler (TSFC), a new form compiler with the main motivation being to maintain the structure of the input expression as long as possible. This facilitates the application of optimizations at the highest possible level of abstraction. TSFC features a novel, structure-preserving method for separating the contributions of a form to the subblocks of the local tensor in discontinuous Galerkin problems. This enables us to preserve the tensor structure of expressions longer through the compilation process than is possible with other form compilers. This is also achieved in part by a two-stage approach that cleanly separates the lowering of finite element constructs to tensor algebra in the first stage, from the scheduling of those tensor operations in the second stage. TSFC also efficiently traverses complicated expressions, and experimental evaluation demonstrates good compile-time performance even for highly complex forms.},
  langid = {english},
  keywords = {code-generation,tsfc},
  file = {/home/connor/Obsidian/30 Literature notes/homolyaTSFCStructurePreservingForm2018 - Extracted Annotations (19042021, 110652).md;/home/connor/Obsidian/30 Literature notes/homolyaTSFCStructurePreservingForm2018 - Summary.md;/home/connor/Obsidian/30 Literature notes/homolyaTSFCStructurePreservingForm2018-zotero.md;/home/connor/Obsidian/30 Literature notes/homolyaTSFCStructurePreservingForm2018.md;/home/connor/Obsidian/30 Literature notes/Zotero/homolyaTSFCStructurePreservingForm2018 - Extracted Annotations (19042021, 110652).md;/home/connor/Obsidian/30 Literature notes/Zotero/homolyaTSFCStructurePreservingForm2018 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/homolyaTSFCStructurePreservingForm2018-zotero.md;/home/connor/OneDrive/AppData/Zotero/Homolya et al_2018_TSFC.pdf}
}

@incollection{howesDerivingEfficientData2009,
  title = {Deriving {{Efficient Data Movement}} from {{Decoupled Access}}/{{Execute Specifications}}},
  booktitle = {High {{Performance Embedded Architectures}} and {{Compilers}}},
  author = {Howes, Lee W. and Lokhmotov, Anton and Donaldson, Alastair F. and Kelly, Paul H. J.},
  editor = {Seznec, André and Emer, Joel and O’Boyle, Michael and Martonosi, Margaret and Ungerer, Theo},
  date = {2009},
  volume = {5409},
  pages = {168--182},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-92990-1_14},
  url = {http://link.springer.com/10.1007/978-3-540-92990-1_14},
  urldate = {2021-05-12},
  abstract = {On multi-core architectures with software-managed memories, effectively orchestrating data movement is essential to performance, but is tedious and error-prone. In this paper we show that when the programmer can explicitly specify both the memory access pattern and the execution schedule of a computation kernel, the compiler or run-time system can derive efficient data movement, even if analysis of kernel code is difficult or impossible. We have developed a framework of C++ classes for decoupled Access/Execute specifications, allowing for automatic communication optimisations such as software pipelining and data reuse. We demonstrate the ease and efficiency of programming the Cell Broadband Engine architecture using these classes by implementing a set of benchmarks, which exhibit data reuse and non-affine access functions, and by comparing these implementations against alternative implementations, which use hand-written DMA transfers and software-based caching.},
  isbn = {978-3-540-92989-5 978-3-540-92990-1},
  langid = {english},
  keywords = {data-movement},
  file = {/home/connor/Obsidian/30 Literature notes/howesDerivingEfficientData2009.md;/home/connor/Obsidian/30 Literature notes/Zotero/howesDerivingEfficientData2009 - Extracted Annotations (18052021, 103944)In this paper, we introduce the decoupled AccessExecute (Æcute—pronounced.md;/home/connor/Obsidian/30 Literature notes/Zotero/howesDerivingEfficientData2009 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/howesDerivingEfficientData2009-zotero.md;/home/connor/OneDrive/AppData/Zotero/Howes et al_2009_Deriving Efficient Data Movement from Decoupled Access-Execute Specifications.pdf}
}

@online{hudakBuildingDomainSpecificEmbedded1996,
  title = {Building {{Domain-Specific Embedded Languages}}},
  author = {Hudak, Paul},
  date = {1996},
  url = {https://dl.acm.org/doi/fullHtml/10.1145/242224.242477},
  urldate = {2023-11-27},
  abstract = {A short treatise on how and why we should design domain-specific embedded languages to solve the problem of building and gracefully evolving large and complex software systems.},
  file = {/home/connor/.local/share/zotero/storage/B2THCGB2/_.pdf}
}

@article{hughesIsogeometricAnalysisCAD2005,
  title = {Isogeometric Analysis: {{CAD}}, Finite Elements, {{NURBS}}, Exact Geometry and Mesh Refinement},
  shorttitle = {Isogeometric Analysis},
  author = {Hughes, T.J.R. and Cottrell, J.A. and Bazilevs, Y.},
  date = {2005-10},
  journaltitle = {Computer Methods in Applied Mechanics and Engineering},
  shortjournal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {194},
  number = {39-41},
  pages = {4135--4195},
  issn = {00457825},
  doi = {10.1016/j.cma.2004.10.008},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0045782504005171},
  urldate = {2024-03-14},
  abstract = {The concept of isogeometric analysis is proposed. Basis functions generated from NURBS (Non-Uniform Rational B-Splines) are employed to construct an exact geometric model. For purposes of analysis, the basis is refined and/or its order elevated without changing the geometry or its parameterization. Analogues of finite element h- and p-refinement schemes are presented and a new, more efficient, higher-order concept, k-refinement, is introduced. Refinements are easily implemented and exact geometry is maintained at all levels without the necessity of subsequent communication with a CAD (Computer Aided Design) description. In the context of structural mechanics, it is established that the basis functions are complete with respect to affine transformations, meaning that all rigid body motions and constant strain states are exactly represented. Standard patch tests are likewise satisfied. Numerical examples exhibit optimal rates of convergence for linear elasticity problems and convergence to thin elastic shell solutions. A k-refinement strategy is shown to converge toward monotone solutions for advection–diffusion processes with sharp internal and boundary layers, a very surprising result. It is argued that isogeometric analysis is a viable alternative to standard, polynomial-based, finite element analysis and possesses several advantages.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/2873MKRQ/Hughes et al. - 2005 - Isogeometric analysis CAD, finite elements, NURBS.pdf}
}

@article{huTaichiLanguageHighperformance2019,
  title = {Taichi: A Language for High-Performance Computation on Spatially Sparse Data Structures},
  shorttitle = {Taichi},
  author = {Hu, Yuanming and Li, Tzu-Mao and Anderson, Luke and Ragan-Kelley, Jonathan and Durand, Frédo},
  date = {2019-12-31},
  journaltitle = {ACM Transactions on Graphics},
  shortjournal = {ACM Trans. Graph.},
  volume = {38},
  number = {6},
  pages = {1--16},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3355089.3356506},
  url = {https://dl.acm.org/doi/10.1145/3355089.3356506},
  urldate = {2022-09-15},
  abstract = {3D visual computing data are often spatially sparse. To exploit such sparsity, people have developed hierarchical sparse data structures, such as multi-level sparse voxel grids, particles, and 3D hash tables. However, developing and using these high-performance sparse data structures is challenging, due to their intrinsic complexity and overhead. We propose               Taichi               , a new data-oriented programming language for efficiently authoring, accessing, and maintaining such data structures. The language offers a high-level, data structure-agnostic interface for writing computation code. The user independently specifies the data structure. We provide several elementary components with different sparsity properties that can be arbitrarily composed to create a wide range of multi-level sparse data structures. This               decoupling               of data structures from computation makes it easy to experiment with different data structures without changing computation code, and allows users to write computation as if they are working with a dense array. Our compiler then uses the semantics of the data structure and index analysis to automatically optimize for locality, remove redundant operations for coherent accesses, maintain sparsity and memory allocations, and generate efficient parallel and vectorized instructions for CPUs and GPUs.                                         Our approach yields competitive performance on common computational kernels such as stencil applications, neighbor lookups, and particle scattering. We demonstrate our language by implementing simulation, rendering, and vision tasks including a material point method simulation, finite element analysis, a multigrid Poisson solver for pressure projection, volumetric path tracing, and 3D convolution on sparse grids. Our computation-data structure decoupling allows us to quickly experiment with different data arrangements, and to develop high-performance data structures tailored for specific computational tasks. With               1               {$<$}u{$>$}               1               {$<$}/u{$>$}               0               th as many lines of code, we achieve 4.55× higher performance on average, compared to hand-optimized reference implementations.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/572WXSJF/Hu et al. - 2019 - Taichi a language for high-performance computatio.pdf}
}

@inproceedings{irigoinSupernodePartitioning1988,
  title = {Supernode Partitioning},
  booktitle = {Proceedings of the 15th {{ACM SIGPLAN-SIGACT}} Symposium on {{Principles}} of Programming Languages},
  author = {Irigoin, François and Triolet, Rémi},
  date = {1988},
  pages = {319--329},
  file = {/home/connor/.local/share/zotero/storage/EQYBPR7G/73560.73588.pdf}
}

@unpublished{isaacSupportNonconformalMeshes2015,
  title = {Support for {{Non-conformal Meshes}} in {{PETSc}}'s {{DMPlex Interface}}},
  author = {Isaac, Tobin and Knepley, Matthew G.},
  date = {2015-08-10},
  eprint = {1508.02470},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1508.02470},
  urldate = {2021-06-04},
  abstract = {PETSc’s DMPlex interface for unstructured meshes has been extended to support non-conformal meshes. The topological construct that DMPlex implements—the CW-complex—is by definition conformal, so representing nonconformal meshes in a way that hides complexity requires careful attention to the interface between DMPlex and numerical methods such as the finite element method. Our approach—which combines a tree structure for subsetsuperset relationships and a “reference tree” describing the types of non-conformal interfaces—allows finite element code written for conformal meshes to extend automatically: in particular, all “hanging-node” constraint calculations are handled behind the scenes. We give example code demonstrating the use of this extension, and use it to convert forests of quadtrees and forests of octrees from the p4est library to DMPlex meshes.},
  langid = {english},
  keywords = {Computer Science - Mathematical Software},
  file = {/home/connor/.local/share/zotero/storage/S2PDX5FA/Isaac_Knepley_2015_Support for Non-conformal Meshes in PETSc's DMPlex Interface.pdf}
}

@online{ivanovRustFastBenchmarking2022,
  title = {Is {{Rust C}}++-Fast? {{Benchmarking System Languages}} on {{Everyday Routines}}},
  shorttitle = {Is {{Rust C}}++-Fast?},
  author = {Ivanov, Nikolay},
  date = {2022-09-19},
  eprint = {2209.09127},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2209.09127},
  urldate = {2022-09-20},
  abstract = {Rust is a relatively new system programming language that has been experiencing a rapid adoption in the past 10 years. Rust incorporates a memory ownership model enforced at a compile time. Since this model involves zero runtime overhead, programs written in Rust are not only memory-safe but also fast, leading to performance comparable to C and C++. Multiple existing benchmarks comparing the performance of Rust with other languages focus on rarely used superficial algorithms, leading to somewhat inconclusive results. In this work, we conduct a comparative performance benchmark of Rust and C++ using commonly used algorithms and data structures rather than exotic ones. Our evaluation shows that the overall performance of Rust is similar to C++, with only minor disadvantage. We also demonstrate that in some Rust routines are slightly faster than the ones of C++.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Performance,Computer Science - Programming Languages},
  file = {/home/connor/.local/share/zotero/storage/E6WQFCKW/Ivanov - 2022 - Is Rust C++-fast Benchmarking System Languages on.pdf}
}

@unpublished{jacquelinMassivelyScalableStencil2022,
  title = {Massively Scalable Stencil Algorithm},
  author = {Jacquelin, Mathias and Araya-Polo, Mauricio and Meng, Jie},
  date = {2022-04-07},
  eprint = {2204.03775},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2204.03775},
  urldate = {2022-04-11},
  abstract = {Stencil computations lie at the heart of many scientific and industrial applications. Unfortunately, stencil algorithms perform poorly on machines with cache based memory hierarchy, due to low re-use of memory accesses. This work shows that for stencil computation a novel algorithm that leverages a localized communication strategy effectively exploits the Cerebras WSE-2, which has no cache hierarchy. This study focuses on a 25-point stencil finite-difference method for the 3D wave equation, a kernel frequently used in earth modeling as numerical simulation. In essence, the algorithm trades memory accesses for data communication and takes advantage of the fast communication fabric provided by the architecture. The algorithm -- historically memory bound -- becomes compute bound. This allows the implementation to achieve near perfect weak scaling, reaching up to 503 TFLOPs on WSE-2, a figure that only full clusters can eventually yield.},
  keywords = {Computer Science - Mathematical Software},
  file = {/home/connor/OneDrive/AppData/Zotero/Jacquelin et al_2022_Massively scalable stencil algorithm.pdf;/home/connor/.local/share/zotero/storage/BXFA6USV/2204.html}
}

@article{JanssonJanssonEtAl2012a,
  title = {Framework for Massively Parallel Adaptive Finite Element Computational Fluid Dynamics on Tetrahedral Meshes},
  author = {Jansson, Niclas and Jansson, Johan and Hoffman, Johan},
  date = {2012},
  journaltitle = {SIAM Journal on Scientific Computing},
  volume = {34},
  number = {1},
  pages = {C24--C41}
}

@article{jongsmaDiscreteMathematicsChapter,
  title = {Discrete {{Mathematics}}: {{Chapter}} 7, {{Posets}}, {{Lattices}}, \& {{Boolean Algebra}}},
  author = {Jongsma, Calvin},
  pages = {82},
  abstract = {Algebra deals with more than computations such as addition or exponentiation; it also studies relations. Calculus touches on this a bit with locating extreme values and determining where functions increase and decrease; and in elementary algebra you occasionally “solve” inequalities involving the order relations of {$<$} or ≤ , but this almost seems like an intrusion foreign to the main focus, which is making algebraic calculations.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/NCHB2IQ8/Jongsma - Discrete Mathematics Chapter 7, Posets, Lattices,.pdf}
}

@misc{kaltofenSevenDwarfsSymbolic2011,
  title = {The “{{Seven Dwarfs}}” of {{Symbolic Computation}}},
  author = {Kaltofen, Erich L.},
  date = {2011},
  abstract = {We present the Seven Dwarfs of Symbolic Computation, which are sequential and parallel algorithmic methods that today carry a great majority of all exact and hybrid symbolic compute cycles. SymDwf 1. Exact linear algebra, integer lattices SymDwf 2. Exact polynomial and differential algebra, Gröbner bases SymDwf 3. Inverse symbolic problems, e.g., interpolation and parameterization SymDwf 4. Tarski’s algebraic theory of real geometry SymDwf 5. Hybrid symbolic-numeric computation SymDwf 6. Computation of closed form solutions SymDwf 7. Rewrite rule systems and computational group theory We will elaborate on each dwarf and compare with Colella’s seven and the Berkeley team’s thirteen dwarfs of scientific computing.},
  file = {/home/connor/OneDrive/AppData/Zotero/Kaltofen_2011_The “Seven Dwarfs” of Symbolic Computation.pdf;/home/connor/.local/share/zotero/storage/TNRC6UMN/download.html}
}

@online{karpExperienceAnalysisScalable2024,
  title = {Experience and {{Analysis}} of {{Scalable High-Fidelity Computational Fluid Dynamics}} on {{Modular Supercomputing Architectures}}},
  author = {Karp, Martin and Suarez, Estela and Meinke, Jan H. and Andersson, Måns I. and Schlatter, Philipp and Markidis, Stefano and Jansson, Niclas},
  date = {2024-05-09},
  eprint = {2405.05640},
  eprinttype = {arXiv},
  eprintclass = {physics},
  url = {http://arxiv.org/abs/2405.05640},
  urldate = {2024-05-13},
  abstract = {The never-ending computational demand from simulations of turbulence makes computational fluid dynamics (CFD) a prime application use case for current and future exascale systems. High-order finite element methods, such as the spectral element method, have been gaining traction as they offer high performance on both multicore CPUs and modern GPU-based accelerators. In this work, we assess how high-fidelity CFD using the spectral element method can exploit the modular supercomputing architecture at scale through domain partitioning, where the computational domain is split between a Booster module powered by GPUs and a Cluster module with conventional CPU nodes. We investigate several different flow cases and computer systems based on the Modular Supercomputing Architecture (MSA). We observe that for our simulations, the communication overhead and load balancing issues incurred by incorporating different computing architectures are seldom worthwhile, especially when I/O is also considered, but when the simulation at hand requires more than the combined global memory on the GPUs, utilizing additional CPUs to increase the available memory can be fruitful. We support our results with a simple performance model to assess when running across modules might be beneficial. As MSA is becoming more widespread and efforts to increase system utilization are growing more important our results give insight into when and how a monolithic application can utilize and spread out to more than one module and obtain a faster time to solution.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},C.1.4,Computer Science - Mathematical Software,G.4,J.2,Physics - Fluid Dynamics},
  file = {/home/connor/.local/share/zotero/storage/5X7FFRXU/Karp et al. - 2024 - Experience and Analysis of Scalable High-Fidelity .pdf}
}

@article{kimTensorDBTensorRelationalModel2014,
  title = {{{TensorDB}} and {{Tensor-Relational Model}} for {{Eﬃcient Tensor-Relational Operations}}},
  author = {Kim, Mijung},
  date = {2014},
  pages = {221},
  abstract = {Multidimensional data have various representations. Thanks to their simplicity in modeling multidimensional data and the availability of various mathematical tools (such as tensor decompositions) that support multi-aspect analysis of such data, tensors are increasingly being used in many application domains including scientific data management, sensor data management, and social network data analysis. Relational model, on the other hand, enables semantic manipulation of data using relational operators, such as projection, selection, Cartesian-product, and set operators. For many multidimensional data applications, tensor operations as well as relational operations need to be supported throughout the data life cycle. In this thesis, we introduce a tensor-based relational data model (TRM), which enables both tensorbased data analysis and relational manipulations of multidimensional data, and define tensor-relational operations on this model. Then we introduce a tensor-relational data management system, so called, TensorDB. TensorDB is based on TRM, which brings together relational algebraic operations (for data manipulation and integration) and tensor algebraic operations (for data analysis). We develop optimization strategies for tensor-relational operations in both in-memory and in-database TensorDB. The goal of the TRM and TensorDB is to serve as a single environment that supports the entire life cycle of data; that is, data can be manipulated, integrated, processed, and analyzed.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/4ZD8TGEM/Kim_for Eﬃcient Tensor-Relational Operations.pdf}
}

@incollection{Kirby2012a,
  title = {{{FIAT}}: {{Numerical}} Construction of Finite Element Basis Functions,},
  booktitle = {Automated Solution of Differential Equations by the Finite Element Method, Volume 84 of Lecture Notes in Computational Science and Engineering},
  author = {Kirby, Robert C.},
  editor = {Logg, Anders and Mardal, Kent-Andre and Wells, Garth N.},
  date = {2012},
  publisher = {Springer}
}

@article{kirbyAlgorithm839FIAT2004,
  title = {Algorithm 839: {{FIAT}}, a New Paradigm for Computing Finite Element Basis Functions},
  shorttitle = {Algorithm 839},
  author = {Kirby, Robert C.},
  date = {2004-12},
  journaltitle = {ACM Transactions on Mathematical Software},
  shortjournal = {ACM Trans. Math. Softw.},
  volume = {30},
  number = {4},
  pages = {502--516},
  issn = {0098-3500, 1557-7295},
  doi = {10.1145/1039813.1039820},
  url = {https://dl.acm.org/doi/10.1145/1039813.1039820},
  urldate = {2021-08-26},
  abstract = {Much of finite element computation is constrained by the difficulty of evaluating high-order nodal basis functions. While most codes rely on explicit formulae for these basis functions, we present a new approach that allows us to construct a general class of finite element basis functions from orthonormal polynomials and evaluate and differentiate them at any points. This approach relies on fundamental ideas from linear algebra and is implemented in Python using several object-oriented and functional programming techniques.},
  langid = {english},
  keywords = {fiat,finite-element-tabulation},
  file = {/home/connor/.local/share/zotero/storage/H4DTQT5J/Kirby_2004_Algorithm 839.pdf}
}

@article{kirbyFunctionalAnalysisIterative2010,
  title = {From {{Functional Analysis}} to {{Iterative Methods}}},
  author = {Kirby, Robert C.},
  date = {2010-01},
  journaltitle = {SIAM Review},
  shortjournal = {SIAM Rev.},
  volume = {52},
  number = {2},
  pages = {269--293},
  issn = {0036-1445, 1095-7200},
  doi = {10.1137/070706914},
  url = {http://epubs.siam.org/doi/10.1137/070706914},
  urldate = {2021-11-15},
  abstract = {We examine condition numbers, preconditioners, and iterative methods for finite element discretizations of coercive PDEs in the context of the fundamental solvability result, the Lax–Milgram lemma. Working in this Hilbert space context is justified because finite element operators are restrictions of infinite-dimensional Hilbert space operators to finitedimensional subspaces. Moreover, useful insight is gained as to the relationship between Hilbert space and matrix condition numbers, and translating Hilbert space fixed point iterations into matrix computations provides new ways of motivating and explaining some classic iteration schemes. In this framework, the “simplest” preconditioner for an operator from a Hilbert space into its dual is the Riesz isomorphism. Simple analysis gives spectral bounds and iteration counts bounded independent of the finite element subspaces chosen. Moreover, the abstraction allows us to consider not only Riesz map preconditioning for convection-diffusion equations in H1 but also operators on other Hilbert spaces, such as planar elasticity in H1 2.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/R38VTERJ/Kirby - 2010 - From Functional Analysis to Iterative Methods.pdf}
}

@article{KirbyKnepleyEtAl2005a,
  title = {Optimizing the Evaluation of Finite Element Matrices},
  author = {Kirby, Robert C. and Knepley, Matthew G. and Logg, Anders and Scott, L. Ridgway},
  date = {2005},
  journaltitle = {SIAM Journal on Scientific Computing},
  volume = {27},
  number = {3},
  pages = {741--758},
  doi = {10.1137/040607824}
}

@article{KirbyLogg2006a,
  title = {A Compiler for Variational Forms},
  author = {Kirby, Robert C. and Logg, Anders},
  date = {2006},
  journaltitle = {ACM Transactions on Mathematical Software},
  volume = {32},
  number = {3},
  eprint = {1112.0402},
  eprinttype = {arXiv},
  doi = {10.1145/1163641.1163644},
  file = {/home/connor/OneDrive/AppData/Zotero/Kirby_Logg_2006_A compiler for variational forms.pdf}
}

@article{KirbyLogg2007a,
  title = {Efficient Compilation of a Class of Variational Forms},
  author = {Kirby, Robert C. and Logg, Anders},
  date = {2007},
  journaltitle = {ACM Transactions on Mathematical Software},
  volume = {33},
  number = {3},
  doi = {10.1145/1268769.1268771}
}

@article{KirbyLogg2008a,
  title = {Benchmarking Domain-Specific Compiler Optimizations for Variational Forms},
  author = {Kirby, Robert C. and Logg, Anders},
  date = {2008},
  journaltitle = {ACM Transactions on Mathematical Software},
  volume = {35},
  number = {2},
  pages = {1--18},
  doi = {10.1145/1377612.1377614}
}

@article{KirbyLoggEtAl2006a,
  title = {Topological Optimization of the Evaluation of Finite Element Matrices},
  author = {Kirby, Robert C. and Logg, Anders and Scott, L. Ridgway and Terrel, Andy R.},
  date = {2006},
  journaltitle = {SIAM Journal on Scientific Computing},
  volume = {28},
  number = {1},
  pages = {224--240},
  doi = {10.1137/050635547}
}

@article{KirbyScott2007a,
  title = {Geometric Optimization of the Evaluation of Finite Element Matrices},
  author = {Kirby, Robert C. and Scott, L. Ridgway},
  date = {2007},
  journaltitle = {SIAM Journal on Scientific Computing},
  volume = {29},
  number = {2},
  pages = {827--841}
}

@article{kirbySolverCompositionPDE2018,
  title = {Solver {{Composition Across}} the {{PDE}}/{{Linear Algebra Barrier}}},
  author = {Kirby, Robert C. and Mitchell, Lawrence},
  date = {2018-01},
  journaltitle = {SIAM Journal on Scientific Computing},
  shortjournal = {SIAM J. Sci. Comput.},
  volume = {40},
  number = {1},
  pages = {C76-C98},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/17M1133208},
  url = {https://epubs.siam.org/doi/10.1137/17M1133208},
  urldate = {2020-10-15},
  abstract = {The efficient solution of discretizations of coupled systems of partial differential equations (PDEs) is at the core of much of numerical simulation. Significant effort has been expended on scalable algorithms to precondition Krylov iterations for the linear systems that arise. With few exceptions, the reported numerical implementation of such solution strategies is specific to a particular model setup, and intimately ties the solver strategy to the discretization and PDE, especially when the preconditioner requires auxiliary operators. In this paper, we present recent improvements in the Firedrake finite element library that allow for straightforward development of the building blocks of extensible, composable preconditioners that decouple the solver from the model formulation. Our implementation extends the algebraic composability of linear solvers offered by the PETSc library by augmenting operators, and hence preconditioners, with the ability to provide any necessary auxiliary operators. Rather than specifying up front the full solver configuration tied to the model, solvers can be developed independently of model formulation and configured at runtime. We illustrate with examples from incompressible fluids and temperature-driven convection.},
  langid = {english},
  keywords = {firedrake,matrix-free,petsc,preconditioner,READNEXT,ufl},
  file = {/home/connor/Obsidian/30 Literature notes/kirbySolverCompositionPDE2018 - Summary.md;/home/connor/Obsidian/30 Literature notes/kirbySolverCompositionPDE2018 - This paper references the poor vector performance of matrix-free methods solved in Sun et al. (2020)..md;/home/connor/Obsidian/30 Literature notes/kirbySolverCompositionPDE2018-zotero.md;/home/connor/Obsidian/30 Literature notes/kirbySolverCompositionPDE2018.md;/home/connor/Obsidian/30 Literature notes/Zotero/kirbySolverCompositionPDE2018 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/kirbySolverCompositionPDE2018 - This paper references the poor vector performance of matrix-free methods solved in Sun et al. (2020)..md;/home/connor/Obsidian/30 Literature notes/Zotero/kirbySolverCompositionPDE2018-zotero.md;/home/connor/OneDrive/AppData/Zotero/Kirby_Mitchell_2018_Solver Composition Across the PDE-Linear Algebra Barrier.pdf}
}

@article{kjolstadSimitLanguagePhysical2016,
  title = {Simit: {{A Language}} for {{Physical Simulation}}},
  shorttitle = {Simit},
  author = {Kjolstad, Fredrik and Kamil, Shoaib and Ragan-Kelley, Jonathan and Levin, David I. W. and Sueda, Shinjiro and Chen, Desai and Vouga, Etienne and Kaufman, Danny M. and Kanwar, Gurtej and Matusik, Wojciech and Amarasinghe, Saman},
  date = {2016-05-25},
  journaltitle = {ACM Transactions on Graphics},
  shortjournal = {ACM Trans. Graph.},
  volume = {35},
  number = {2},
  pages = {1--21},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/2866569},
  url = {https://dl.acm.org/doi/10.1145/2866569},
  urldate = {2022-03-29},
  abstract = {With existing programming tools, writing high-performance simulation code is labor intensive and requires sacrificing readability and portability. The alternative is to prototype simulations in a high-level language like Matlab, thereby sacrificing performance. The Matlab programming model naturally describes the behavior of an entire physical system using the language of linear algebra. However, simulations also manipulate individual geometric elements, which are best represented using linked data structures like meshes. Translating between the linked data structures and linear algebra comes at significant cost, both to the programmer and to the machine. High-performance implementations avoid the cost by rephrasing the computation in terms of linked or index data structures, leaving the code complicated and monolithic, often increasing its size by an order of magnitude.             In this article, we present Simit, a new language for physical simulations that lets the programmer view the system both as a linked data structure in the form of a hypergraph and as a set of global vectors, matrices, and tensors depending on what is convenient at any given time. Simit provides a novel assembly construct that makes it conceptually easy and computationally efficient to move between the two abstractions. Using the information provided by the assembly construct, the compiler generates efficient in-place computation on the graph. We demonstrate that Simit is easy to use: a Simit program is typically shorter than a Matlab program; that it is high performance: a Simit program running sequentially on a CPU performs comparably to hand-optimized simulations; and that it is portable: Simit programs can be compiled for GPUs with no change to the program, delivering 4 to 20× speedups over our optimized CPU code.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/MY5T3L7V/Kjolstad et al_2016_Simit.pdf}
}

@inproceedings{kjolstadTacoToolGenerate2017,
  title = {Taco: {{A}} Tool to Generate Tensor Algebra Kernels},
  shorttitle = {Taco},
  booktitle = {2017 32nd {{IEEE}}/{{ACM International Conference}} on {{Automated Software Engineering}} ({{ASE}})},
  author = {Kjolstad, Fredrik and Chou, Stephen and Lugato, David and Kamil, Shoaib and Amarasinghe, Saman},
  date = {2017-10},
  pages = {943--948},
  publisher = {IEEE},
  location = {Urbana, IL},
  doi = {10.1109/ASE.2017.8115709},
  url = {http://ieeexplore.ieee.org/document/8115709/},
  urldate = {2022-04-07},
  abstract = {Tensor algebra is an important computational abstraction that is increasingly used in data analytics, machine learning, engineering, and the physical sciences. However, the number of tensor expressions is unbounded, which makes it hard to develop and optimize libraries. Furthermore, the tensors are often sparse (most components are zero), which means the code has to traverse compressed formats. To support programmers we have developed taco, a code generation tool that generates dense, sparse, and mixed kernels from tensor algebra expressions. This paper describes the taco web and command-line tools and discusses the benefits of a code generator over a traditional library approach.},
  eventtitle = {2017 32nd {{IEEE}}/{{ACM International Conference}} on {{Automated Software Engineering}} ({{ASE}})},
  isbn = {978-1-5386-2684-9},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/46MBUU9G/Kjolstad et al_2017_Taco.pdf}
}

@inproceedings{klocknerArrayProgramTransformation2016,
  title = {Array Program Transformation with {{Loo}}.Py by Example: High-Order Finite Elements},
  shorttitle = {Array Program Transformation with {{Loo}}.Py by Example},
  booktitle = {Proceedings of the 3rd {{ACM SIGPLAN International Workshop}} on {{Libraries}}, {{Languages}}, and {{Compilers}} for {{Array Programming}} - {{ARRAY}} 2016},
  author = {Klöckner, Andreas and Wilcox, Lucas C. and Warburton, T.},
  date = {2016},
  pages = {9--16},
  publisher = {ACM Press},
  location = {Santa Barbara, CA, USA},
  doi = {10.1145/2935323.2935325},
  url = {http://dl.acm.org/citation.cfm?doid=2935323.2935325},
  urldate = {2020-10-14},
  abstract = {To concisely and effectively demonstrate the capabilities of our program transformation system Loo.py, we examine a transformation path from two real-world Fortran subroutines as found in a weather model to a single high-performance computational kernel suitable for execution on modern GPU hardware. Along the transformation path, we encounter kernel fusion, vectorization, prefetching, parallelization, and algorithmic changes achieved by mechanized conversion between imperative and functional/substitutionbased code, among a number more. We conclude with performance results that demonstrate the effects and support the effectiveness of the applied transformations.},
  eventtitle = {The 3rd {{ACM SIGPLAN International Workshop}}},
  isbn = {978-1-4503-4384-8},
  langid = {english},
  keywords = {gpu,loopy,weather-modelling},
  file = {/home/connor/Obsidian/30 Literature notes/klocknerArrayProgramTransformation2016 - Summary.md;/home/connor/Obsidian/30 Literature notes/klocknerArrayProgramTransformation2016-zotero.md;/home/connor/Obsidian/30 Literature notes/klocknerArrayProgramTransformation2016.md;/home/connor/Obsidian/30 Literature notes/Zotero/klocknerArrayProgramTransformation2016 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/klocknerArrayProgramTransformation2016-zotero.md;/home/connor/OneDrive/AppData/Zotero/Klöckner et al_2016_Array program transformation with Loo.pdf}
}

@inproceedings{klocknerLooPyFortran2015,
  title = {Loo.Py: From Fortran to Performance via Transformation and Substitution Rules},
  shorttitle = {Loo.Py},
  booktitle = {Proceedings of the 2nd {{ACM SIGPLAN International Workshop}} on {{Libraries}}, {{Languages}}, and {{Compilers}} for {{Array Programming}} - {{ARRAY}} 2015},
  author = {Klöckner, Andreas},
  date = {2015},
  pages = {1--6},
  publisher = {ACM Press},
  location = {Portland, OR, USA},
  doi = {10.1145/2774959.2774969},
  url = {http://dl.acm.org/citation.cfm?doid=2774959.2774969},
  urldate = {2020-12-04},
  abstract = {A large amount of numerically-oriented code is written and is being written in legacy languages. Much of this code could, in principle, make good use of data-parallel throughput-oriented computer architectures. Loo.py, a transformation-based programming system targeted at GPUs and general data-parallel architectures, provides a mechanism for user-controlled transformation of array programs. This transformation capability is designed to not just apply to programs written specifically for Loo.py, but also those imported from other languages such as Fortran. It eases the trade-off between achieving high performance, portability, and programmability by allowing the user to apply a large and growing family of transformations to an input program. These transformations are expressed in and used from Python and may be applied from a variety of settings, including a pragma-like manner from other languages.},
  eventtitle = {The 2nd {{ACM SIGPLAN International Workshop}}},
  isbn = {978-1-4503-3584-3},
  langid = {english},
  keywords = {code-generation,fortran,loopy},
  file = {/home/connor/Obsidian/30 Literature notes/klocknerLooPyFortran2015 - Extracted Annotations (26052021, 113712)One salient feature of Loo.py is that programs written in it necessarily co.md;/home/connor/Obsidian/30 Literature notes/klocknerLooPyFortran2015 - Summary.md;/home/connor/Obsidian/30 Literature notes/klocknerLooPyFortran2015-zotero.md;/home/connor/Obsidian/30 Literature notes/klocknerLooPyFortran2015.md;/home/connor/Obsidian/30 Literature notes/Zotero/klocknerLooPyFortran2015 - Extracted Annotations (26052021, 113712)One salient feature of Loo.py is that programs written in it necessarily co.md;/home/connor/Obsidian/30 Literature notes/Zotero/klocknerLooPyFortran2015 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/klocknerLooPyFortran2015-zotero.md;/home/connor/OneDrive/AppData/Zotero/Klöckner_2015_Loo.pdf}
}

@article{klocknerLooPyTransformationbased2014,
  title = {Loo.Py: Transformation-Based Code Generation for {{GPUs}} and {{CPUs}}},
  shorttitle = {Loo.Py},
  author = {Klöckner, Andreas},
  date = {2014},
  journaltitle = {Proceedings of ACM SIGPLAN International Workshop on Libraries, Languages, and Compilers for Array Programming - ARRAY'14},
  eprint = {1405.7470},
  eprinttype = {arXiv},
  pages = {82--87},
  doi = {10.1145/2627373.2627387},
  url = {http://arxiv.org/abs/1405.7470},
  urldate = {2020-10-14},
  abstract = {Today’s highly heterogeneous computing landscape places a burden on programmers wanting to achieve high performance on a reasonably broad cross-section of machines. To do so, computations need to be expressed in many different but mathematically equivalent ways, with, in the worst case, one variant per target machine.},
  langid = {english},
  keywords = {gpu,loopy,opencl},
  file = {/home/connor/Obsidian/30 Literature notes/klocknerLooPyTransformationbased2014 - Summary.md;/home/connor/Obsidian/30 Literature notes/klocknerLooPyTransformationbased2014-zotero.md;/home/connor/Obsidian/30 Literature notes/klocknerLooPyTransformationbased2014.md;/home/connor/Obsidian/30 Literature notes/Zotero/klocknerLooPyTransformationbased2014 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/klocknerLooPyTransformationbased2014-zotero.md;/home/connor/OneDrive/AppData/Zotero/Klöckner_2014_Loo.pdf}
}

@article{klocknerPyCUDAPyOpenCLScriptingbased2012,
  title = {{{PyCUDA}} and {{PyOpenCL}}: {{A}} Scripting-Based Approach to {{GPU}} Run-Time Code Generation},
  shorttitle = {{{PyCUDA}} and {{PyOpenCL}}},
  author = {Klöckner, Andreas and Pinto, Nicolas and Lee, Yunsup and Catanzaro, Bryan and Ivanov, Paul and Fasih, Ahmed},
  date = {2012-03},
  journaltitle = {Parallel Computing},
  shortjournal = {Parallel Computing},
  volume = {38},
  number = {3},
  pages = {157--174},
  issn = {01678191},
  doi = {10.1016/j.parco.2011.09.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167819111001281},
  urldate = {2020-12-04},
  abstract = {High-performance computing has recently seen a surge of interest in heterogeneous systems, with an emphasis on modern Graphics Processing Units (GPUs). These devices offer tremendous potential for performance and efficiency in important large-scale applications of computational science. However, exploiting this potential can be challenging, as one must adapt to the specialized and rapidly evolving computing environment currently exhibited by GPUs. One way of addressing this challenge is to embrace better techniques and develop tools tailored to their needs. This article presents one simple technique, GPU run-time code generation (RTCG), along with PyCUDA and PyOpenCL, two open-source toolkits that supports this technique.},
  langid = {english},
  keywords = {code-generation,gpu,opencl},
  file = {/home/connor/Obsidian/30 Literature notes/klocknerPyCUDAPyOpenCLScriptingbased2012 - Summary.md;/home/connor/Obsidian/30 Literature notes/klocknerPyCUDAPyOpenCLScriptingbased2012-zotero.md;/home/connor/Obsidian/30 Literature notes/klocknerPyCUDAPyOpenCLScriptingbased2012.md;/home/connor/Obsidian/30 Literature notes/Zotero/klocknerPyCUDAPyOpenCLScriptingbased2012 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/klocknerPyCUDAPyOpenCLScriptingbased2012-zotero.md;/home/connor/OneDrive/AppData/Zotero/Klöckner et al_2012_PyCUDA and PyOpenCL.pdf}
}

@article{knepleyAccuratelyCitingSoftware,
  title = {Accurately {{Citing Software}} and {{Algorithms Used}} in {{Publications}}},
  author = {Knepley, Matthew G and Brown, Jed and McInnes, Lois Curfman and Smith, Barry},
  abstract = {Properly citing academic publications that describe software libraries and algorithms is the way that open source scientific library users “pay” to use the free software. With large multifaceted libraries and applications that use several such libraries, even the conscientious user ends up citing publications in error or missing relevant publications. Some open source developers list appropriate citations on their website or in their documentation. Based on a recent addition to the PETSc numerical software libraries, we suggest an alternative model where the library itself generates the bibtex items based on exactly what algorithms and portions of the code are used in the application.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/KS4D9JZI/Knepley et al. - Accurately Citing Software and Algorithms Used in .pdf}
}

@unpublished{knepleyAchievingHighPerformance2013,
  title = {Achieving {{High Performance}} with {{Unified Residual Evaluation}}},
  author = {Knepley, Matthew G. and Brown, Jed and Rupp, Karl and Smith, Barry F.},
  date = {2013-09-06},
  eprint = {1309.1204},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1309.1204},
  urldate = {2022-02-03},
  abstract = {We examine residual evaluation, perhaps the most basic operation in numerical simulation. By raising the level of abstraction in this operation, we can eliminate specialized code, enable optimization, and greatly increase the extensibility of existing code.},
  keywords = {{Computer Science - Computational Engineering, Finance, and Science},Computer Science - Mathematical Software},
  file = {/home/connor/OneDrive/AppData/Zotero/Knepley et al_2013_Achieving High Performance with Unified Residual Evaluation.pdf;/home/connor/.local/share/zotero/storage/PVCMST5U/1309.html}
}

@book{knepleyComputationalScienceLecture2017,
  title = {Computational {{Science I}}, {{Lecture Notes}} for {{CAAM}} 519},
  author = {Knepley, Matthew G.},
  date = {2017},
  publisher = {{Department of Computational and Applied Mathematics, William Marsh Rice University, Houston, TX}},
  url = {https://cse.buffalo.edu/~knepley/classes/caam519/CSBook.pdf},
  urldate = {2021-06-18},
  file = {/home/connor/.local/share/zotero/storage/7353C5KB/CSBook.pdf}
}

@article{knepleyExascaleComputingThreads2015,
  title = {Exascale {{Computing}} without {{Threads}}},
  author = {Knepley, Matthew G and Brown, Jed and McInnes, Lois Curfman and Smith, Barry and Rupp, Karl and Adams, Mark},
  date = {2015},
  pages = {2},
  abstract = {We provide technical details on why we feel the use of threads does not offer any fundamental performance advantage over using processes for high-performance computing and hence why we plan to extend PETSc to exascale (on emerging architectures) using node-aware MPI techniques, including neighborhood collectives and portable shared memory within a node, instead of threads.},
  langid = {english},
  keywords = {mpi,openmp,petsc,shared-memory},
  file = {/home/connor/.local/share/zotero/storage/8RX4HDB5/Knepley et al. - Exascale Computing without Threads˚.pdf}
}

@unpublished{knepleyMeshAlgorithmsPDE2009,
  title = {Mesh {{Algorithms}} for {{PDE}} with {{Sieve I}}: {{Mesh Distribution}}},
  shorttitle = {Mesh {{Algorithms}} for {{PDE}} with {{Sieve I}}},
  author = {Knepley, Matthew G. and Karpeev, Dmitry A.},
  date = {2009-08-30},
  eprint = {0908.4427},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.3233/SPR-2009-0249},
  url = {http://arxiv.org/abs/0908.4427},
  urldate = {2021-02-16},
  abstract = {We have developed a new programming framework, called Sieve, to support parallel numerical PDE1 algorithms operating over distributed meshes. We have also developed a reference implementation of Sieve in C++ as a library of generic algorithms operating on distributed containers conforming to the Sieve interface. Sieve makes instances of the incidence relation, or arrows, the conceptual first-class objects represented in the containers. Further, generic algorithms acting on this arrow container are systematically used to provide natural geometric operations on the topology and also, through duality, on the data. Finally, coverings and duality are used to encode not only individual meshes, but all types of hierarchies underlying PDE data structures, including multigrid and mesh partitions.},
  langid = {english},
  keywords = {unstructured-mesh},
  file = {/home/connor/Obsidian/30 Literature notes/knepleyMeshAlgorithmsPDE2009 - Comment 36 pages, 22 figures.md;/home/connor/Obsidian/30 Literature notes/knepleyMeshAlgorithmsPDE2009 - Extracted Annotations (18052021, 103526)Our Sieve framework, is a collection of interfaces and algorithms for manip.md;/home/connor/Obsidian/30 Literature notes/knepleyMeshAlgorithmsPDE2009 - Summary.md;/home/connor/Obsidian/30 Literature notes/knepleyMeshAlgorithmsPDE2009-zotero.md;/home/connor/Obsidian/30 Literature notes/knepleyMeshAlgorithmsPDE2009.md;/home/connor/Obsidian/30 Literature notes/Zotero/knepleyMeshAlgorithmsPDE2009 - Comment 36 pages, 22 figures.md;/home/connor/Obsidian/30 Literature notes/Zotero/knepleyMeshAlgorithmsPDE2009 - Extracted Annotations (18052021, 103526)Our Sieve framework, is a collection of interfaces and algorithms for manip.md;/home/connor/Obsidian/30 Literature notes/Zotero/knepleyMeshAlgorithmsPDE2009 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/knepleyMeshAlgorithmsPDE2009-zotero.md;/home/connor/OneDrive/AppData/Zotero/Knepley_Karpeev_2009_Mesh Algorithms for PDE with Sieve I.pdf}
}

@book{knepleyProgrammingLanguagesScientific2015,
  title = {Programming {{Languages}} for {{Scientific Computing}}},
  author = {Knepley, Matthew G.},
  date = {2015},
  eprint = {1209.1711},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.1007/978-3-540-70529-1},
  url = {http://arxiv.org/abs/1209.1711},
  urldate = {2023-03-23},
  abstract = {Scientific computation is a discipline that combines numerical analysis, physical understanding, algorithm development, and structured programming. Several yottacycles per year on the world's largest computers are spent simulating problems as diverse as weather prediction, the properties of material composites, the behavior of biomolecules in solution, and the quantum nature of chemical compounds. This article is intended to review specfic languages features and their use in computational science. We will review the strengths and weaknesses of different programming styles, with examples taken from widely used scientific codes.},
  langid = {english},
  keywords = {{Computer Science - Computational Engineering, Finance, and Science},Computer Science - Mathematical Software,Computer Science - Programming Languages},
  file = {/home/connor/.local/share/zotero/storage/UNY6TDU4/Knepley - 2015 - Programming Languages for Scientific Computing.pdf}
}

@unpublished{knepleyUnstructuredOverlappingMesh2015,
  title = {Unstructured {{Overlapping Mesh Distribution}} in {{Parallel}}},
  author = {Knepley, Matthew G. and Lange, Michael and Gorman, Gerard J.},
  date = {2015-06-19},
  eprint = {1506.06194},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/1506.06194},
  urldate = {2021-02-16},
  abstract = {We present a simple mathematical framework and API for parallel mesh and data distribution, load balancing, and overlap generation. It relies on viewing the mesh as a Hasse diagram, abstracting away information such as cell shape, dimension, and coordinates. The high level of abstraction makes our interface both concise and powerful, as the same algorithm applies to any representable mesh, such as hybrid meshes, meshes embedded in higher dimension, and overlapped meshes in parallel. We present evidence, both theoretical and experimental, that the algorithms are scalable and efficient. A working implementation can be found in the latest release of the PETSc libraries.},
  langid = {english},
  keywords = {dmplex,petsc,petsc-star-forest,unstructured-mesh},
  file = {/home/connor/Obsidian/30 Literature notes/knepleyUnstructuredOverlappingMesh2015 - Comment 14 pages, 6 figures, submitted to TOMS.md;/home/connor/Obsidian/30 Literature notes/knepleyUnstructuredOverlappingMesh2015 - Extracted Annotations (04052021, 160617).md;/home/connor/Obsidian/30 Literature notes/knepleyUnstructuredOverlappingMesh2015 - Summary.md;/home/connor/Obsidian/30 Literature notes/knepleyUnstructuredOverlappingMesh2015-zotero.md;/home/connor/Obsidian/30 Literature notes/knepleyUnstructuredOverlappingMesh2015.md;/home/connor/Obsidian/30 Literature notes/Zotero/knepleyUnstructuredOverlappingMesh2015 - Comment 14 pages, 6 figures, submitted to TOMS.md;/home/connor/Obsidian/30 Literature notes/Zotero/knepleyUnstructuredOverlappingMesh2015 - Extracted Annotations (04052021, 160617).md;/home/connor/Obsidian/30 Literature notes/Zotero/knepleyUnstructuredOverlappingMesh2015 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/knepleyUnstructuredOverlappingMesh2015-zotero.md;/home/connor/OneDrive/AppData/Zotero/Knepley et al_2015_Unstructured Overlapping Mesh Distribution in Parallel.pdf}
}

@article{kohlHyTeGFiniteelementSoftware2019,
  title = {The {{{\emph{HyTeG}}}} Finite-Element Software Framework for Scalable Multigrid Solvers},
  author = {Kohl, Nils and Thönnes, Dominik and Drzisga, Daniel and Bartuschat, Dominik and Rüde, Ulrich},
  date = {2019-09-03},
  journaltitle = {International Journal of Parallel, Emergent and Distributed Systems},
  shortjournal = {International Journal of Parallel, Emergent and Distributed Systems},
  volume = {34},
  number = {5},
  pages = {477--496},
  issn = {1744-5760, 1744-5779},
  doi = {10.1080/17445760.2018.1506453},
  url = {https://www.tandfonline.com/doi/full/10.1080/17445760.2018.1506453},
  urldate = {2022-08-18},
  abstract = {In this article, a new generic higher-order finite-element framework for massively parallel simulations is presented. The modular software architecture is carefully designed to exploit the resources of modern and future supercomputers. Combining an unstructured topology with structured grid refinement facilitates high geometric adaptability and matrixfree multigrid implementations with excellent performance. Different abstraction levels and fully distributed data structures additionally ensure high flexibility, extensibility, and scalability. The software concepts support sophisticated load balancing and flexibly combining finite-element spaces. Example scenarios with coupled systems of partial differential equations show the applicability of the concepts to performing geophysical simulations.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/CWAXUCK5/Kohl et al. - 2019 - The HyTeG finite-element software framework.pdf}
}

@article{kohlTextbookEfficiencyMassively2022,
  title = {Textbook {{Efficiency}}: {{Massively Parallel Matrix-Free Multigrid}} for the {{Stokes System}}},
  shorttitle = {Textbook {{Efficiency}}},
  author = {Kohl, Nils and Rüde, Ulrich},
  date = {2022-04},
  journaltitle = {SIAM Journal on Scientific Computing},
  shortjournal = {SIAM J. Sci. Comput.},
  volume = {44},
  number = {2},
  pages = {C124-C155},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/20M1376005},
  url = {https://epubs.siam.org/doi/10.1137/20M1376005},
  urldate = {2022-08-19},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/I7UUR4C3/Kohl and Rüde - 2022 - Textbook Efficiency Massively Parallel Matrix-Fre.pdf}
}

@article{komatsuEvaluatingPerformancePortability2010,
  title = {Evaluating {{Performance}} and {{Portability}} of {{OpenCL Programs}}},
  author = {Komatsu, Kazuhiko and Sato, Katsuto and Arai, Yusuke and Koyama, Kentaro and Takizawa, Hiroyuki and Kobayashi, Hiroaki},
  date = {2010-01},
  pages = {16},
  abstract = {Recently, OpenCL, a new open programming standard for GPGPU programming, has become available in addition to CUDA. OpenCL can support various compute devices due to its higher abstraction programming framework. Since there is a semantic gap between OpenCL and compute devices, the OpenCL C compiler plays important roles to exploit the potential of compute devices and therefore its capability should be clarified. In this paper, the performance of CUDA and OpenCL programs is quantitatively evaluated. First, several CUDA and OpenCL programs of almost the same computations are developed, and their performances are compared. Then, the main factors causing their performance differences is investigated. The evaluation results suggest that the performances of OpenCL programs are comparable with those of CUDA ones if the kernel codes are appropriately optimized by hand or by the compiler optimizations. This paper also discusses the differences between NVIDIA and AMD OpenCL implementations by comparing the performances of their GPUs for the same programs. The performance comparison shows that the compiler options of the OpenCL C compiler and the execution configuration parameters have to be optimized for each GPU to obtain its best performance. Therefore, automatic parameter tuning is essential to enable a single OpenCL code to run efficiently on various GPUs.},
  langid = {english},
  keywords = {cuda,gpu,opencl,performance-portability},
  file = {/home/connor/Obsidian/30 Literature notes/komatsuEvaluatingPerformancePortability2010 - Extracted Annotations (01062021, 114042)However, although OpenCL allows a programmer to use various compute devices.md;/home/connor/Obsidian/30 Literature notes/komatsuEvaluatingPerformancePortability2010 - Summary.md;/home/connor/Obsidian/30 Literature notes/komatsuEvaluatingPerformancePortability2010-zotero.md;/home/connor/Obsidian/30 Literature notes/komatsuEvaluatingPerformancePortability2010.md;/home/connor/Obsidian/30 Literature notes/Zotero/komatsuEvaluatingPerformancePortability2010 - Extracted Annotations (01062021, 114042)However, although OpenCL allows a programmer to use various compute devices.md;/home/connor/Obsidian/30 Literature notes/Zotero/komatsuEvaluatingPerformancePortability2010 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/komatsuEvaluatingPerformancePortability2010-zotero.md;/home/connor/OneDrive/AppData/Zotero/Komatsu et al_2010_Evaluating Performance and Portability of OpenCL Programs.pdf}
}

@article{krawiecProvablyCorrectAsymptotically2022,
  title = {Provably Correct, Asymptotically Efficient, Higher-Order Reverse-Mode Automatic Differentiation},
  author = {Krawiec, Faustyna and Peyton Jones, Simon and Krishnaswami, Neel and Ellis, Tom and Eisenberg, Richard A. and Fitzgibbon, Andrew},
  date = {2022-01-16},
  journaltitle = {Proceedings of the ACM on Programming Languages},
  shortjournal = {Proc. ACM Program. Lang.},
  volume = {6},
  pages = {1--30},
  issn = {2475-1421},
  doi = {10.1145/3498710},
  url = {https://dl.acm.org/doi/10.1145/3498710},
  urldate = {2022-01-20},
  abstract = {In this paper, we give a simple and efficient implementation of reverse-mode automatic differentiation, which both extends easily to higher-order functions, and has run time and memory consumption linear in the run time of the original program. In addition to a formal description of the translation, we also describe an implementation of this algorithm, and prove its correctness by means of a logical relations argument.},
  issue = {POPL},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/PPI627TI/Krawiec et al. - 2022 - Provably correct, asymptotically efficient, higher.pdf}
}

@thesis{kriegerGeneralizedFullSparse2013,
  title = {Generalized {{Full Sparse Tiling}} of {{Loop Chains}}},
  author = {Krieger, Christopher D},
  date = {2013},
  institution = {Colorado State University},
  abstract = {Computer and computational scientists are tackling increasingly large and complex prob-lems and are seeking ways of improving the performance of their codes.  The key issue facedis  how  to  reach  an  effective  balance  between  parallelism  and  locality.   In  trying  to  reachthis balance, a problem commonly encountered is that of ascertaining the data dependences.Approaches that rely on automatic extraction of data dependences are frequently stymiedby complications such as interprocedural and alias analysis.  Placing the dependence analysisburden upon the programmer creates a significant barrier to adoption.In this work, we present a new programming abstraction, theloop  chain, that specifiesa series of loops and the data they access.  Given this abstraction, a compiler, inspector, orruntime optimizer can avoid the computationally expensive process of formally determiningdata dependences, yet still determine beneficial and legal data and iteration reorderings.One optimization method that has been previously applied to irregular scientific codes isfull sparse tiling.  Full sparse tiling has been used to improve the performance of a handfulof  scientific  codes,  but  in  each  case  the  technique  had  to  be  applied  from  scratch  by  anexpert  after  careful  manual  analysis  of  the  possible  data  dependence  patterns.   The  fullsparse tiling approach was extended and generalized as part of this work to apply to anycode represented by the loop chain abstraction.  Using only the abstraction, the generalizedalgorithm  can  produce  a  new  data  and  iteration  ordering  as  well  as  a  parallel  executionschedule.Insight into tuning a generalized full sparse tiled application was gained through a studyof the different factors influencing tile count.  This work lays the foundation for an efficient  autotuning approach to optimizing tile count.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/GIL6YE2Z/Krieger - GENERALIZED FULL SPARSE TILING OF LOOP CHAINS.pdf}
}

@inproceedings{kriegerLoopChainingProgramming2013,
  title = {Loop {{Chaining}}: {{A Programming Abstraction}} for {{Balancing Locality}} and {{Parallelism}}},
  shorttitle = {Loop {{Chaining}}},
  booktitle = {2013 {{IEEE International Symposium}} on {{Parallel}} \& {{Distributed Processing}}, {{Workshops}} and {{Phd Forum}}},
  author = {Krieger, Christopher D. and Strout, Michelle Mills and Olschanowsky, Catherine and Stone, Andrew and Guzik, Stephen and Gao, Xinfeng and Bertolli, Carlo and Kelly, Paul H. J. and Mudalige, Gihan and Van Straalen, Brian and Williams, Sam},
  date = {2013-05},
  pages = {375--384},
  publisher = {IEEE},
  location = {Cambridge, MA, USA},
  doi = {10.1109/IPDPSW.2013.68},
  url = {http://ieeexplore.ieee.org/document/6650909/},
  urldate = {2021-06-03},
  abstract = {There is a significant, established code base in the scientific computing community. Some of these codes have been parallelized already but are now encountering scalability issues due to poor data locality, inefficient data distributions, or load imbalance. In this work, we introduce a new abstraction called loop chaining in which a sequence of parallel and/or reduction loops that explicitly share data are grouped together into a chain. Once specified, a chain of loops can be viewed as a set of iterations under a partial ordering. This partial ordering is dictated by data dependencies that, as part of the abstraction, are exposed, thereby avoiding inter-procedural program analysis. Thus a loop chain is a partially ordered set of iterations that makes scheduling and determining data distributions across loops possible for a compiler and/or run-time system. The flexibility of being able to schedule across loops enables better management of the data locality and parallelism tradeoff. In this paper, we define the loop chaining concept and present three case studies using loop chains in scientific codes: the sparse matrix Jacobi benchmark, a domain-specific library, OP2, used in full applications with unstructured grids, and a domain-specific library, Chombo, used in full applications with structured grids. Preliminary results for the Jacobi benchmark show that a loop chain enabled optimization, full sparse tiling, results in a speedup of as much as 2.68x over a parallelized, blocked implementation on a multicore system with 40 cores.},
  eventtitle = {2013 {{IEEE International Symposium}} on {{Parallel}} \& {{Distributed Processing}}, {{Workshops}} and {{Phd Forum}} ({{IPDPSW}})},
  isbn = {978-0-7695-4979-8},
  langid = {english},
  keywords = {loop-chain,op2},
  file = {/home/connor/.local/share/zotero/storage/MLZSGD88/Krieger et al_2013_Loop Chaining.pdf}
}

@online{kronbichlerEnhancingDataLocality2022,
  title = {Enhancing Data Locality of the Conjugate Gradient Method for High-Order Matrix-Free Finite-Element Implementations},
  author = {Kronbichler, Martin and Sashko, Dmytro and Munch, Peter},
  date = {2022-05-18},
  eprint = {2205.08909},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2205.08909},
  urldate = {2022-09-06},
  abstract = {This work investigates a variant of the conjugate gradient (CG) method and embeds it into the context of high-order finite-element schemes with fast matrix-free operator evaluation and cheap preconditioners like the matrix diagonal. Relying on a data-dependency analysis and appropriate enumeration of degrees of freedom, we interleave the vector updates and inner products in a CG iteration with the matrix-vector product with only minor organizational overhead. As a result, around 90\% of the vector entries of the three active vectors of the CG method are transferred from slow RAM memory exactly once per iteration, with all additional access hitting fast cache memory. Node-level performance analyses and scaling studies on up to 147k cores show that the CG method with the proposed performance optimizations is around two times faster than a standard CG solver as well as optimized pipelined CG and s-step CG methods for large sizes that exceed processor caches, and provides similar performance near the strong scaling limit.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Mathematical Software,G.4,Mathematics - Numerical Analysis},
  file = {/home/connor/.local/share/zotero/storage/P4IB2XZX/Kronbichler et al. - 2022 - Enhancing data locality of the conjugate gradient .pdf}
}

@article{kronbichlerFastMatrixFreeEvaluation2019,
  title = {Fast {{Matrix-Free Evaluation}} of {{Discontinuous Galerkin Finite Element Operators}}},
  author = {Kronbichler, Martin and Kormann, Katharina},
  date = {2019-09-30},
  journaltitle = {ACM Transactions on Mathematical Software},
  shortjournal = {ACM Trans. Math. Softw.},
  volume = {45},
  number = {3},
  pages = {1--40},
  issn = {0098-3500, 1557-7295},
  doi = {10.1145/3325864},
  url = {https://dl.acm.org/doi/10.1145/3325864},
  urldate = {2022-02-04},
  abstract = {We present an algorithmic framework for matrix-free evaluation of discontinuous Galerkin finite element operators. It relies on fast quadrature with sum factorization on quadrilateral and hexahedral meshes, targeting general weak forms of linear and nonlinear partial differential equations. Different algorithms and data structures are compared in an in-depth performance analysis. The implementations of the local integrals are optimized by vectorization over several cells and faces and an even-odd decomposition of the one-dimensional interpolations. Up to 60\% of the arithmetic peak on Intel Haswell, Broadwell, and Knights Landing processors is reached when running from caches and up to 40\% of peak when also considering the access to vectors from main memory. On 2×14 Broadwell cores, the throughput is up to 2.2 billion unknowns per second for the 3D Laplacian and up to 4 billion unknowns per second for the 3D advection on affine geometries, close to a simple copy operation at 4.7 billion unknowns per second. Our experiments show that MPI ghost exchange has a considerable impact on performance and we present strategies to mitigate this effect. Finally, various options for evaluating geometry terms and their performance are discussed. Our implementations are publicly available through the deal.II finite element library.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/SERFG7KM/Kronbichler_Kormann_2019_Fast Matrix-Free Evaluation of Discontinuous Galerkin Finite Element Operators.pdf}
}

@book{kunProgrammerIntroductionMathematics2020,
  title = {A {{Programmer}}'s {{Introduction}} to {{Mathematics}}},
  author = {Kun, Jeremy},
  date = {2020},
  file = {/home/connor/.local/share/zotero/storage/X5XNQCZP/a-programmers-introduction-to-mathematics.pdf}
}

@unpublished{laakmannAugmentedLagrangianPreconditioner2021,
  title = {An Augmented {{Lagrangian}} Preconditioner for the Magnetohydrodynamics Equations at High {{Reynolds}} and Coupling Numbers},
  author = {Laakmann, Fabian and Farrell, Patrick E. and Mitchell, Lawrence},
  date = {2021-04-30},
  eprint = {2104.14855},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2104.14855},
  urldate = {2022-01-14},
  abstract = {The magnetohydrodynamics (MHD) equations are generally known to be difficult to solve numerically, due to their highly nonlinear structure and the strong coupling between the electromagnetic and hydrodynamic variables, especially for high Reynolds and coupling numbers. In this work, we present a scalable augmented Lagrangian preconditioner for a finite element discretization of the \$\textbackslash mathbf\{B\}\$-\$\textbackslash mathbf\{E\}\$ formulation of the incompressible viscoresistive MHD equations. For stationary problems, our solver achieves robust performance with respect to the Reynolds and coupling numbers in two dimensions and good results in three dimensions. We extend our method to fully implicit methods for time-dependent problems which we solve robustly in both two and three dimensions. Our approach relies on specialized parameter-robust multigrid methods for the hydrodynamic and electromagnetic blocks. The scheme ensures exactly divergence-free approximations of both the velocity and the magnetic field up to solver tolerances. We confirm the robustness of our solver by numerical experiments in which we consider fluid and magnetic Reynolds numbers and coupling numbers up to 10,000 for stationary problems and up to 100,000 for transient problems in two and three dimensions.},
  keywords = {Mathematics - Numerical Analysis},
  file = {/home/connor/OneDrive/AppData/Zotero/Laakmann et al_2021_An augmented Lagrangian preconditioner for the magnetohydrodynamics equations.pdf;/home/connor/.local/share/zotero/storage/2CAN4B87/2104.html}
}

@misc{lamOptimalReorderingMapping1996,
  title = {Optimal {{Reordering}} and {{Mapping}} of a {{Class}} of {{NestedLoops}} for {{Parallel Execution}}},
  author = {Lam, Chi-Chung and Sadayappan, P. and Wenger, Rephael},
  date = {1996},
  abstract = {This paper addresses the compile-time optimization of a class of nested-loop computations that arise in some computational physics applications. The computations involve summations over products of array terms in order to compute multi-dimensional surface and volume integrals. Reordering additions and multiplications and applying the distributive law can significantly reduce the number of operations required in evaluating these summations. In a multiprocessor environment, proper distribution of the arrays among processors will reduce the inter-processor communication time. We present a formal description of the operation minimization problem, a proof of its NPcompleteness, and a pruning strategy for finding the optimal solution in small cases. We also give an algorithm for determining the optimal distribution of the arrays among processors in a multiprocessor environment. 1. Introduction  This paper addresses the problem of compile-time optimization of a particular form of nested loop ...},
  file = {/home/connor/OneDrive/AppData/Zotero/Lam et al_1996_Optimal Reordering and Mapping of a Class of NestedLoops for Parallel Execution.pdf;/home/connor/.local/share/zotero/storage/JJ579GAR/summary.html}
}

@inproceedings{langeDevitoGenericFinite2016,
  title = {Devito: {{Towards}} a {{Generic Finite Difference DSL Using Symbolic Python}}},
  shorttitle = {Devito},
  booktitle = {2016 6th {{Workshop}} on {{Python}} for {{High-Performance}} and {{Scientific Computing}} ({{PyHPC}})},
  author = {Lange, Michael and Kukreja, Navjot and Louboutin, Mathias and Luporini, Fabio and Vieira, Felippe and Pandolfo, Vincenzo and Velesko, Paulius and Kazakas, Paulius and Gorman, Gerard},
  date = {2016-11},
  pages = {67--75},
  publisher = {IEEE},
  location = {Salt Lake, UT, USA},
  doi = {10.1109/PyHPC.2016.013},
  url = {http://ieeexplore.ieee.org/document/7836846/},
  urldate = {2021-02-02},
  abstract = {Domain specific languages (DSL) have been used in a variety of fields to express complex scientific problems in a concise manner and provide automated performance optimization for a range of computational architectures. As such DSLs provide a powerful mechanism to speed up scientific Python computation that goes beyond traditional vectorization and pre-compilation approaches, while allowing domain scientists to build applications within the comforts of the Python software ecosystem. In this paper we present Devito, a new finite difference DSL that provides optimized stencil computation from high-level problem specifications based on symbolic Python expressions. We demonstrate Devito’s symbolic API and performance advantages over traditional Python acceleration methods before highlighting its use in the scientific context of seismic inversion problems.},
  eventtitle = {2016 6th {{Workshop}} on {{Python}} for {{High-Performance}} and {{Scientific Computing}} ({{PyHPC}})},
  isbn = {978-1-5090-5220-2},
  langid = {english},
  keywords = {code-generation,devito,domain-specific-language,finite-difference,sympy},
  file = {/home/connor/Obsidian/30 Literature notes/langeDevitoGenericFinite2016 - Extracted Annotations (26052021, 113448)In contrast to traditional Python-embedded DSLs, Devito does not define its.md;/home/connor/Obsidian/30 Literature notes/langeDevitoGenericFinite2016 - Summary.md;/home/connor/Obsidian/30 Literature notes/langeDevitoGenericFinite2016-zotero.md;/home/connor/Obsidian/30 Literature notes/langeDevitoGenericFinite2016.md;/home/connor/Obsidian/30 Literature notes/Zotero/langeDevitoGenericFinite2016 - Extracted Annotations (26052021, 113448)In contrast to traditional Python-embedded DSLs, Devito does not define its.md;/home/connor/Obsidian/30 Literature notes/Zotero/langeDevitoGenericFinite2016 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/langeDevitoGenericFinite2016-zotero.md;/home/connor/OneDrive/AppData/Zotero/Lange et al_2016_Devito.pdf}
}

@article{langeEfficientMeshManagement2016,
  title = {Efficient {{Mesh Management}} in {{Firedrake Using PETSc DMPlex}}},
  author = {Lange, Michael and Mitchell, Lawrence and Knepley, Matthew G. and Gorman, Gerard J.},
  date = {2016-01},
  journaltitle = {SIAM Journal on Scientific Computing},
  shortjournal = {SIAM J. Sci. Comput.},
  volume = {38},
  number = {5},
  pages = {S143-S155},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/15M1026092},
  url = {http://epubs.siam.org/doi/10.1137/15M1026092},
  urldate = {2020-12-08},
  abstract = {The use of composable abstractions allows the application of new and established algorithms to a wide range of problems, while automatically inheriting the benefits of well-known performance optimizations. This work highlights the composition of the PETSc DMPlex domain topology abstraction with the Firedrake automated finite element system to create a PDE solving environment that combines expressiveness, flexibility, and high performance. We describe how Firedrake utilizes DMPlex to provide the indirection maps required for finite element assembly, while supporting various mesh input formats and runtime domain decomposition. In particular, we describe how DMPlex and its accompanying data structures allow the generic creation of user-defined discretizations, while utilizing data layout optimizations that improve cache coherency and ensure overlapped communication during assembly computation.},
  langid = {english},
  file = {/home/connor/Obsidian/30 Literature notes/langeEfficientMeshManagement2016 - Extracted Annotations (24022021, 143914)Firedrake imposes a clear separation of concerns between the definition of.md;/home/connor/Obsidian/30 Literature notes/langeEfficientMeshManagement2016 - Summary.md;/home/connor/Obsidian/30 Literature notes/langeEfficientMeshManagement2016-zotero.md;/home/connor/Obsidian/30 Literature notes/langeEfficientMeshManagement2016.md;/home/connor/Obsidian/30 Literature notes/Zotero/langeEfficientMeshManagement2016 - Extracted Annotations (24022021, 143914)Firedrake imposes a clear separation of concerns between the definition of.md;/home/connor/Obsidian/30 Literature notes/Zotero/langeEfficientMeshManagement2016 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/langeEfficientMeshManagement2016-zotero.md;/home/connor/OneDrive/AppData/Zotero/Lange et al_2016_Efficient Mesh Management in Firedrake Using PETSc DMPlex.pdf}
}

@unpublished{langeFlexibleScalableMesh2015,
  title = {Flexible, {{Scalable Mesh}} and {{Data Management}} Using {{PETSc DMPlex}}},
  author = {Lange, Michael and Knepley, Matthew G. and Gorman, Gerard J.},
  date = {2015-05-18},
  eprint = {1505.04633},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1505.04633},
  urldate = {2020-12-11},
  abstract = {Designing a scientific software stack to meet the needs of the next-generation of mesh-based simulation demands, not only scalable and efficient mesh and data management on a wide range of platforms, but also an abstraction layer that makes it useful for a wide range of application codes. Common utility tasks, such as file I/O, mesh distribution, and work partitioning, should be delegated to external libraries in order to promote code re-use, extensibility and software interoperability. In this paper we demonstrate the use of PETSc’s DMPlex data management API to perform mesh input and domain partitioning in Fluidity, a large scale CFD application. We demonstrate that raising the level of abstraction adds new functionality to the application code, such as support for additional mesh file formats and mesh reordering, while improving simlutation startup cost through more efficient mesh distribution. Moreover, the separation of concerns accomplished through this interface shifts critical performance and interoperability issues, such as scalable I/O and file format support, to a widely used and supported open source community library, improving the sustainability, performance, and functionality of Fluidity.},
  langid = {english},
  keywords = {dmplex,petsc,unstructured-mesh},
  file = {/home/connor/Obsidian/30 Literature notes/langeFlexibleScalableMesh2015 - Comment 6 pages, 6 figures, to appear in EASC 2015.md;/home/connor/Obsidian/30 Literature notes/langeFlexibleScalableMesh2015 - Extracted Annotations (29032021, 160420).md;/home/connor/Obsidian/30 Literature notes/langeFlexibleScalableMesh2015-zotero.md;/home/connor/Obsidian/30 Literature notes/langeFlexibleScalableMesh2015.md;/home/connor/Obsidian/30 Literature notes/Zotero/langeFlexibleScalableMesh2015 - Comment 6 pages, 6 figures, to appear in EASC 2015.md;/home/connor/Obsidian/30 Literature notes/Zotero/langeFlexibleScalableMesh2015 - Extracted Annotations (29032021, 160420).md;/home/connor/Obsidian/30 Literature notes/Zotero/langeFlexibleScalableMesh2015-zotero.md;/home/connor/OneDrive/AppData/Zotero/Lange et al_2015_Flexible, Scalable Mesh and Data Management using PETSc DMPlex.pdf;/home/connor/OneDrive/AppData/Zotero/Lange et al_2015_Flexible, Scalable Mesh and Data Management using PETSc DMPlex2.pdf}
}

@book{langtangenIntroductionNumericalMethods2019,
  title = {Introduction to {{Numerical Methods}} for {{Variational Problems}}},
  author = {Langtangen, Hans Petter and Mardal, Kent-Andre},
  date = {2019},
  series = {Texts in {{Computational Science}} and {{Engineering}}},
  volume = {21},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-030-23788-2},
  url = {http://link.springer.com/10.1007/978-3-030-23788-2},
  urldate = {2020-03-10},
  isbn = {978-3-030-23787-5 978-3-030-23788-2},
  langid = {english},
  file = {/home/connor/Obsidian/30 Literature notes/langtangenIntroductionNumericalMethods2019-zotero.md;/home/connor/Obsidian/30 Literature notes/langtangenIntroductionNumericalMethods2019.md;/home/connor/Obsidian/30 Literature notes/Zotero/langtangenIntroductionNumericalMethods2019-zotero.md;/home/connor/OneDrive/AppData/Zotero/Langtangen_Mardal_2019_Introduction to Numerical Methods for Variational Problems.pdf}
}

@book{larsonFiniteElementMethod2013,
  title = {The {{Finite Element Method}}: {{Theory}}, {{Implementation}}, and {{Applications}}},
  shorttitle = {The {{Finite Element Method}}},
  author = {Larson, Mats G. and Bengzon, Fredrik},
  date = {2013},
  series = {Texts in {{Computational Science}} and {{Engineering}}},
  volume = {10},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-33287-6},
  url = {http://link.springer.com/10.1007/978-3-642-33287-6},
  urldate = {2020-03-10},
  isbn = {978-3-642-33286-9 978-3-642-33287-6},
  langid = {english},
  file = {/home/connor/Obsidian/30 Literature notes/larsonFiniteElementMethod2013 - Progress.md;/home/connor/Obsidian/30 Literature notes/larsonFiniteElementMethod2013-zotero.md;/home/connor/Obsidian/30 Literature notes/larsonFiniteElementMethod2013.md;/home/connor/Obsidian/30 Literature notes/Zotero/larsonFiniteElementMethod2013 - Progress.md;/home/connor/Obsidian/30 Literature notes/Zotero/larsonFiniteElementMethod2013-zotero.md;/home/connor/OneDrive/AppData/Zotero/Larson_Bengzon_2013_The Finite Element Method.pdf}
}

@unpublished{lattnerMLIRCompilerInfrastructure2020,
  title = {{{MLIR}}: {{A Compiler Infrastructure}} for the {{End}} of {{Moore}}'s {{Law}}},
  shorttitle = {{{MLIR}}},
  author = {Lattner, Chris and Amini, Mehdi and Bondhugula, Uday and Cohen, Albert and Davis, Andy and Pienaar, Jacques and Riddle, River and Shpeisman, Tatiana and Vasilache, Nicolas and Zinenko, Oleksandr},
  date = {2020-02-29},
  eprint = {2002.11054},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2002.11054},
  urldate = {2022-02-25},
  abstract = {This work presents MLIR, a novel approach to building reusable and extensible compiler infrastructure. MLIR aims to address software fragmentation, improve compilation for heterogeneous hardware, significantly reduce the cost of building domain specific compilers, and aid in connecting existing compilers together. MLIR facilitates the design and implementation of code generators, translators and optimizers at different levels of abstraction and also across application domains, hardware targets and execution environments. The contribution of this work includes (1) discussion of MLIR as a research artifact, built for extension and evolution, and identifying the challenges and opportunities posed by this novel design point in design, semantics, optimization specification, system, and engineering. (2) evaluation of MLIR as a generalized infrastructure that reduces the cost of building compilers-describing diverse use-cases to show research and educational opportunities for future programming languages, compilers, execution environments, and computer architecture. The paper also presents the rationale for MLIR, its original design principles, structures and semantics.},
  keywords = {Computer Science - Machine Learning,Computer Science - Programming Languages},
  file = {/home/connor/OneDrive/AppData/Zotero/Lattner et al_2020_MLIR.pdf;/home/connor/.local/share/zotero/storage/RBNSW7NX/2002.html}
}

@article{lengauerAdvancedStencilCodeEngineering2015,
  title = {Advanced {{Stencil-Code Engineering}} ({{Dagstuhl Seminar}} 15161)},
  author = {Lengauer, Christian and Bolten, Matthias and Falgout, Robert D. and Schenk, Olaf},
  namea = {Herbstritt, Marc},
  nameatype = {collaborator},
  date = {2015},
  pages = {20 pages},
  publisher = {Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik GmbH, Wadern/Saarbruecken, Germany},
  doi = {10.4230/DAGREP.5.4.56},
  url = {http://drops.dagstuhl.de/opus/volltexte/2015/5350/},
  urldate = {2023-04-03},
  abstract = {This report documents the program and the outcomes of Dagstuhl Seminar 15161 “Advanced Stencil-Code Engineering”. The seminar was hosted by the DFG project with the same name (ExaStencils for short) in the DFG priority programme “Software for Exascale Computing” (SPPEXA). It brought together experts from mathematics, computer science and applications to explore the challenges of very high performance and massive parallelism in solving partial differential equations. Its aim was to lay the basis for a new interdisciplinary research community on high-performance stencil codes.},
  langid = {english},
  keywords = {{000 Computer science, knowledge, general works},Computer Science},
  file = {/home/connor/.local/share/zotero/storage/9TJSQV43/Lengauer et al. - 2015 - Advanced Stencil-Code Engineering (Dagstuhl Semina.pdf}
}

@article{levequeHighResolutionConservativeAlgorithms1996,
  title = {High-{{Resolution Conservative Algorithms}} for {{Advection}} in {{Incompressible Flow}}},
  author = {LeVeque, Randall J.},
  date = {1996-04},
  journaltitle = {SIAM Journal on Numerical Analysis},
  shortjournal = {SIAM J. Numer. Anal.},
  volume = {33},
  number = {2},
  pages = {627--665},
  issn = {0036-1429, 1095-7170},
  doi = {10.1137/0733033},
  url = {http://epubs.siam.org/doi/10.1137/0733033},
  urldate = {2022-09-20},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/HEUX79ZZ/0733033.pdf}
}

@article{liDiscontinuousGalerkinSpectral2018,
  title = {The Discontinuous {{Galerkin}} Spectral Element Methods for Compressible Flows on Two-Dimensional Mixed Grids},
  author = {Li, Wanai and Pan, Jianhua and Ren, Yu-Xin},
  date = {2018-07},
  journaltitle = {Journal of Computational Physics},
  shortjournal = {Journal of Computational Physics},
  volume = {364},
  pages = {314--346},
  issn = {00219991},
  doi = {10.1016/j.jcp.2018.03.001},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999118301451},
  urldate = {2021-10-04},
  langid = {english},
  keywords = {spectral-element-method},
  file = {/home/connor/.local/share/zotero/storage/ZS2YAW5Y/Li et al. - 2018 - The discontinuous Galerkin spectral element method.pdf}
}

@article{Logg2007a,
  title = {Automating the Finite Element Method},
  author = {Logg, Anders},
  date = {2007},
  journaltitle = {Archives of Computational Methods in Engineering},
  volume = {14},
  number = {2},
  eprint = {1112.0433},
  eprinttype = {arXiv},
  pages = {93--138},
  doi = {10.1007/s11831-007-9003-9}
}

@book{loggAutomatedSolutionDifferential2012,
  ids = {loggAutomatedSolutionDifferential2012a},
  title = {Automated {{Solution}} of {{Differential Equations}} by the {{Finite Element Method}}},
  editor = {Logg, Anders and Mardal, Kent-Andre and Wells, Garth},
  date = {2012},
  series = {Lecture {{Notes}} in {{Computational Science}} and {{Engineering}}},
  volume = {84},
  publisher = {Springer Berlin Heidelberg},
  location = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-23099-8},
  url = {http://link.springer.com/10.1007/978-3-642-23099-8},
  urldate = {2020-03-09},
  isbn = {978-3-642-23098-1 978-3-642-23099-8},
  langid = {english},
  keywords = {dolfin,fenics,ufl},
  file = {/home/connor/Obsidian/30 Literature notes/loggAutomatedSolutionDifferential2012 - Discusses non-linear solving methods and Gateaux derivatives..md;/home/connor/Obsidian/30 Literature notes/loggAutomatedSolutionDifferential2012 - Mentions the action() function in chapter 1..md;/home/connor/Obsidian/30 Literature notes/loggAutomatedSolutionDifferential2012-zotero.md;/home/connor/Obsidian/30 Literature notes/loggAutomatedSolutionDifferential2012.md;/home/connor/Obsidian/30 Literature notes/Zotero/loggAutomatedSolutionDifferential2012 - Discusses non-linear solving methods and Gateaux derivatives..md;/home/connor/Obsidian/30 Literature notes/Zotero/loggAutomatedSolutionDifferential2012 - Mentions the action() function in chapter 1..md;/home/connor/Obsidian/30 Literature notes/Zotero/loggAutomatedSolutionDifferential2012-zotero.md;/home/connor/OneDrive/AppData/Zotero/Logg et al_2012_Automated Solution of Differential Equations by the Finite Element Method.pdf}
}

@article{loggEfficientRepresentationComputational2009,
  title = {Efficient {{Representation}} of {{Computational Meshes}}},
  author = {Logg, Anders},
  date = {2009},
  journaltitle = {International Journal of Computational Science and Engineering},
  shortjournal = {IJCSE},
  volume = {4},
  number = {4},
  eprint = {1205.3081},
  eprinttype = {arXiv},
  pages = {283},
  issn = {1742-7185, 1742-7193},
  doi = {10.1504/IJCSE.2009.029164},
  url = {http://arxiv.org/abs/1205.3081},
  urldate = {2022-02-22},
  abstract = {We present a simple yet general and efficient approach to representation of computational meshes. Meshes are represented as sets of mesh entities of different topological dimensions and their incidence relations. We discuss a straightforward and efficient storage scheme for such mesh representations and efficient algorithms for computation of arbitrary incidence relations from a given initial and minimal set of incidence relations. The general representation may harbor a wide range of computational meshes, and may also be specialized to provide simple user interfaces for particular meshes, including simplicial meshes in one, two and three space dimensions where the mesh entities correspond to vertices, edges, faces and cells. It is elaborated on how the proposed concepts and data structures may be used for assembly of variational forms in parallel over distributed finite element meshes. Benchmarks are presented to demonstrate efficiency in terms of CPU time and memory usage.},
  langid = {english},
  keywords = {Mathematics - Numerical Analysis},
  file = {/home/connor/.local/share/zotero/storage/GS5IBIFP/Logg_2009_Efficient Representation of Computational Meshes.pdf}
}

@incollection{LoggOlgaardEtAl2012a,
  title = {{{FFC}}: The {{FEniCS}} Form Compiler},
  booktitle = {Automated Solution of Differential Equations by the Finite Element Method, Volume 84 of Lecture Notes in Computational Science and Engineering},
  author = {Logg, Anders and Ølgaard, Kristian B. and Rognes, Marie E. and Wells, Garth N.},
  editor = {Logg, Anders and Mardal, Kent-Andre and Wells, Garth N.},
  date = {2012},
  publisher = {Springer}
}

@article{LoggWells2010a,
  title = {{{DOLFIN}}: {{Automated}} Finite Element Computing},
  author = {Logg, Anders and Wells, Garth N.},
  date = {2010},
  journaltitle = {ACM Transactions on Mathematical Software},
  volume = {37},
  number = {2},
  eprint = {1103.6248},
  eprinttype = {arXiv},
  doi = {10.1145/1731022.1731030}
}

@incollection{LoggWellsEtAl2012a,
  title = {{{DOLFIN}}: A {{C}}++/{{Python}} Finite Element Library},
  booktitle = {Automated Solution of Differential Equations by the Finite Element Method, Volume 84 of Lecture Notes in Computational Science and Engineering},
  author = {Logg, Anders and Wells, Garth N. and Hake, Johan},
  editor = {Logg, Anders and Mardal, Kent-Andre and Wells, Garth N.},
  date = {2012},
  publisher = {Springer}
}

@unpublished{lovelandExtendingFEniCSWork2022,
  title = {Extending {{FEniCS}} to {{Work}} in {{Higher Dimensions Using Tensor Product Finite Elements}}},
  author = {Loveland, Mark and Valseth, Eirik and Lukac, Matt and Dawson, Clint},
  date = {2022-02-01},
  eprint = {2202.00762},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2202.00762},
  urldate = {2022-02-03},
  abstract = {We present a method to extend the finite element library FEniCS to solve problems with domains in dimensions above three by constructing tensor product finite elements. This methodology only requires that the high dimensional domain is structured as a Cartesian product of two lower dimensional subdomains. In this study we consider linear partial differential equations, though the methodology can be extended to non-linear problems. The utilization of tensor product finite elements allows us to construct a global system of linear algebraic equations that only relies on the finite element infrastructure of the lower dimensional subdomains contained in FEniCS. We demonstrate the effectiveness of our methodology in three distinctive test cases. The first test case is a Poisson equation posed in a four dimensional domain which is a Cartesian product of two unit squares solved using the classical Galerkin finite element method. The second test case is the wave equation in space-time, where the computational domain is a Cartesian product of a two dimensional space grid and a one dimensional time interval. In this second case we also employ the Galerkin method. Finally, the third test case is an advection dominated advection-diffusion equation where the global domain is a Cartesian product of two one dimensional intervals. The streamline upwind Petrov-Galerkin method is applied to ensure discrete stability. In all three cases, optimal convergence rates are achieved with respect to h refinement.},
  keywords = {Mathematics - Numerical Analysis},
  file = {/home/connor/OneDrive/AppData/Zotero/Loveland et al_2022_Extending FEniCS to Work in Higher Dimensions Using Tensor Product Finite.pdf;/home/connor/.local/share/zotero/storage/D9LSTD4N/2202.html}
}

@article{luporiniAlgorithmOptimizationFinite2017,
  title = {An {{Algorithm}} for the {{Optimization}} of {{Finite Element Integration Loops}}},
  author = {Luporini, Fabio and Ham, David A. and Kelly, Paul H. J.},
  date = {2017-07-24},
  journaltitle = {ACM Transactions on Mathematical Software},
  shortjournal = {ACM Trans. Math. Softw.},
  volume = {44},
  number = {1},
  pages = {1--26},
  issn = {0098-3500, 1557-7295},
  doi = {10.1145/3054944},
  url = {https://dl.acm.org/doi/10.1145/3054944},
  urldate = {2020-10-15},
  langid = {english},
  keywords = {coffee,Computer Science - Mathematical Software,firedrake,G.1.8,G.4,sharing,tensor},
  file = {/home/connor/.local/share/zotero/storage/GNJ2BENL/Luporini et al. - 2017 - An algorithm for the optimization of finite elemen.pdf;/home/connor/Obsidian/30 Literature notes/luporiniAlgorithmOptimizationFinite2017 - Discusses Firedrake parallelism strategy.md;/home/connor/Obsidian/30 Literature notes/luporiniAlgorithmOptimizationFinite2017 - Summary.md;/home/connor/Obsidian/30 Literature notes/luporiniAlgorithmOptimizationFinite2017-zotero.md;/home/connor/Obsidian/30 Literature notes/luporiniAlgorithmOptimizationFinite2017.md;/home/connor/Obsidian/30 Literature notes/Zotero/luporiniAlgorithmOptimizationFinite2017 - Discusses Firedrake parallelism strategy.md;/home/connor/Obsidian/30 Literature notes/Zotero/luporiniAlgorithmOptimizationFinite2017 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/luporiniAlgorithmOptimizationFinite2017-zotero.md;/home/connor/OneDrive/AppData/Zotero/Luporini et al_2017_An Algorithm for the Optimization of Finite Element Integration Loops.pdf}
}

@article{luporiniAlgorithmOptimizationFinite2018,
  title = {An Algorithm for the Optimization of Finite Element Integration Loops},
  author = {Luporini, Fabio and Ham, David A. and Kelly, Paul H. J.},
  date = {2018-03-31},
  journaltitle = {ACM Transactions on Mathematical Software},
  shortjournal = {ACM Trans. Math. Softw.},
  volume = {44},
  number = {1},
  eprint = {1604.05872},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {1--26},
  issn = {0098-3500, 1557-7295},
  doi = {10.1145/3054944},
  url = {http://arxiv.org/abs/1604.05872},
  urldate = {2023-11-29},
  abstract = {We present an algorithm for the optimization of a class of finite element integration loop nests. This algorithm, which exploits fundamental mathematical properties of finite element operators, is proven to achieve a locally optimal operation count. In specified circumstances the optimum achieved is global. Extensive numerical experiments demonstrate significant performance improvements over the state of the art in finite element code generation in almost all cases. This validates the effectiveness of the algorithm presented here, and illustrates its limitations.},
  langid = {english},
  keywords = {Computer Science - Mathematical Software,G.1.8,G.4},
  file = {/home/connor/.local/share/zotero/storage/68DZFB24/Luporini et al. - 2018 - An algorithm for the optimization of finite elemen.pdf}
}

@unpublished{luporiniArchitecturePerformanceDevito2020,
  title = {Architecture and Performance of {{Devito}}, a System for Automated Stencil Computation},
  author = {Luporini, Fabio and Lange, Michael and Louboutin, Mathias and Kukreja, Navjot and Hückelheim, Jan and Yount, Charles and Witte, Philipp and Kelly, Paul H. J. and Herrmann, Felix J. and Gorman, Gerard J.},
  date = {2020-02-07},
  eprint = {1807.03032},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/1807.03032},
  urldate = {2020-12-14},
  abstract = {Stencil computations are a key part of many high-performance computing applications, such as image processing, convolutional neural networks, and finite-difference solvers for partial differential equations. Devito is a framework capable of generating highly-optimized code given symbolic equations expressed in Python, specialized in, but not limited to, affine (stencil) codes. The lowering process---from mathematical equations down to C++ code---is performed by the Devito compiler through a series of intermediate representations. Several performance optimizations are introduced, including advanced common sub-expressions elimination, tiling and parallelization. Some of these are obtained through well-established stencil optimizers, integrated in the back-end of the Devito compiler. The architecture of the Devito compiler, as well as the performance optimizations that are applied when generating code, are presented. The effectiveness of such performance optimizations is demonstrated using operators drawn from seismic imaging applications.},
  langid = {english},
  keywords = {code-generation,devito},
  file = {/home/connor/Obsidian/30 Literature notes/luporiniArchitecturePerformanceDevito2020 - Comment Submitted to ACM Transactions on Mathematical Software.md;/home/connor/Obsidian/30 Literature notes/luporiniArchitecturePerformanceDevito2020-zotero.md;/home/connor/Obsidian/30 Literature notes/luporiniArchitecturePerformanceDevito2020.md;/home/connor/Obsidian/30 Literature notes/Zotero/luporiniArchitecturePerformanceDevito2020 - Comment Submitted to ACM Transactions on Mathematical Software.md;/home/connor/Obsidian/30 Literature notes/Zotero/luporiniArchitecturePerformanceDevito2020-zotero.md;/home/connor/OneDrive/AppData/Zotero/Luporini et al_2020_Architecture and performance of Devito, a system for automated stencil.pdf}
}

@article{luporiniAutomatedOptimizationNumerical2016,
  title = {Automated Optimization of Numerical Methods for Partial Differential Equations},
  author = {Luporini, Fabio},
  namea = {Kelly, Paul H. J. and Ham, David A.},
  nameatype = {collaborator},
  date = {2016-10},
  publisher = {Imperial College London},
  doi = {10.25560/44726},
  url = {http://spiral.imperial.ac.uk/handle/10044/1/44726},
  urldate = {2021-06-03},
  abstract = {The time required to execute real-world scientific computations is a major issue. A single simulation may last hours, days, or even weeks to reach a certain level of accuracy, despite running on large-scale parallel architectures. Strict time limits may often be imposed too -- 60 minutes in the case of the UK Met Office to produce a forecast. In this thesis, it is demonstrated that by raising the level of abstraction, the performance of a class of numerical methods for solving partial differential equations is improvable with minimal user intervention or, in many circumstances, with no user intervention at all. The use of high level languages to express mathematical problems enables domain-specific optimization via compilers. These automated optimizations are proven to be effective in a variety of real-world applications and computational kernels. The focus is on numerical methods based on unstructured meshes, such as the finite element method. The loop nests for unstructured mesh traversal are often irregular (i.e., they perform non-affine memory accesses, such as A[B[i]]), which makes reordering transformations for data locality essentially impossible for low level compilers. Further, the computational kernels are often characterized by complex mathematical expressions, and manual optimization is simply not conceivable. We discuss algorithmic solutions to these problems and present tools for their automation. These tools -- the COFFEE compiler and the SLOPE library -- are currently in use in frameworks for solving partial differential equations.},
  keywords = {loop-chain,sparse-tiling},
  file = {/home/connor/Obsidian/30 Literature notes/Zotero/luporiniAutomatedOptimizationNumerical2016 - Extracted Annotations (03062021, 141959).md;/home/connor/Obsidian/30 Literature notes/Zotero/luporiniAutomatedOptimizationNumerical2016-zotero.md;/home/connor/Obsidian/30 Literature notes/Zotero/luporiniAutomatedOptimizationNumerical2016.md;/home/connor/OneDrive/AppData/Zotero/Luporini_2016_Automated optimization of numerical methods for partial differential equations.pdf}
}

@online{luporiniAutomatedTilingUnstructured2019,
  title = {Automated {{Tiling}} of {{Unstructured Mesh Computations}} with {{Application}} to {{Seismological Modelling}}},
  author = {Luporini, Fabio and Lange, Michael and Jacobs, Christian T. and Gorman, Gerard J. and Ramanujam, J. and Kelly, Paul H. J.},
  date = {2019-06-19},
  eprint = {1708.03183},
  eprinttype = {arXiv},
  eprintclass = {physics},
  url = {http://arxiv.org/abs/1708.03183},
  urldate = {2022-09-06},
  abstract = {Sparse tiling is a technique to fuse loops that access common data, thus increasing data locality. Unlike traditional loop fusion or blocking, the loops may have different iteration spaces and access shared datasets through indirect memory accesses, such as A[map[i]] -- hence the name "sparse". One notable example of such loops arises in discontinuous-Galerkin finite element methods, because of the computation of numerical integrals over different domains (e.g., cells, facets). The major challenge with sparse tiling is implementation -- not only is it cumbersome to understand and synthesize, but it is also onerous to maintain and generalize, as it requires a complete rewrite of the bulk of the numerical computation. In this article, we propose an approach to extend the applicability of sparse tiling based on raising the level of abstraction. Through a sequence of compiler passes, the mathematical specification of a problem is progressively lowered, and eventually sparse-tiled C for-loops are generated. Besides automation, we advance the state-of-the-art by introducing: a revisited, more efficient sparse tiling algorithm; support for distributed-memory parallelism; a range of fine-grained optimizations for increased run-time performance; implementation in a publicly-available library, SLOPE; and an in-depth study of the performance impact in Seigen, a real-world elastic wave equation solver for seismological problems, which shows speed-ups up to 1.28x on a platform consisting of 896 Intel Broadwell cores.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {{Computer Science - Computational Engineering, Finance, and Science},D.1.2,G.4,Physics - Geophysics},
  file = {/home/connor/.local/share/zotero/storage/R4WSS8F7/Luporini et al. - 2019 - Automated Tiling of Unstructured Mesh Computations.pdf}
}

@article{luporiniCrossLoopOptimizationArithmetic2015,
  title = {Cross-{{Loop Optimization}} of {{Arithmetic Intensity}} for {{Finite Element Local Assembly}}},
  author = {Luporini, Fabio and Varbanescu, Ana Lucia and Rathgeber, Florian and Bercea, Gheorghe-Teodor and Ramanujam, J. and Ham, David A. and Kelly, Paul H. J.},
  date = {2015-01-09},
  journaltitle = {ACM Transactions on Architecture and Code Optimization},
  shortjournal = {ACM Trans. Archit. Code Optim.},
  volume = {11},
  number = {4},
  pages = {1--25},
  issn = {1544-3566, 1544-3973},
  doi = {10.1145/2687415},
  url = {https://dl.acm.org/doi/10.1145/2687415},
  urldate = {2020-10-12},
  langid = {english},
  file = {/home/connor/Obsidian/30 Literature notes/luporiniCrossLoopOptimizationArithmetic2015-zotero.md;/home/connor/Obsidian/30 Literature notes/luporiniCrossLoopOptimizationArithmetic2015.md;/home/connor/Obsidian/30 Literature notes/Zotero/luporiniCrossLoopOptimizationArithmetic2015-zotero.md;/home/connor/OneDrive/AppData/Zotero/Luporini et al_2015_Cross-Loop Optimization of Arithmetic Intensity for Finite Element Local.pdf}
}

@book{maclaneCategoriesWorkingMathematician1978,
  title = {Categories for the {{Working Mathematician}}},
  author = {Mac Lane, Saunders},
  date = {1978},
  series = {Graduate {{Texts}} in {{Mathematics}}},
  volume = {5},
  publisher = {Springer New York},
  location = {New York, NY},
  doi = {10.1007/978-1-4757-4721-8},
  url = {http://link.springer.com/10.1007/978-1-4757-4721-8},
  urldate = {2022-08-11},
  isbn = {978-1-4419-3123-8 978-1-4757-4721-8},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/FEXWRIBD/Mac Lane_1978_Categories for the Working Mathematician.pdf}
}

@article{maclaurinDexArrayProgramming,
  title = {Dex: Array Programming with Typed Indices},
  author = {Maclaurin, Dougal and Radul, Alexey and Johnson, Matthew J and Vytiniotis, Dimitrios},
  pages = {5},
  abstract = {Array programming is harder than it should be. Major pain points are managing bulk operations on high-rank arrays, and the associated shape and indexing errors. We describe Dex, a functional array processing language in the Haskell/ML family. Dex introduces a lightweight looping construct and a type system that captures common patterns of array shapes. We hope the language ideas we present here can influence the design of existing array programming systems.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/RLAGRTE4/Maclaurin et al. - Dex array programming with typed indices.pdf}
}

@article{maddisonAutomatedCalculationHigher2019,
  title = {Automated {{Calculation}} of {{Higher Order Partial Differential Equation Constrained Derivative Information}}},
  author = {Maddison, James R. and Goldberg, Daniel N. and Goddard, Benjamin D.},
  date = {2019-01},
  journaltitle = {SIAM Journal on Scientific Computing},
  shortjournal = {SIAM J. Sci. Comput.},
  volume = {41},
  number = {5},
  pages = {C417-C445},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/18M1209465},
  url = {https://epubs.siam.org/doi/10.1137/18M1209465},
  urldate = {2021-04-15},
  abstract = {Developments in automated code generation have allowed extremely compact representations of numerical models and for associated adjoint models to be derived automatically via high level algorithmic differentiation. In this article these principles are extended to enable the calculation of higher order derivative information. The higher order derivative information is computed through the automated derivation of tangent-linear equations, which are then treated as new forward equations, and from which higher order tangent-linear and adjoint information can be derived. The principal emphasis is on the calculation of partial differential equation constrained Hessian actions, but the approach generalizes for derivative information at arbitrary order. The derivative calculations are further combined with an advanced data checkpointing strategy. Applications which make use of partial differential equation constrained Hessian actions are presented.},
  langid = {english},
  keywords = {adjoint,code-generation,tangent-linear},
  file = {/home/connor/Obsidian/30 Literature notes/maddisonAutomatedCalculationHigher2019 - Extracted Annotations (19042021, 114056).md;/home/connor/Obsidian/30 Literature notes/maddisonAutomatedCalculationHigher2019 - Summary.md;/home/connor/Obsidian/30 Literature notes/maddisonAutomatedCalculationHigher2019-zotero.md;/home/connor/Obsidian/30 Literature notes/maddisonAutomatedCalculationHigher2019.md;/home/connor/Obsidian/30 Literature notes/Zotero/maddisonAutomatedCalculationHigher2019 - Extracted Annotations (19042021, 114056).md;/home/connor/Obsidian/30 Literature notes/Zotero/maddisonAutomatedCalculationHigher2019 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/maddisonAutomatedCalculationHigher2019-zotero.md;/home/connor/OneDrive/AppData/Zotero/Maddison et al_2019_Automated Calculation of Higher Order Partial Differential Equation Constrained.pdf}
}

@article{maddisonRapidDevelopmentAdjoining2014,
  title = {Rapid Development and Adjoining of Transient Finite Element Models},
  author = {Maddison, J.R. and Farrell, P.E.},
  date = {2014-07},
  journaltitle = {Computer Methods in Applied Mechanics and Engineering},
  shortjournal = {Computer Methods in Applied Mechanics and Engineering},
  volume = {276},
  pages = {95--121},
  issn = {00457825},
  doi = {10.1016/j.cma.2014.03.010},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0045782514000966},
  urldate = {2021-04-16},
  abstract = {Recent advances in high level finite element systems have allowed for the symbolic representation of discretisations and their efficient automated implementation as model source code. This allows for the extremely compact implementation of complex non-linear models in a handful of lines of high level code. In this work we extend the high level finite element FEniCS system to introduce an abstract representation of the temporal discretisation: this enables the similarly rapid development of transient finite element models. Efficiency is achieved via aggressive optimisations that exploit the temporal structure, such as automated pre-assembly and caching of forms, and the robust re-use of matrix factorisations and preconditioner data. The resulting models are as fast or faster than hand-optimised finite element codes. The high level representation of the system remains extremely compact and easily manipulated. This structure is exploited to derive the associated discrete adjoint model automatically, with the adjoint model inheriting the performance advantages of the forward model. Combined, this provides a system for the rapid development of efficient transient models, together with their discrete adjoints.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/LGAXG9W8/Maddison_Farrell_2014_Rapid development and adjoining of transient finite element models.pdf;/home/connor/Obsidian/30 Literature notes/maddisonRapidDevelopmentAdjoining2014 - Extracted Annotations (16042021, 153736)Lastly, the ability to analyse the mathematical structure of the equations.md;/home/connor/Obsidian/30 Literature notes/maddisonRapidDevelopmentAdjoining2014 - Summary.md;/home/connor/Obsidian/30 Literature notes/maddisonRapidDevelopmentAdjoining2014-zotero.md;/home/connor/Obsidian/30 Literature notes/maddisonRapidDevelopmentAdjoining2014.md;/home/connor/Obsidian/30 Literature notes/Zotero/maddisonRapidDevelopmentAdjoining2014 - Extracted Annotations (16042021, 153736)Lastly, the ability to analyse the mathematical structure of the equations.md;/home/connor/Obsidian/30 Literature notes/Zotero/maddisonRapidDevelopmentAdjoining2014 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/maddisonRapidDevelopmentAdjoining2014-zotero.md}
}

@article{markallFiniteElementAssembly2013,
  title = {Finite Element Assembly Strategies on Multi-Core and Many-Core Architectures: {{FINITE ELEMENT ASSEMBLY ON MULTI-CORE AND MANY-CORE ARCHITECTURES}}},
  shorttitle = {Finite Element Assembly Strategies on Multi-Core and Many-Core Architectures},
  author = {Markall, G. R. and Slemmer, A. and Ham, David A. and Kelly, Paul H. J. and Cantwell, C. D. and Sherwin, S. J.},
  date = {2013-01-10},
  journaltitle = {International Journal for Numerical Methods in Fluids},
  shortjournal = {Int. J. Numer. Meth. Fluids},
  volume = {71},
  number = {1},
  pages = {80--97},
  issn = {02712091},
  doi = {10.1002/fld.3648},
  url = {http://doi.wiley.com/10.1002/fld.3648},
  urldate = {2020-10-12},
  abstract = {We demonstrate that radically differing implementations of finite element methods (FEMs) are needed on multi-core (CPU) and many-core (GPU) architectures, if their respective performance potential is to be realised. Our numerical investigations using a finite element advection–diffusion solver show that increased performance on each architecture can only be achieved by committing to specific and diverse algorithmic choices that cut across the high-level structure of the implementation. Making these commitments to achieve high performance for a single architecture leads to a loss of performance portability. Data structures that include redundant data but enable coalesced memory accesses are faster on many-core architectures, whereas redundancy-free data structures that are accessed indirectly are faster on multi-core architectures. The Addto algorithm for global assembly is optimal on multi-core architectures, whereas the Local Matrix Approach is optimal on many-core architectures despite requiring more computation than the Addto algorithm. These results demonstrate the value in making the correct choice of algorithm and data structure when implementing FEMs, spectral element methods and low-order discontinuous Galerkin methods on modern high-performance architectures. Copyright © 2012 John Wiley \& Sons, Ltd.},
  langid = {english},
  file = {/home/connor/Obsidian/30 Literature notes/markallFiniteElementAssembly2013 - Extracted Annotations (31032021, 100440).md;/home/connor/Obsidian/30 Literature notes/markallFiniteElementAssembly2013 - Summary.md;/home/connor/Obsidian/30 Literature notes/markallFiniteElementAssembly2013-zotero.md;/home/connor/Obsidian/30 Literature notes/markallFiniteElementAssembly2013.md;/home/connor/Obsidian/30 Literature notes/Zotero/markallFiniteElementAssembly2013 - Extracted Annotations (31032021, 100440).md;/home/connor/Obsidian/30 Literature notes/Zotero/markallFiniteElementAssembly2013 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/markallFiniteElementAssembly2013-zotero.md;/home/connor/OneDrive/AppData/Zotero/Markall et al_2013_Finite element assembly strategies on multi-core and many-core architectures.pdf}
}

@thesis{marsdenSymbolicNumericalRepresentation,
  title = {Symbolic and {{Numerical Representation}} of {{Dual Spaces}} in the {{Unified Form Language}} and {{Firedrake}}},
  author = {Marsden, India},
  file = {/home/connor/.local/share/zotero/storage/ANRLDU3W/Marsden_Symbolic and Numerical Representation of Dual Spaces in the Unified Form.pdf}
}

@online{matsuokaMythsLegendsHighPerformance2023,
  title = {Myths and {{Legends}} in {{High-Performance Computing}}},
  author = {Matsuoka, Satoshi and Domke, Jens and Wahib, Mohamed and Drozd, Aleksandr and Hoefler, Torsten},
  date = {2023-01-06},
  eprint = {2301.02432},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2301.02432},
  urldate = {2023-03-05},
  abstract = {In this humorous and thought provoking article, we discuss certain myths and legends that are folklore among members of the high-performance computing community. We collected those myths from conversations at conferences and meetings, product advertisements, papers, and other communications such as tweets, blogs, and news articles within (and beyond) our community. We believe they represent the zeitgeist of the current era of massive change, driven by the end of many scaling laws such as Dennard scaling and Moore’s law. While some laws end, new directions open up, such as algorithmic scaling or novel architecture research. However, these myths are rarely based on scientific facts but often on some evidence or argumentation. In fact, we believe that this is the very reason for the existence of many myths and why they cannot be answered clearly. While it feels like there should be clear answers for each, some may remain endless philosophical debates such as the question whether Beethoven was better than Mozart. We would like to see our collection of myths as a discussion of possible new directions for research and industry investment.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Computers and Society,Computer Science - Hardware Architecture,Computer Science - Machine Learning,Computer Science - Social and Information Networks},
  file = {/home/connor/.local/share/zotero/storage/XR9AD9IC/Matsuoka et al. - 2023 - Myths and Legends in High-Performance Computing.pdf}
}

@inproceedings{mayExtremeScaleMultigridComponents2016,
  title = {Extreme-{{Scale Multigrid Components}} within {{PETSc}}},
  booktitle = {Proceedings of the {{Platform}} for {{Advanced Scientific Computing Conference}}},
  author = {May, Dave A. and Sanan, Patrick and Rupp, Karl and Knepley, Matthew G. and Smith, Barry F.},
  date = {2016-06-08},
  pages = {1--12},
  publisher = {ACM},
  location = {Lausanne Switzerland},
  doi = {10.1145/2929908.2929913},
  url = {https://dl.acm.org/doi/10.1145/2929908.2929913},
  urldate = {2022-08-12},
  abstract = {Elliptic partial differential equations (PDEs) frequently arise in continuum descriptions of physical processes relevant to science and engineering. Multilevel preconditioners represent a family of scalable techniques for solving discrete PDEs of this type and thus are the method of choice for high-resolution simulations. The scalability and time-tosolution of massively parallel multilevel preconditioners can be adversely affected by using a coarse-level solver with suboptimal algorithmic complexity. To maintain scalability, agglomeration techniques applied to the coarse level have been shown to be necessary.},
  eventtitle = {{{PASC}} '16: {{Platform}} for {{Advanced Scientific Computing Conference}}},
  isbn = {978-1-4503-4126-4},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/W6IKKDRX/May et al_2016_Extreme-Scale Multigrid Components within PETSc.pdf}
}

@inproceedings{mayPTatin3DHighPerformanceMethods2014,
  title = {{{pTatin3D}}: {{High-Performance Methods}} for {{Long-Term Lithospheric Dynamics}}},
  shorttitle = {{{pTatin3D}}},
  booktitle = {{{SC14}}: {{International Conference}} for {{High Performance Computing}}, {{Networking}}, {{Storage}} and {{Analysis}}},
  author = {May, Dave A. and Brown, Jed and Pourhiet, Laetitia Le},
  date = {2014-11},
  pages = {274--284},
  publisher = {IEEE},
  location = {New Orleans, LA, USA},
  doi = {10.1109/SC.2014.28},
  url = {http://ieeexplore.ieee.org/document/7013010/},
  urldate = {2022-09-23},
  abstract = {Simulations of long-term lithospheric deformation involve post-failure analysis of high-contrast brittle materials driven by buoyancy and processes at the free surface. Geodynamic phenomena such as subduction and continental rifting take place over millions year time scales, thus require efficient solution methods. We present pTatin3D, a geodynamics modeling package utilising the material-point-method for tracking material composition, combined with a multigrid finite-element method to solve heterogeneous, incompressible visco-plastic Stokes problems. Here we analyze the performance and algorithmic tradeoffs of pTatin3D’s multigrid preconditioner. Our matrix-free geometric multigrid preconditioner trades flops for memory bandwidth to produce a time-to-solution {$>$} 2× faster than the best available methods utilising stored matrices (plagued by memory bandwidth limitations), exploits local element structure to achieve weak scaling at 30\% of FPU peak on Cray XC-30, has improved dynamic range due to smaller memory footprint, and has more consistent timing and better intra-node scalability due to reduced memory-bus and cache pressure.},
  eventtitle = {{{SC14}}: {{International Conference}} for {{High Performance Computing}}, {{Networking}}, {{Storage}} and {{Analysis}}},
  isbn = {978-1-4799-5500-8 978-1-4799-5499-5},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/B6FVBJY9/May et al. - 2014 - pTatin3D High-Performance Methods for Long-Term L.pdf}
}

@article{mcraeAutomatedGenerationSymbolic2016,
  title = {Automated {{Generation}} and {{Symbolic Manipulation}} of {{Tensor Product Finite Elements}}},
  author = {McRae, A. T. T. and Bercea, G.-T. and Mitchell, L. and Ham, D. A. and Cotter, C. J.},
  date = {2016-01},
  journaltitle = {SIAM Journal on Scientific Computing},
  shortjournal = {SIAM J. Sci. Comput.},
  volume = {38},
  number = {5},
  pages = {S25-S47},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/15M1021167},
  url = {http://epubs.siam.org/doi/10.1137/15M1021167},
  urldate = {2020-10-05},
  abstract = {We describe and implement a symbolic algebra for scalar and vector-valued finite elements, enabling the computer generation of elements with tensor product structure on quadrilateral, hexahedral, and triangular prismatic cells. The algebra is implemented as an extension to the domain-specific language UFL, the Unified Form Language. This allows users to construct many finite element spaces beyond those supported by existing software packages. We have made corresponding extensions to FIAT, the FInite element Automatic Tabulator, to enable numerical tabulation of such spaces. This tabulation is consequently used during the automatic generation of low-level code that carries out local assembly operations, within the wider context of solving finite element problems posed over such function spaces. We have done this work within the code-generation pipeline of the software package Firedrake; we make use of the full Firedrake package to present numerical examples.},
  langid = {english},
  keywords = {fiat,firedrake,sum-factorisation,tensor-product,ufl},
  file = {/home/connor/Obsidian/30 Literature notes/mcraeAutomatedGenerationSymbolic2016 - Extracted Annotations (24052021, 160428)A limitation of Firedrake and FEniCS has been the lack of support for anyth.md;/home/connor/Obsidian/30 Literature notes/mcraeAutomatedGenerationSymbolic2016 - Summary.md;/home/connor/Obsidian/30 Literature notes/mcraeAutomatedGenerationSymbolic2016-zotero.md;/home/connor/Obsidian/30 Literature notes/mcraeAutomatedGenerationSymbolic2016.md;/home/connor/Obsidian/30 Literature notes/Zotero/mcraeAutomatedGenerationSymbolic2016 - Extracted Annotations (24052021, 160428)A limitation of Firedrake and FEniCS has been the lack of support for anyth.md;/home/connor/Obsidian/30 Literature notes/Zotero/mcraeAutomatedGenerationSymbolic2016 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/mcraeAutomatedGenerationSymbolic2016-zotero.md;/home/connor/OneDrive/AppData/Zotero/McRae et al_2016_Automated Generation and Symbolic Manipulation of Tensor Product Finite Elements.pdf}
}

@article{mcraeCompatibleFiniteElement,
  title = {Compatible Finite Element Methods for Atmospheric Dynamical Cores},
  author = {McRae, Andrew Timothy Tang},
  pages = {132},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/LX37RFBH/McRae and London - Compatible finite element methods for atmospheric .pdf}
}

@inproceedings{menierMultigridStrategiesCoupled2015,
  title = {Multigrid {{Strategies Coupled}} with {{Anisotropic Mesh Adaptation}}},
  booktitle = {53rd {{AIAA Aerospace Sciences Meeting}}},
  author = {Menier, Victorien and Loseille, Adrien and Alauzet, Frederic},
  date = {2015-01-05},
  publisher = {{American Institute of Aeronautics and Astronautics}},
  location = {Kissimmee, Florida},
  doi = {10.2514/6.2015-2041},
  url = {https://arc.aiaa.org/doi/10.2514/6.2015-2041},
  urldate = {2022-09-15},
  eventtitle = {53rd {{AIAA Aerospace Sciences Meeting}}},
  isbn = {978-1-62410-343-8},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/SMHYSMRQ/Menier et al_2015_Multigrid Strategies Coupled with Anisotropic Mesh Adaptation.pdf}
}

@article{milewskiCategoryTheoryProgrammers,
  title = {Category {{Theory}} for {{Programmers}}},
  author = {Milewski, Bartosz},
  pages = {498},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/ASIL4JWK/Milewski - Category Theory for Programmers.pdf}
}

@unpublished{millsPerformancePortablePETScGPUbased2020,
  title = {Toward {{Performance-Portable PETSc}} for {{GPU-based Exascale Systems}}},
  author = {Mills, Richard Tran and Adams, Mark F. and Balay, Satish and Brown, Jed and Dener, Alp and Knepley, Matthew and Kruger, Scott E. and Morgan, Hannah and Munson, Todd and Rupp, Karl and Smith, Barry F. and Zampini, Stefano and Zhang, Hong and Zhang, Junchao},
  date = {2020-11-01},
  eprint = {2011.00715},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2011.00715},
  urldate = {2021-03-22},
  abstract = {The Portable Extensible Toolkit for Scientific computation (PETSc) library delivers scalable solvers for nonlinear time-dependent differential and algebraic equations and for numerical optimization. The PETSc design for performance portability addresses fundamental GPU accelerator challenges and stresses flexibility and extensibility by separating the programming model used by the application from that used by the library, and it enables application developers to use their preferred programming model, such as Kokkos, RAJA, SYCL, HIP, CUDA, or OpenCL, on upcoming exascale systems. A blueprint for using GPUs from PETSc-based codes is provided, and case studies emphasize the flexibility and high performance achieved on current GPU-based systems.},
  langid = {english},
  keywords = {cuda,exascale,gpu,kokkos,performance-portability,petsc,petsc-star-forest},
  file = {/home/connor/OneDrive/AppData/Zotero/Mills et al_2020_Toward Performance-Portable PETSc for GPU-based Exascale Systems.pdf}
}

@online{millsPETScTAODevelopments2024,
  title = {{{PETSc}}/{{TAO Developments}} for {{Early Exascale Systems}}},
  author = {Mills, Richard Tran and Adams, Mark and Balay, Satish and Brown, Jed and Faibussowitsch, Jacob and Isaac, Toby and Knepley, Matthew and Munson, Todd and Suh, Hansol and Zampini, Stefano and Zhang, Hong and Zhang, Junchao},
  date = {2024-06-12},
  eprint = {2406.08646},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2406.08646},
  urldate = {2024-07-22},
  abstract = {The Portable Extensible Toolkit for Scientific Computation (PETSc) library provides scalable solvers for nonlinear timedependent differential and algebraic equations and for numerical optimization via the Toolkit for Advanced Optimization (TAO). PETSc is used in dozens of scientific fields and is an important building block for many simulation codes. During the U.S. Department of Energy’s Exascale Computing Project, the PETSc team has made substantial efforts to enable efficient utilization of the massive fine-grain parallelism present within exascale compute nodes and to enable performance portability across exascale architectures. We recap some of the challenges that designers of numerical libraries face in such an endeavor, and then discuss the many developments we have made, which include the addition of new GPU backends, features supporting efficient on-device matrix assembly, better support for asynchronicity and GPU kernel concurrency, and new communication infrastructure. We evaluate the performance of these developments on some pre-exascale systems as well the early exascale systems Frontier and Aurora, using compute kernel, communication layer, solver, and mini-application benchmark studies, and then close with a few observations drawn from our experiences on the tension between portable performance and other goals of numerical libraries.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},00A69,Computer Science - Mathematical Software},
  file = {/home/connor/.local/share/zotero/storage/8ZAXGSYE/Mills et al. - 2024 - PETScTAO Developments for Early Exascale Systems.pdf}
}

@inproceedings{mirchandaneyPrinciplesRuntimeSupport1988,
  title = {Principles of Runtime Support for Parallel Processors},
  booktitle = {Proceedings of the 2nd International Conference on {{Supercomputing}}  - {{ICS}} '88},
  author = {Mirchandaney, R. and Saltz, J. H. and Smith, R. M. and Nico, D. M. and Crowley, K.},
  date = {1988},
  pages = {140--152},
  publisher = {ACM Press},
  location = {St. Malo, France},
  doi = {10.1145/55364.55378},
  url = {http://portal.acm.org/citation.cfm?doid=55364.55378},
  urldate = {2023-11-27},
  abstract = {There exists substantial data level parallelism in scientific problems. The PARTY runtime system is an attempt to obtain efficient parallel implementations for scientific computations, particularly those where the data dependencies are manifest only at runtime. This can preclude compiler based detection of certain types of parallelism. The automated system is structured as follows: An appropeate level of granularity is first selected for the computations. A directed acyclic graph representation of the program is generated on which various aggregation techniques may be employed in order to generate efficient schedules. These schedules are then mapped onto thk target machine. We describe some initial results from experiments conducted on the Intel Hypercube and the Encore Multimax that indicate the usefulness of our approach.},
  eventtitle = {The 2nd International Conference},
  isbn = {978-0-89791-272-3},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/3ZBHPZHN/Mirchandaney et al. - 1988 - Principles of runtime support for parallel process.pdf}
}

@article{mitchellHighLevelImplementation2016,
  title = {High Level Implementation of Geometric Multigrid Solvers for Finite Element Problems: {{Applications}} in Atmospheric Modelling},
  shorttitle = {High Level Implementation of Geometric Multigrid Solvers for Finite Element Problems},
  author = {Mitchell, Lawrence and Müller, Eike Hermann},
  date = {2016-12},
  journaltitle = {Journal of Computational Physics},
  shortjournal = {Journal of Computational Physics},
  volume = {327},
  pages = {1--18},
  issn = {00219991},
  doi = {10.1016/j.jcp.2016.09.037},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999116304582},
  urldate = {2022-08-12},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/R4WMX865/Mitchell_Müller_2016_High level implementation of geometric multigrid solvers for finite element.pdf}
}

@article{mudaligeDesignInitialPerformance2013,
  title = {Design and Initial Performance of a High-Level Unstructured Mesh Framework on Heterogeneous Parallel Systems},
  author = {Mudalige, G.R. and Giles, M.B. and Thiyagalingam, J. and Reguly, I.Z. and Bertolli, C. and Kelly, Paul H. J. and Trefethen, A.E.},
  date = {2013-11},
  journaltitle = {Parallel Computing},
  shortjournal = {Parallel Computing},
  volume = {39},
  number = {11},
  pages = {669--692},
  issn = {01678191},
  doi = {10.1016/j.parco.2013.09.004},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0167819113001166},
  urldate = {2020-10-12},
  abstract = {OP2 is a high-level domain specific library framework for the solution of unstructured mesh-based applications. It utilizes source-to-source translation and compilation so that a single application code written using the OP2 API can be transformed into multiple parallel implementations for execution on a range of back-end hardware platforms. In this paper we present the design and performance of OP2’s recent developments facilitating code generation and execution on distributed memory heterogeneous systems. OP2 targets the solution of numerical problems based on static unstructured meshes. We discuss the main design issues in parallelizing this class of applications. These include handling data dependencies in accessing indirectly referenced data and design considerations in generating code for execution on a cluster of multi-threaded CPUs and GPUs. Two representative CFD applications, written using the OP2 framework, are utilized to provide a contrasting benchmarking and performance analysis study on a number of heterogeneous systems including a large scale Cray XE6 system and a large GPU cluster. A range of performance metrics are benchmarked including runtime, scalability, achieved compute and bandwidth performance, runtime bottlenecks and systems energy consumption. We demonstrate that an application written once at a high-level using the OP2 API is easily portable across a wide range of contrasting platforms and is capable of achieving near-optimal performance without the intervention of the domain application programmer.},
  langid = {english},
  keywords = {gpu,op2,openmp,performance-portability,unstructured-mesh},
  file = {/home/connor/Obsidian/30 Literature notes/mudaligeDesignInitialPerformance2013.md;/home/connor/Obsidian/30 Literature notes/Zotero/mudaligeDesignInitialPerformance2013 - Extracted Annotations (12052021, 134059)Application developers would like to benefit from the performance gains pro.md;/home/connor/Obsidian/30 Literature notes/Zotero/mudaligeDesignInitialPerformance2013 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/mudaligeDesignInitialPerformance2013-zotero.md;/home/connor/OneDrive/AppData/Zotero/Mudalige et al_2013_Design and initial performance of a high-level unstructured mesh framework on.pdf}
}

@inproceedings{mudaligeOP2ActiveLibrary2012,
  title = {{{OP2}}: {{An}} Active Library Framework for Solving Unstructured Mesh-Based Applications on Multi-Core and Many-Core Architectures},
  shorttitle = {{{OP2}}},
  booktitle = {2012 {{Innovative Parallel Computing}} ({{InPar}})},
  author = {Mudalige, G.R. and Giles, M.B. and Reguly, I. and Bertolli, C. and Kelly, Paul H. J.},
  date = {2012-05},
  pages = {1--12},
  publisher = {IEEE},
  location = {San Jose, CA, USA},
  doi = {10.1109/InPar.2012.6339594},
  url = {http://ieeexplore.ieee.org/document/6339594/},
  urldate = {2021-01-28},
  abstract = {OP2 is an "active" library framework for the solution of unstructured mesh-based applications. It utilizes source­ to-source translation and compilation so that a single ap­ plication code written using the OP2 API can be trans­ formed into different parallel implementations for execution on different back-end hardware platforms. In this paper we present the design of the current OP2 library, and inves­ tigate its capabilities in achieving performance portability, near-optimal performance, and scaling on modern multi-core and many-core processor based systems. A key feature of this work is OP2 's recent extension facilitating the develop­ ment and execution of applications on a distributed memory cluster of GPUs.},
  eventtitle = {2012 {{Innovative Parallel Computing}} ({{InPar}})},
  isbn = {978-1-4673-2633-9 978-1-4673-2632-2 978-1-4673-2631-5},
  langid = {english},
  keywords = {op2,unstructured-mesh},
  file = {/home/connor/Obsidian/30 Literature notes/mudaligeOP2ActiveLibrary2012-zotero.md;/home/connor/Obsidian/30 Literature notes/mudaligeOP2ActiveLibrary2012.md;/home/connor/Obsidian/30 Literature notes/Zotero/mudaligeOP2ActiveLibrary2012-zotero.md;/home/connor/OneDrive/AppData/Zotero/Mudalige et al_2012_OP2.pdf}
}

@unpublished{munchEfficientDistributedMatrixfree2022,
  title = {Efficient Distributed Matrix-Free Multigrid Methods on Locally Refined Meshes for {{FEM}} Computations},
  author = {Munch, Peter and Heister, Timo and Saavedra, Laura Prieto and Kronbichler, Martin},
  date = {2022-04-10},
  eprint = {2203.12292},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2203.12292},
  urldate = {2022-04-19},
  abstract = {This work studies three multigrid variants for matrix-free finite-element computations on locally refined meshes: geometric local smoothing, geometric global coarsening, and polynomial global coarsening. We have integrated the algorithms into the same framework—the open-source finite-element library deal.II—, which allows us to make fair comparisons regarding their implementation complexity, computational efficiency, and parallel scalability as well as to compare the measurements with theoretically derived performance models. Serial simulations and parallel weak and strong scaling on up to 147,456 CPU cores on 3,072 compute nodes are presented. The results obtained indicate that global coarsening algorithms show a better parallel behavior for comparable smoothers due to the better load balance particularly on the expensive fine levels. In the serial case, the costs of applying hanging-node constraints might be significant, leading to advantages of local smoothing, even though the number of solver iterations needed is slightly higher.},
  langid = {english},
  keywords = {Computer Science - Mathematical Software,G.4,Mathematics - Numerical Analysis},
  file = {/home/connor/.local/share/zotero/storage/93BIB53G/Munch et al_2022_Efficient distributed matrix-free multigrid methods on locally refined meshes.pdf}
}

@book{naumannArtDifferentiatingComputer2011,
  title = {The {{Art}} of {{Differentiating Computer Programs}}: {{An Introduction}} to {{Algorithmic Differentiation}}},
  shorttitle = {The {{Art}} of {{Differentiating Computer Programs}}},
  author = {Naumann, Uwe},
  date = {2011-01},
  publisher = {{Society for Industrial and Applied Mathematics}},
  doi = {10.1137/1.9781611972078},
  url = {http://epubs.siam.org/doi/book/10.1137/1.9781611972078},
  urldate = {2023-04-03},
  isbn = {978-1-61197-206-1 978-1-61197-207-8},
  langid = {english},
  keywords = {\_tablet},
  file = {/home/connor/.local/share/zotero/storage/8B58Y6RM/Naumann_2011_The Art of Differentiating Computer Programs.pdf}
}

@online{nigamConformingFiniteElement2023,
  title = {Conforming {{Finite Element Function Spaces}} in {{Four Dimensions}}, {{Part}} 1: {{Foundational Principles}} and the {{Tesseract}}},
  shorttitle = {Conforming {{Finite Element Function Spaces}} in {{Four Dimensions}}, {{Part}} 1},
  author = {Nigam, Nilima and Williams, David M.},
  date = {2023-08-13},
  eprint = {2308.06243},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2308.06243},
  urldate = {2023-08-16},
  abstract = {The stability, robustness, accuracy, and efficiency of space-time finite element methods crucially depend on the choice of approximation spaces for test and trial functions. This is especially true for high-order, mixed finite element methods which often must satisfy an inf-sup condition in order to ensure stability. With this in mind, the primary objective of this paper and a companion paper is to provide a wide range of explicitly stated, conforming, finite element spaces in four-dimensions. In this paper, we construct explicit high-order conforming finite elements on 4-cubes (tesseracts); our construction uses tools from the recently developed ‘Finite Element Exterior Calculus’. With a focus on practical implementation, we provide details including Piola-type transformations, and explicit expressions for the volumetric, facet, face, edge, and vertex degrees of freedom. In addition, we establish important theoretical properties, such as the exactness of the finite element sequences, and the unisolvence of the degrees of freedom.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {{14F40, 52B11, 58A12, 65D05, 74S05},Mathematics - Numerical Analysis},
  file = {/home/connor/.local/share/zotero/storage/CZIDFXD9/Nigam_Williams_2023_Conforming Finite Element Function Spaces in Four Dimensions, Part 1.pdf}
}

@online{nixon-hillConsistentPointData2023,
  title = {Consistent {{Point Data Assimilation}} in {{Firedrake}} and {{Icepack}}},
  author = {Nixon-Hill, Reuben W. and Shapero, Daniel and Cotter, Colin J. and Ham, David A.},
  date = {2023-04-12},
  eprint = {2304.06058},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2304.06058},
  urldate = {2023-04-17},
  abstract = {We present methods and tools that significantly improve the ability to estimate quantities and fields which are difficult to directly measure, such as the fluidity of ice, using point data sources, such as satellite altimetry. These work with both sparse and dense point data with estimated quantities and fields becoming more accurate as the number of measurements are increased. Such quantities and fields are often used as inputs to mathematical models that are used to make predictions so improving their accuracy is of vital importance. We demonstrate how our methods and tools can increase the accuracy of results, ensure posterior consistency, and aid discourse between modellers and experimenters.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Mathematical Software,Mathematics - Numerical Analysis},
  file = {/home/connor/.local/share/zotero/storage/2R3SQDZF/Nixon-Hill et al. - 2023 - Consistent Point Data Assimilation in Firedrake an.pdf}
}

@article{OlgaardLoggEtAl2008a,
  title = {Automated Code Generation for Discontinuous Galerkin Methods},
  author = {Ølgaard, Kristian B. and Logg, Anders and Wells, Garth N.},
  date = {2008},
  journaltitle = {SIAM Journal on Scientific Computing},
  volume = {31},
  number = {2},
  eprint = {1104.0628},
  eprinttype = {arXiv},
  pages = {849--864},
  doi = {10.1137/070710032},
  file = {/home/connor/OneDrive/AppData/Zotero/Ølgaard et al_2008_Automated code generation for discontinuous galerkin methods.pdf}
}

@article{OlgaardWells2010b,
  title = {Optimisations for Quadrature Representations of Finite Element Tensors through Automated Code Generation},
  author = {Ølgaard, Kristian B. and Wells, Garth N.},
  date = {2010},
  journaltitle = {ACM Transactions on Mathematical Software},
  volume = {37},
  eprint = {1104.0199},
  eprinttype = {arXiv},
  doi = {10.1145/1644001.1644009},
  num_pages = {23}
}

@article{paper17,
  title = {Automating the Solution of {{PDEs}} on the Sphere and Other Manifolds in {{FEniCS}} 1.2},
  author = {Rognes, Marie E. and Ham, David A. and Cotter, Colin J. and McRae, Andrew T. T.},
  date = {2013},
  journaltitle = {Geoscientific Model Development},
  volume = {6},
  pages = {2099--2119},
  doi = {10.5194/gmd-6-2099-2013}
}

@online{ParseDonValidate,
  title = {Parse, Don’t Validate},
  url = {https://lexi-lambda.github.io/blog/2019/11/05/parse-don-t-validate/},
  urldate = {2022-04-06},
  file = {/home/connor/.local/share/zotero/storage/RRYDJ5UB/parse-don-t-validate.html}
}

@article{pateraSpectralElementMethod1984,
  title = {A Spectral Element Method for Fluid Dynamics: {{Laminar}} Flow in a Channel Expansion},
  shorttitle = {A Spectral Element Method for Fluid Dynamics},
  author = {Patera, Anthony T},
  date = {1984-06},
  journaltitle = {Journal of Computational Physics},
  shortjournal = {Journal of Computational Physics},
  volume = {54},
  number = {3},
  pages = {468--488},
  issn = {00219991},
  doi = {10.1016/0021-9991(84)90128-1},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0021999184901281},
  urldate = {2021-10-04},
  langid = {english},
  keywords = {spectral-element-method},
  file = {/home/connor/.local/share/zotero/storage/DRPU84HB/Patera - 1984 - A spectral element method for fluid dynamics Lami.pdf}
}

@inproceedings{petsc-efficient,
  title = {Efficient Management of Parallelism in Object Oriented Numerical Software Libraries},
  booktitle = {Modern Software Tools in Scientific Computing},
  author = {Balay, Satish and Gropp, William D. and McInnes, Lois Curfman and Smith, Barry F.},
  editor = {Arge, E. and Bruaset, A. M. and Langtangen, H. P.},
  date = {1997},
  pages = {163--202},
  publisher = {Birkhäuser Press},
  keywords = {petsc}
}

@report{petsc-user-ref,
  title = {{{PETSc}} Users Manual},
  author = {Balay, Satish and Abhyankar, Shrirang and Adams, Mark F. and Brown, Jed and Brune, Peter and Buschelman, Kris and Dalcin, Lisandro and Dener, Alp and Eijkhout, Victor and Gropp, William D. and Karpeyev, Dmitry and Kaushik, Dinesh and Knepley, Matthew G. and May, Dave A. and McInnes, Lois Curfman and Mills, Richard Tran and Munson, Todd and Rupp, Karl and Sanan, Patrick and Smith, Barry F. and Zampini, Stefano and Zhang, Hong and Zhang, Hong},
  date = {2021},
  number = {ANL-95/11 - Revision 3.15},
  institution = {Argonne National Laboratory},
  url = {https://www.mcs.anl.gov/petsc},
  keywords = {petsc}
}

@misc{petsc-web-page,
  title = {{{PETSc Web}} Page},
  author = {Balay, Satish and Abhyankar, Shrirang and Adams, Mark F. and Brown, Jed and Brune, Peter and Buschelman, Kris and Dalcin, Lisandro and Dener, Alp and Eijkhout, Victor and Gropp, William D. and Karpeyev, Dmitry and Kaushik, Dinesh and Knepley, Matthew G. and May, Dave A. and McInnes, Lois Curfman and Mills, Richard Tran and Munson, Todd and Rupp, Karl and Sanan, Patrick and Smith, Barry F. and Zampini, Stefano and Zhang, Hong and Zhang, Hong},
  date = {2021},
  url = {https://www.mcs.anl.gov/petsc},
  keywords = {petsc}
}

@inproceedings{pugh1991uniform,
  title = {Uniform Techniques for Loop Optimization},
  booktitle = {Proceedings of the 5th International Conference on {{Supercomputing}}},
  author = {Pugh, William},
  date = {1991},
  pages = {341--352},
  file = {/home/connor/.local/share/zotero/storage/PWHNXWFM/Pugh_1991_Uniform techniques for loop optimization.pdf}
}

@article{ragan-kelleyHalideLanguageCompiler,
  title = {Halide: {{A Language}} and {{Compiler}} for {{Optimizing Parallelism}}, {{Locality}}, and {{Recomputation}} in {{Image Processing Pipelines}}},
  author = {Ragan-Kelley, Jonathan and Barnes, Connelly and Adams, Andrew},
  pages = {12},
  abstract = {Image processing pipelines combine the challenges of stencil computations and stream programs. They are composed of large graphs of different stencil stages, as well as complex reductions, and stages with global or data-dependent access patterns. Because of their complex structure, the performance difference between a naive implementation of a pipeline and an optimized one is often an order of magnitude. Efficient implementations require optimization of both parallelism and locality, but due to the nature of stencils, there is a fundamental tension between parallelism, locality, and introducing redundant recomputation of shared values.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/8ZLKIVN7/Ragan-Kelley et al. - Halide A Language and Compiler for Optimizing Par.pdf}
}

@article{ramanujamTilingMultidimensionalIteration1992,
  title = {Tiling Multidimensional Iteration Spaces for Multicomputers},
  author = {Ramanujam, J. and Sadayappan, P.},
  date = {1992-10},
  journaltitle = {Journal of Parallel and Distributed Computing},
  shortjournal = {Journal of Parallel and Distributed Computing},
  volume = {16},
  number = {2},
  pages = {108--120},
  issn = {07437315},
  doi = {10.1016/0743-7315(92)90027-K},
  url = {https://linkinghub.elsevier.com/retrieve/pii/074373159290027K},
  urldate = {2022-11-24},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/PCBM8X9H/Ramanujam and Sadayappan - 1992 - Tiling multidimensional iteration spaces for multi.pdf}
}

@article{rathgeberFiredrakeAutomatingFinite2016,
  title = {Firedrake: {{Automating}} the {{Finite Element Method}} by {{Composing Abstractions}}},
  shorttitle = {Firedrake},
  author = {Rathgeber, Florian and Ham, David A. and Mitchell, Lawrence and Lange, Michael and Luporini, Fabio and Mcrae, Andrew T. T. and Bercea, Gheorghe-Teodor and Markall, Graham R. and Kelly, Paul H. J.},
  date = {2016-12},
  journaltitle = {ACM Transactions on Mathematical Software},
  shortjournal = {ACM Trans. Math. Softw.},
  volume = {43},
  number = {3},
  pages = {1--27},
  issn = {0098-3500, 1557-7295},
  doi = {10.1145/2998441},
  url = {https://dl.acm.org/doi/10.1145/2998441},
  urldate = {2020-10-05},
  langid = {english},
  keywords = {firedrake,pyop2},
  file = {/home/connor/Obsidian/30 Literature notes/rathgeberFiredrakeAutomatingFinite2016 - Summary.md;/home/connor/Obsidian/30 Literature notes/rathgeberFiredrakeAutomatingFinite2016-zotero.md;/home/connor/Obsidian/30 Literature notes/rathgeberFiredrakeAutomatingFinite2016.md;/home/connor/Obsidian/30 Literature notes/Zotero/rathgeberFiredrakeAutomatingFinite2016 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/rathgeberFiredrakeAutomatingFinite2016-zotero.md;/home/connor/OneDrive/AppData/Zotero/Rathgeber et al_2016_Firedrake.pdf}
}

@article{rathgeberProductiveEfficientComputational2014,
  title = {Productive and {{Efficient Computational Science Through Domain-specific Abstractions}}},
  author = {Rathgeber, Florian},
  date = {2014},
  pages = {178},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/3JWCURBK/Rathgeber - Productive and Efficient Computational Science Thr.pdf}
}

@inproceedings{rathgeberPyOP2HighLevelFramework2012,
  title = {{{PyOP2}}: {{A High-Level Framework}} for {{Performance-Portable Simulations}} on {{Unstructured Meshes}}},
  shorttitle = {{{PyOP2}}},
  booktitle = {2012 {{SC Companion}}: {{High Performance Computing}}, {{Networking Storage}} and {{Analysis}}},
  author = {Rathgeber, Florian and Markall, Graham R. and Mitchell, Lawrence and Loriant, Nicolas and Ham, David A. and Bertolli, Carlo and Kelly, Paul H. J.},
  date = {2012-11},
  pages = {1116--1123},
  publisher = {IEEE},
  location = {Salt Lake City, UT},
  doi = {10.1109/SC.Companion.2012.134},
  url = {http://ieeexplore.ieee.org/document/6495916/},
  abstract = {Emerging many-core platforms are very difficult to program in a performance portable manner whilst achieving high efficiency on a diverse range of architectures.},
  isbn = {978-0-7695-4956-9 978-1-4673-6218-4},
  langid = {english},
  keywords = {fenics,gpu,op2,pyop2},
  file = {/home/connor/Obsidian/30 Literature notes/rathgeberPyOP2HighLevelFramework2012-zotero.md;/home/connor/Obsidian/30 Literature notes/rathgeberPyOP2HighLevelFramework2012.md;/home/connor/Obsidian/30 Literature notes/Zotero/rathgeberPyOP2HighLevelFramework2012-zotero.md;/home/connor/OneDrive/AppData/Zotero/Rathgeber et al_2012_PyOP2.pdf}
}

@article{rognesEfficientAssemblyDiv2010,
  title = {Efficient {{Assembly}} of {{H}}(Div) and {{H}}(Curl) {{Conforming Finite Elements}}},
  author = {Rognes, Marie E. and Kirby, Robert C. and Logg, Anders},
  date = {2010-01},
  journaltitle = {SIAM Journal on Scientific Computing},
  shortjournal = {SIAM J. Sci. Comput.},
  volume = {31},
  number = {6},
  pages = {4130--4151},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/08073901X},
  url = {http://epubs.siam.org/doi/10.1137/08073901X},
  urldate = {2021-06-29},
  abstract = {In this paper, we discuss how to efficiently evaluate and assemble general finite element variational forms on H(div) and H(curl). The proposed strategy relies on a decomposition of the element tensor into a precomputable reference tensor and a mesh-dependent geometry tensor. Two key points must then be considered: the appropriate mapping of basis functions from a reference element, and the orientation of geometrical entities. To address these issues, we extend here a previously presented representation theorem for affinely mapped elements to Piola-mapped elements. We also discuss a simple numbering strategy that removes the need to contend with directions of facet normals and tangents. The result is an automated, efficient, and easy-to-use implementation that allows a user to specify finite element variational forms on H(div) and H(curl) in close to mathematical notation.},
  langid = {english},
  keywords = {orientation,simplices},
  file = {/home/connor/.local/share/zotero/storage/THYWJBFH/Rognes et al_2010_Efficient Assembly of H(div) and H(curl) Conforming Finite Elements.pdf}
}

@article{ronchiCubedSphereNew1996,
  title = {The “{{Cubed Sphere}}”: {{A New Method}} for the {{Solution}} of {{Partial Differential Equations}} in {{Spherical Geometry}}},
  shorttitle = {The “{{Cubed Sphere}}”},
  author = {Ronchi, C. and Iacono, R. and Paolucci, P.S.},
  date = {1996-03},
  journaltitle = {Journal of Computational Physics},
  shortjournal = {Journal of Computational Physics},
  volume = {124},
  number = {1},
  pages = {93--114},
  issn = {00219991},
  doi = {10.1006/jcph.1996.0047},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0021999196900479},
  urldate = {2022-08-19},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/R243W6LL/Ronchi et al. - 1996 - The “Cubed Sphere” A New Method for the Solution .pdf}
}

@article{roodNumericalAdvectionAlgorithms1987,
  title = {Numerical Advection Algorithms and Their Role in Atmospheric Transport and Chemistry Models},
  author = {Rood, Richard B.},
  date = {1987},
  journaltitle = {Reviews of Geophysics},
  shortjournal = {Rev. Geophys.},
  volume = {25},
  number = {1},
  pages = {71},
  issn = {8755-1209},
  doi = {10.1029/RG025i001p00071},
  url = {http://doi.wiley.com/10.1029/RG025i001p00071},
  urldate = {2022-09-20},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/KS58SFYJ/Rood - 1987 - Numerical advection algorithms and their role in a.pdf}
}

@online{rothwellImplementingRestrictedFunction2024,
  title = {Implementing a {{Restricted Function Space Class}} in {{Firedrake}}},
  author = {Rothwell, Emma},
  date = {2024-07-24},
  eprint = {2408.05217},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2408.05217},
  urldate = {2024-08-14},
  abstract = {The implementation process of a \$\textbackslash texttt\{RestrictedFunctionSpace\}\$ class in Firedrake, a Python library which numerically solves partial differential equations through the use of the finite element method, is documented. This includes an introduction to the current \$\textbackslash texttt\{FunctionSpace\}\$ class in Firedrake, and the key features that it has. With the current \$\textbackslash texttt\{FunctionSpace\}\$ class, the limitations of the capabilities of the solvers in Firedrake when imposing Dirichlet boundary conditions are explored, as well as what the \$\textbackslash texttt\{RestrictedFunctionSpace\}\$ class does differently to remove these issues. These will be considered in both a mathematical way, and in the code as an abstraction of the mathematical ideas presented. Finally, the benefits to the user of the \$\textbackslash texttt\{RestrictedFunctionSpace\}\$ class are considered, and demonstrated through tests and comparisons. This leads to the conclusion that in particular, the eigensolver in Firedrake is improved through the use of the \$\textbackslash texttt\{RestrictedFunctionSpace\}\$, through the removal of eigenvalues associated with the Dirichlet boundary conditions for a system.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Mathematical Software,Mathematics - Numerical Analysis},
  file = {/home/connor/.local/share/zotero/storage/2GVFC5VC/Rothwell - 2024 - Implementing a Restricted Function Space Class in .pdf}
}

@article{rovelliRelationalQuantumMechanics1996,
  title = {Relational {{Quantum Mechanics}}},
  author = {Rovelli, Carlo},
  date = {1996-08},
  journaltitle = {International Journal of Theoretical Physics},
  shortjournal = {Int J Theor Phys},
  volume = {35},
  number = {8},
  eprint = {quant-ph/9609002},
  eprinttype = {arXiv},
  pages = {1637--1678},
  issn = {0020-7748, 1572-9575},
  doi = {10.1007/BF02302261},
  url = {http://arxiv.org/abs/quant-ph/9609002},
  urldate = {2023-05-02},
  abstract = {I suggest that the common unease with taking quantum mechanics as a fundamental description of nature (the "measurement problem") could derive from the use of an incorrect notion, as the unease with the Lorentz transformations before Einstein derived from the notion of observer-independent time. I suggest that this incorrect notion is the notion of observer-independent state of a system (or observer-independent values of physical quantities). I reformulate the problem of the "interpretation of quantum mechanics" as the problem of deriving the formalism from a few simple physical postulates. I consider a reformulation of quantum mechanics in terms of information theory. All systems are assumed to be equivalent, there is no observer-observed distinction, and the theory describes only the information that systems have about each other; nevertheless, the theory is complete.},
  langid = {english},
  keywords = {General Relativity and Quantum Cosmology,High Energy Physics - Theory,Quantum Physics},
  file = {/home/connor/.local/share/zotero/storage/QA85T6HQ/Rovelli - 1996 - Relational Quantum Mechanics.pdf}
}

@article{royEchemFEMFiredrakebasedPython2024,
  title = {{{EchemFEM}}: {{A Firedrake-based Python}} Package Forelectrochemical Transport},
  shorttitle = {{{EchemFEM}}},
  author = {Roy, Thomas and Andrej, Julian and Antimes, Aymeric and Beck, Victor A. and Ehlinger, Victoria and Euzenat, Florian and Govindarajan, Nitish and Guo, Jack and Lin, Tiras Y. and Moore, Thomas},
  date = {2024-05-31},
  journaltitle = {Journal of Open Source Software},
  shortjournal = {JOSS},
  volume = {9},
  number = {97},
  pages = {6531},
  issn = {2475-9066},
  doi = {10.21105/joss.06531},
  url = {https://joss.theoj.org/papers/10.21105/joss.06531},
  urldate = {2024-06-12},
  abstract = {The transition from fossil fuels to renewable energy has brought about a rapid increase in the availability of clean electricity. However, electricity generated from sources such as wind and solar are limited to intermittent operation due to daily and seasonal variation. One solution is to utilize electrochemical devices in energy storage and electrochemical manufacturing applications, where they can harness surplus energy and decarbonize chemical industries traditionally reliant on petrochemical feedstocks. Managing the growing prevalence of renewable energy underscores the importance of developing and scaling up these technologies, which can in turn facilitate the achievement of carbon emission reduction commitments of companies and developed economies. Likewise, the electrification of transport creates an increasing need for energy-dense electrochemical energy storage devices such as batteries and supercapacitors. Naturally, simulation tools are required to assist in the design of efficient and industrial-scale electrochemical devices.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/HZNEUFPZ/Roy et al. - 2024 - EchemFEM A Firedrake-based Python package forelec.pdf}
}

@article{rudeFullyAdaptiveMultigrid1993,
  title = {Fully {{Adaptive Multigrid Methods}}},
  author = {Rüde, Ulrich},
  date = {1993-02},
  journaltitle = {SIAM Journal on Numerical Analysis},
  shortjournal = {SIAM J. Numer. Anal.},
  volume = {30},
  number = {1},
  pages = {230--248},
  issn = {0036-1429, 1095-7170},
  doi = {10.1137/0730011},
  url = {http://epubs.siam.org/doi/10.1137/0730011},
  urldate = {2023-04-03},
  abstract = {Adaptivity is a key concept for the e ective numerical solution of di erential equations. The multilevel solution of elliptic partial di erential equations can be combined with adaptive mesh re nement and an adaptive choice of the discretization order. Additionally, adaptivity may be built into the relaxation and the multilevel cycling strategy. The goal of these fully adaptive methods is to spend work only where it is most e ective in the solution process. This approach includes concepts like local relaxation and not only leads to particularly fast convergence but also to additional robustness and generality. The e cient implementation of fully adaptive multilevel methods in a  nite element framework will be discussed.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/AN2652CN/Rüde - 1993 - Fully Adaptive Multigrid Methods.pdf}
}

@article{russellOptimizedCodeGeneration2013,
  title = {Optimized Code Generation for Finite Element Local Assembly Using Symbolic Manipulation},
  author = {Russell, Francis P. and Kelly, Paul H. J.},
  date = {2013-07},
  journaltitle = {ACM Transactions on Mathematical Software},
  shortjournal = {ACM Trans. Math. Softw.},
  volume = {39},
  number = {4},
  pages = {1--29},
  issn = {0098-3500, 1557-7295},
  doi = {10.1145/2491491.2491496},
  url = {https://dl.acm.org/doi/10.1145/2491491.2491496},
  urldate = {2020-10-12},
  langid = {english},
  file = {/home/connor/Obsidian/30 Literature notes/russellOptimizedCodeGeneration2013-zotero.md;/home/connor/Obsidian/30 Literature notes/russellOptimizedCodeGeneration2013.md;/home/connor/Obsidian/30 Literature notes/Zotero/russellOptimizedCodeGeneration2013-zotero.md;/home/connor/OneDrive/AppData/Zotero/Russell_Kelly_2013_Optimized code generation for finite element local assembly using symbolic.pdf}
}

@book{saadIterativeMethodsSparse2003,
  title = {Iterative Methods for Sparse Linear Systems},
  author = {Saad, Y.},
  date = {2003},
  edition = {2nd ed},
  publisher = {SIAM},
  location = {Philadelphia},
  isbn = {978-0-89871-534-7},
  langid = {english},
  pagetotal = {528},
  keywords = {{Differential equations, Partial},Iterative methods (Mathematics),Numerical solutions,Sparse matrices},
  file = {/home/connor/.local/share/zotero/storage/GFXRT22K/Saad_2003_Iterative methods for sparse linear systems.pdf}
}

@article{saltzRunTimeParallelizationScheduling,
  title = {Run-{{Time Parallelization}} and {{Scheduling}} of {{Loops}}},
  author = {Saltz, Joel H. and {Ravi Mirchandaney} and {Doug Baxter}},
  abstract = {In this paper, we extend t h e class of problenis t h a t can be effcrtively m n piled by parallelizing compilers. This is accornplislictl with t h e doconsider coils t r u c t which would allow these compilers t o paralldizc\textasciitilde many prohlcnis i n \textbackslash vliit 11 siil)staiitial loop-lcvel parallelisin is available h i t cattnot bc tlctcctctl hy staiitl;irtl corn pile-t iriie analysis. \textbackslash Ire describe and espcriincii till I J analyze m c d i a nisni.; II srd to parallclize t h e work required for these types of loops. I n each of t hcse met Iiotls. a new loop structure is produced hy modifying t h e loop to be parallclizcd. \textbackslash\textbackslash 'P also prcscnt t h e rules by wliicli these loop transformations may be autoiiiatcd i n oi t1c.r.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/4QUEGVDE/Baxter - Joel H. Saltz Ravi Mirchandaney.pdf}
}

@article{saundersDevelopmentPerformancePortableFramework,
  title = {Development {{Of A Performance-Portable Framework For Atomistic Simulations}}},
  author = {Saunders, William Robert},
  pages = {197},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/33CNGE7K/Saunders_Development Of A Performance-Portable Framework For Atomistic Simulations.pdf}
}

@article{saundersDomainSpecificLanguage2018,
  title = {A Domain Specific Language for Performance Portable Molecular Dynamics Algorithms},
  author = {Saunders, William Robert and Grant, James and Müller, Eike Hermann},
  date = {2018-03},
  journaltitle = {Computer Physics Communications},
  shortjournal = {Computer Physics Communications},
  volume = {224},
  pages = {119--135},
  issn = {00104655},
  doi = {10.1016/j.cpc.2017.11.006},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S0010465517303892},
  urldate = {2021-10-29},
  abstract = {Developers of Molecular Dynamics (MD) codes face significant challenges when adapting existing simulation packages to new hardware. In a continuously diversifying hardware landscape it becomes increasingly difficult for scientists to be experts both in their own domain (physics/chemistry/biology) and specialists in the low level parallelisation and optimisation of their codes. To address this challenge, we describe a ‘‘Separation of Concerns’’ approach for the development of parallel and optimised MD codes: the science specialist writes code at a high abstraction level in a domain specific language (DSL), which is then translated into efficient computer code by a scientific programmer. In a related context, an abstraction for the solution of partial differential equations with grid based methods has recently been implemented in the (Py)OP2 library. Inspired by this approach, we develop a Python code generation system for molecular dynamics simulations on different parallel architectures, including massively parallel distributed memory systems and GPUs. We demonstrate the efficiency of the auto-generated code by studying its performance and scalability on different hardware and compare it to other state-of-theart simulation packages. With growing data volumes the extraction of physically meaningful information from the simulation becomes increasingly challenging and requires equally efficient implementations. A particular advantage of our approach is the easy expression of such analysis algorithms. We consider two popular methods for deducing the crystalline structure of a material from the local environment of each atom, show how they can be expressed in our abstraction and implement them in the code generation framework.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/SPY9LETR/Saunders et al_2018_A domain specific language for performance portable molecular dynamics.pdf}
}

@article{scalaVariationalTimeSteppersThat,
  title = {Variational {{Time-Steppers}} That Are {{Finite Element}} in {{Time}} for {{Firedrake}} and {{Irksome}}},
  author = {Scala, Giacomo La},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/XVJ2R8KV/Scala - Variational Time-Steppers that are Finite Element .pdf}
}

@article{schapiraCategoriesHomologicalAlgebra,
  title = {Categories and Homological Algebra},
  author = {Schapira, Pierre},
  pages = {120},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/EWIF423L/Schapira_Categories and homological algebra.pdf}
}

@article{schoberlMultigridMethodsParameter1999,
  title = {Multigrid Methods for a Parameter Dependent Problem in Primal Variables},
  author = {Schöberl, Joachim},
  date = {1999-11-01},
  journaltitle = {Numerische Mathematik},
  shortjournal = {Numerische Mathematik},
  volume = {84},
  number = {1},
  pages = {97--119},
  issn = {0029-599X, 0945-3245},
  doi = {10.1007/s002110050465},
  url = {http://link.springer.com/10.1007/s002110050465},
  urldate = {2022-01-19},
  abstract = {In this paper we consider multigrid methods for the parameter dependent problem of nearly incompressible materials. We construct and analyze multilevel-projection algorithms, which can be applied to the mixed as well as to the equivalent, non-conforming finite element scheme in primal variables. For proper norms, we prove that the smoothing property and the approximation property hold with constants that are independent of the small parameter. Thus we obtain robust and optimal convergence rates for the Wcycle and the variable V-cycle multigrid methods. The numerical results pretty well conform the robustness and optimality of the multigrid methods proposed.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/7VGPJGHZ/Schöberl - 1999 - Multigrid methods for a parameter dependent proble.pdf}
}

@thesis{schoberlRobustMultigridMethods1999,
  title = {Robust {{Multigrid Methods}} for {{Parameter Dependent Problems}}},
  author = {Schöberl, Joachim},
  date = {1999},
  file = {/home/connor/.local/share/zotero/storage/2GYYDXAJ/Schöberl_Robust Multigrid Methods for Parameter Dependent Problems.pdf}
}

@article{schornbaumExtremeScaleBlockStructuredAdaptive2018,
  title = {Extreme-{{Scale Block-Structured Adaptive Mesh Refinement}}},
  author = {Schornbaum, Florian and Rüde, Ulrich},
  date = {2018-01},
  journaltitle = {SIAM Journal on Scientific Computing},
  shortjournal = {SIAM J. Sci. Comput.},
  volume = {40},
  number = {3},
  eprint = {1704.06829},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {C358-C387},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/17M1128411},
  url = {http://arxiv.org/abs/1704.06829},
  urldate = {2023-04-03},
  abstract = {In this article, we present a novel approach for block-structured adaptive mesh refinement (AMR) that is suitable for extreme-scale parallelism. All data structures are designed such that the size of the meta data in each distributed processor memory remains bounded independent of the processor number. In all stages of the AMR process, we use only distributed algorithms. No central resources such as a master process or replicated data are employed, so that an unlimited scalability can be achieved. For the dynamic load balancing in particular, we propose to exploit the hierarchical nature of the block-structured domain partitioning by creating a lightweight, temporary copy of the core data structure. This copy acts as a local and fully distributed proxy data structure. It does not contain simulation data, but only provides topological information about the domain partitioning into blocks. Ultimately, this approach enables an inexpensive, local, diffusion-based dynamic load balancing scheme.},
  langid = {english},
  keywords = {{68W10, 68W15, 68U20, 65Y05, 65Y20, 76P05},{Computer Science - Distributed, Parallel, and Cluster Computing}},
  file = {/home/connor/.local/share/zotero/storage/JXGAP7G6/Schornbaum and Rüde - 2018 - Extreme-Scale Block-Structured Adaptive Mesh Refin.pdf}
}

@unpublished{schulzTaskInefficiencyPatterns2021,
  title = {Task Inefficiency Patterns for a Wave Equation Solver},
  author = {Schulz, Holger and Gadeschi, Gonzalo Brito and Rudyy, Oleksandr and Weinzierl, Tobias},
  date = {2021-07-12},
  eprint = {2105.12739},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2105.12739},
  urldate = {2021-07-13},
  abstract = {The orchestration of complex algorithms demands high levels of automation to use modern hardware efficiently. Task-based programming with OpenMP 5.0 is a prominent candidate to accomplish this goal. We study OpenMP 5.0 ’s tasking in the context of a wave equation solver (ExaHyPE) using three different architectures and runtimes. We describe several task-scheduling flaws present in currently available runtimes, demonstrate how they impact performance and show how to work around them. Finally, we propose extensions to the OpenMP standard.},
  langid = {english},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Mathematical Software},
  file = {/home/connor/.local/share/zotero/storage/I8JKIF5R/Schulz et al. - 2021 - Task inefficiency patterns for a wave equation sol.pdf}
}

@article{scottDimensionsExactlyDivergenceFree2024,
  title = {Dimensions of {{Exactly Divergence-Free Finite Element Spaces}} in {{3D}}},
  author = {Scott, L. Ridgway and Tscherpel, Tabea},
  date = {2024-04-30},
  journaltitle = {SIAM Journal on Scientific Computing},
  shortjournal = {SIAM J. Sci. Comput.},
  volume = {46},
  number = {2},
  pages = {A1102-A1131},
  issn = {1064-8275, 1095-7197},
  doi = {10.1137/22M1544579},
  url = {https://epubs.siam.org/doi/10.1137/22M1544579},
  urldate = {2024-05-03},
  abstract = {We examine the dimensions of various inf-sup stable mixed finite element spaces on tetrahedral meshes in three dimensions with exact divergence constraints. More precisely, we compare the standard Scott--Vogelius elements of higher polynomial degree and low-order methods on split meshes, the Alfeld and the Worsey--Farin split. The main tool is a counting strategy to express the degrees of freedom for given polynomial degree and given split in terms of only a few mesh quantities, for which bounds and asymptotic behavior under mesh refinement is investigated. Furthermore, this is used to obtain insights on potential precursor spaces in the Stokes complex for finite element methods on the Worsey--Farin split.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/PSZFRIXP/Scott and Tscherpel - 2024 - Dimensions of Exactly Divergence-Free Finite Eleme.pdf}
}

@article{scottNormEstimatesMaximal1985,
  title = {Norm Estimates for a Maximal Right Inverse of the Divergence Operator in Spaces of Piecewise Polynomials},
  author = {Scott, L. R. and Vogelius, M.},
  date = {1985},
  journaltitle = {ESAIM: Mathematical Modelling and Numerical Analysis},
  shortjournal = {ESAIM: M2AN},
  volume = {19},
  number = {1},
  pages = {111--143},
  issn = {0764-583X, 1290-3841},
  doi = {10.1051/m2an/1985190101111},
  url = {http://www.esaim-m2an.org/10.1051/m2an/1985190101111},
  urldate = {2024-06-17},
  abstract = {Jn this paper we study the divergence operator acting on continuons piecewise polynomials ofdegree p 4- 1, p \textasciicircum{} 3, on triangulations of a plane polygonal domain Q. We give a characterization of the range of the divergence operator and thefull details of a combinatorial vérification oj this. As the central resuit we show that for very gênerai families ofmeshes it is possible to jïnd a maximal right inversefor the divergence operator with a È\{L2\textbackslash îi ) norm which is bounded indepenâently of the mesh size. The norm of this right inverse grows at most algebraically with p, but it necessarily blows up as a certain measure oj singularity oj the meshes approaches 0.\vphantom\}},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/WUGIDK86/Scott and Vogelius - 1985 - Norm estimates for a maximal right inverse of the .pdf}
}

@article{scroggsBasixRuntimeFinite2022,
  title = {Basix: A Runtime Finite Element Basis Evaluation Library},
  shorttitle = {Basix},
  author = {Scroggs, Matthew W. and Baratta, Igor A. and Richardson, Chris N. and Wells, Garth N.},
  date = {2022-05-25},
  journaltitle = {Journal of Open Source Software},
  shortjournal = {JOSS},
  volume = {7},
  number = {73},
  pages = {3982},
  issn = {2475-9066},
  doi = {10.21105/joss.03982},
  url = {https://joss.theoj.org/papers/10.21105/joss.03982},
  urldate = {2022-10-17},
  abstract = {The finite element method (FEM) (Ciarlet, 1978) is a widely used numerical method for approximating the solution of partial differential equations (PDEs). Solving a problem using FEM involves discretising the problem and searching for a solution in a finite dimensional space: these finite spaces are created by defining a finite element on each cell of a mesh.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/BSPWSQEU/Scroggs et al. - 2022 - Basix a runtime finite element basis evaluationli.pdf}
}

@unpublished{scroggsConstructionArbitraryOrder2021,
  title = {Construction of Arbitrary Order Finite Element Degree-of-Freedom Maps on Polygonal and Polyhedral Cell Meshes},
  author = {Scroggs, Matthew W. and Dokken, Jørgen S. and Richardson, Chris N. and Wells, Garth N.},
  date = {2021-03-23},
  eprint = {2102.11901},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2102.11901},
  urldate = {2021-06-29},
  abstract = {We develop an approach to generating degree-of-freedom maps for arbitrary order finite element spaces for any cell shape. The approach is based on the composition of permutations and transformations by cell sub-entity. Current approaches to generating degree-of-freedom maps for arbitrary order problems typically rely on a consistent orientation of cell entities that permits the definition of a common local coordinate system on shared edges and faces. However, while orientation of a mesh is straightforward for simplex cells and is a local operation, it is not a strictly local operation for quadrilateral cells and in the case of hexahedral cells not all meshes are orientable. The permutation and transformation approach is developed for a range of element types, including Lagrange, and divergence- and curl-conforming elements, and for a range of cell shapes. The approach is local and can be applied to cells of any shape, including general polytopes and meshes with mixed cell types. A number of examples are presented and the developed approach has been implemented in an open-source finite element library.},
  langid = {english},
  keywords = {basix,orientation},
  file = {/home/connor/.local/share/zotero/storage/Q88KF2MX/Scroggs et al. - 2021 - Construction of arbitrary order finite element deg.pdf}
}

@online{settgastPerformantLoworderMatrixfree2023,
  title = {Performant Low-Order Matrix-Free Finite Element Kernels on {{GPU}} Architectures},
  author = {Settgast, Randolph R. and Dudouit, Yohann and Castelletto, Nicola and Tobin, William R. and Corbett, Benjamin C. and Klevtsov, Sergey},
  date = {2023-08-18},
  eprint = {2308.09839},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2308.09839},
  urldate = {2023-08-22},
  abstract = {Numerical methods such as the Finite Element Method (FEM) have been successfully adapted to utilize the computational power of GPU accelerators. However, much of the effort around applying FEM to GPU’s has been focused on high-order FEM due to higher arithmetic intensity and order of accuracy. For applications such as the simulation of subsurface processes, high levels of heterogeneity results in high-resolution grids characterized by highly discontinuous (cell-wise) material property fields. Moreover, due to the significant uncertainties in the characterization of the domain of interest, e.g. geologic reservoirs, the benefits of high order accuracy are reduced, and low-order methods are typically employed. In this study, we present a strategy for implementing highly performant low-order matrix-free FEM operator kernels in the context of the conjugate gradient (CG) method. Performance results of matrix-free Laplace and isotropic elasticity operator kernels are presented and are shown to compare favorably to matrix-based SpMV operators on V100, A100, and MI250X GPUs.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Mathematical Software,Mathematics - Numerical Analysis},
  file = {/home/connor/.local/share/zotero/storage/DWJVFQR8/Settgast et al_2023_Performant low-order matrix-free finite element kernels on GPU architectures.pdf}
}

@online{shannonPEP659Specializing,
  title = {{{PEP}} 659 – {{Specializing Adaptive Interpreter}}},
  author = {Shannon, Mark},
  url = {https://peps.python.org/pep-0659/},
  abstract = {In order to perform well, virtual machines for dynamic languages must specialize the code that they execute to the types and values in the program being run. This specialization is often associated with “JIT” compilers, but is beneficial even without machine code generation. A specializing, adaptive interpreter is one that speculatively specializes on the types or values it is currently operating on, and adapts to changes in those types and values. Specialization gives us improved performance, and adaptation allows the interpreter to rapidly change when the pattern of usage in a program alters, limiting the amount of additional work caused by mis-specialization. This PEP proposes using a specializing, adaptive interpreter that specializes code aggressively, but over a very small region, and is able to adjust to mis-specialization rapidly and at low cost. Adding a specializing, adaptive interpreter to CPython will bring significant performance improvements. It is hard to come up with meaningful numbers, as it depends very much on the benchmarks and on work that has not yet happened. Extensive experimentation suggests speedups of up to 50\%. Even if the speedup were only 25\%, this would still be a worthwhile enhancement.}
}

@report{shaperoIcepackNewGlacier2021,
  type = {preprint},
  title = {Icepack: A New Glacier Flow Modeling Package in {{Python}}, Version 1.0},
  shorttitle = {\&lt;I\&gt;Icepack\&lt;/I\&gt;},
  author = {Shapero, Daniel and Badgeley, Jessica and Hoffmann, Andrew and Joughin, Ian},
  date = {2021-01-12},
  institution = {Cryosphere},
  doi = {10.5194/gmd-2020-419},
  url = {https://gmd.copernicus.org/preprints/gmd-2020-419/},
  urldate = {2021-07-26},
  abstract = {We introduce a new software package called “icepack” for modeling the flow of glaciers and ice sheets. The icepack package is built on the finite element modeling library Firedrake, which uses the Unified Form Language (UFL), a domain-specific language embedded into Python for describing weak forms of partial differential equations. The diagnostic models in icepack are formulated through action principles that are specified in UFL. The components of each action functional can be substituted for different forms of the user’s choosing, which makes it easy to experiment with the model physics. The action functional itself can be used to define a solver convergence criterion that is independent of the mesh and requires little tuning on the part of the user. The icepack package includes the 2D shallow ice and shallow stream models. We have also defined a 3D hybrid model based on spectral semi-discretization of the Blatter–Pattyn equations. Finally, icepack includes a Gauss–Newton solver for inverse problems that runs substantially faster than the Broyden–Fletcher–Goldfarb–Shanno (BFGS) method often used in the glaciological literature. The overall design philosophy of icepack is to be as usable as possible for a wide a swath of the glaciological community, including both experts and novices in computational science.},
  langid = {english},
  keywords = {firedrake,icepack},
  file = {/home/connor/.local/share/zotero/storage/FXS6XYJL/Shapero et al_2021_icepack.pdf}
}

@unpublished{shihRobustMultigridTechniques2021,
  title = {Robust Multigrid Techniques for Augmented {{Lagrangian}} Preconditioning of Incompressible {{Stokes}} Equations with Extreme Viscosity Variations},
  author = {Shih, Yu-hsuan and Stadler, Georg and Wechsung, Florian},
  date = {2021-07-02},
  eprint = {2107.00820},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2107.00820},
  urldate = {2021-09-17},
  abstract = {We present augmented Lagrangian Schur complement preconditioners and robust multigrid methods for incompressible Stokes problems with extreme viscosity variations. Such Stokes systems arise, for instance, upon linearization of nonlinear viscous flow problems, and they can have severely inhomogeneous and anisotropic coefficients. Using an augmented Lagrangian formulation for the incompressibility constraint makes the Schur complement easier to approximate, but results in a nearly singular (1,1)-block in the Stokes system. We present eigenvalue estimates for the quality of the Schur complement approximation. To cope with the near-singularity of the (1,1)-block, we extend a multigrid scheme with a discretization-dependent smoother and transfer operators from triangular/tetrahedral to the quadrilateral/hexahedral finite element discretizations \$[\textbackslash mathbb\{Q\}\_k]\textasciicircum d\textbackslash times \textbackslash mathbb\{P\}\_\{k-1\}\textasciicircum\{\textbackslash text\{disc\}\}\$, \$k\textbackslash geq 2\$, \$d=2,3\$. Using numerical examples with scalar and with anisotropic fourth-order tensor viscosity arising from linearization of a viscoplastic constitutive relation, we confirm the robustness of the multigrid scheme and the overall efficiency of the solver. We present scalability results using up to 28,672 parallel tasks for problems with up to 1.6 billion unknowns and a viscosity contrast up to ten orders of magnitude.},
  keywords = {{65F08, 65F10, 65N55, 65Y05, 76D07},{Computer Science - Computational Engineering, Finance, and Science},Mathematics - Numerical Analysis},
  file = {/home/connor/OneDrive/AppData/Zotero/Shih et al_2021_Robust multigrid techniques for augmented Lagrangian preconditioning of.pdf;/home/connor/.local/share/zotero/storage/ZC76CQMG/2107.html}
}

@unpublished{singhNEROAcceleratingWeather2021,
  title = {{{NERO}}: {{Accelerating Weather Prediction}} Using {{Near-Memory Reconfigurable Fabric}}},
  shorttitle = {{{NERO}}},
  author = {Singh, Gagandeep and Diamantopoulos, Dionysios and Gómez-Luna, Juan and Hagleitner, Christoph and Stuijk, Sander and Corporaal, Henk and Mutlu, Onur},
  date = {2021-07-19},
  eprint = {2107.08716},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2107.08716},
  urldate = {2021-07-20},
  abstract = {Ongoing climate change calls for fast and accurate weather and climate modeling. However, when solving large-scale weather prediction simulations, state-of-the-art CPU and GPU implementations suffer from limited performance and high energy consumption. These implementations are dominated by complex irregular memory access patterns and low arithmetic intensity that pose fundamental challenges to acceleration. To overcome these challenges, we propose and evaluate the use of near-memory acceleration using a reconfigurable fabric with high-bandwidth memory (HBM). We focus on compound stencils that are fundamental kernels in weather prediction models. By using high-level synthesis techniques, we develop NERO, an FPGA+HBM-based accelerator connected through IBM OCAPI (Open Coherent Accelerator Processor Interface) to an IBM POWER9 host system. Our experimental results show that NERO outperforms a 16-core POWER9 system by 5.3× and 12.7× when running two different compound stencil kernels. NERO reduces the energy consumption by 12× and 35× for the same two kernels over the POWER9 system with an energy efficiency of 1.61 GFLOPS/Watt and 21.01 GFLOPS/Watt . We conclude that employing near-memory acceleration solutions for weather prediction modeling is promising as a means to achieve both high performance and high energy efficiency.},
  langid = {english},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Hardware Architecture},
  file = {/home/connor/.local/share/zotero/storage/WL9G2ADP/Singh et al. - 2021 - NERO Accelerating Weather Prediction using Near-M.pdf}
}

@article{smigajSolvingBoundaryIntegral2015,
  title = {Solving {{Boundary Integral Problems}} with {{BEM}}++},
  author = {Śmigaj, Wojciech and Betcke, Timo and Arridge, Simon and Phillips, Joel and Schweiger, Martin},
  date = {2015-02-04},
  journaltitle = {ACM Transactions on Mathematical Software},
  shortjournal = {ACM Trans. Math. Softw.},
  volume = {41},
  number = {2},
  pages = {1--40},
  issn = {0098-3500, 1557-7295},
  doi = {10.1145/2590830},
  url = {https://dl.acm.org/doi/10.1145/2590830},
  urldate = {2023-10-24},
  abstract = {Many important partial differential equation problems in homogeneous media, such as those of acoustic or electromagnetic wave propagation, can be represented in the form of integral equations on the boundary of the domain of interest. In order to solve such problems, the boundary element method (BEM) can be applied. The advantage compared to domain-discretisation-based methods such as finite element methods is that only a discretisation of the boundary is necessary, which significantly reduces the number of unknowns. Yet, BEM formulations are much more difficult to implement than finite element methods. In this article, we present BEM++, a novel open-source library for the solution of boundary integral equations for Laplace, Helmholtz and Maxwell problems in three space dimensions. BEM++ is a C++ library with Python bindings for all important features, making it possible to integrate the library into other C++ projects or to use it directly via Python scripts. The internal structure and design decisions for BEM++ are discussed. Several examples are presented to demonstrate the performance of the library for larger problems.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/3PS78C9V/Śmigaj et al. - 2015 - Solving Boundary Integral Problems with BEM++.pdf}
}

@article{smithPETScSoftwareStrategy,
  title = {{{PETSc}}’s {{Software Strategy}} for the {{Design Space}} of {{Composable Extreme-Scale Solvers}}\$},
  author = {Smith, Barry and McInnes, Lois Curfman and Constantinescu, Emil and Adams, Mark and Balay, Satish and Brown, Jed and Knepley, Matthew and Zhang, Hong},
  abstract = {Emerging extreme-scale architectures present new opportunities for broader scope of simulations as well as new challenges in algorithms and software to exploit unprecedented levels of parallelism. Composable, hierarchical solver algorithms and carefully designed portable software are crucial to the success of extremescale simulations, because solver phases often dominate overall simulation time. This paper presents the PETSc design philogophy and recent advances in the library that enable application scientists to investigate the design space of composable linear, nonlinear, and timestepping solvers. In particular, separation of the control logic of the algorithms from the computational kernels of the solvers is crucial to allow injecting new hardware-specific computational kernels without having to rewrite the entire solver software library. Progress in this direction has already begun in PETSc, with new support for pthreads, OpenMP, and GPUs as a first step toward hardware-independent, high-level control logic for computational kernels. This multipronged software strategy for composable extreme-scale solvers will help exploit unprecedented extreme-scale computational power in two important ways: by facilitating the injection of newly developed scalable algorithms and data structures into fundamental components, and by providing the underlying foundation for a paradigm shift that raises the level of abstraction from simulation of complex systems to the design and uncertainty quantification of these systems.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/RQSVICJ4/Smith et al. - PETSc’s Software Strategy for the Design Space of .pdf}
}

@online{SrcSysLogging,
  title = {Src/Sys/Logging/Xmllogevent.c · Main · {{PETSc}} / Petsc},
  url = {https://gitlab.com/petsc/petsc/-/blob/main/src/sys/logging/xmllogevent.c},
  urldate = {2021-06-29},
  abstract = {PETSc, pronounced PET-see (the S is silent), is a suite of data structures and routines for the scalable (parallel) solution of scientific applications modeled by partial differential equations.},
  langid = {english},
  organization = {GitLab},
  file = {/home/connor/.local/share/zotero/storage/HGIL6JHY/xmllogevent.html}
}

@article{stoneOpenCLParallelProgramming2010,
  title = {{{OpenCL}}: {{A Parallel Programming Standard}} for {{Heterogeneous Computing Systems}}},
  author = {Stone, John E and Gohara, David and Shi, Guochun},
  date = {2010},
  pages = {8},
  langid = {english},
  keywords = {opencl},
  file = {/home/connor/Obsidian/30 Literature notes/stoneOpenCLParallelProgramming2010 - Summary.md;/home/connor/Obsidian/30 Literature notes/stoneOpenCLParallelProgramming2010-zotero.md;/home/connor/Obsidian/30 Literature notes/stoneOpenCLParallelProgramming2010.md;/home/connor/Obsidian/30 Literature notes/Zotero/stoneOpenCLParallelProgramming2010 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/stoneOpenCLParallelProgramming2010-zotero.md;/home/connor/OneDrive/AppData/Zotero/Stone et al_2010_OpenCL.pdf}
}

@inproceedings{stroutGeneralizingRunTimeTiling2014,
  title = {Generalizing {{Run-Time Tiling}} with the {{Loop Chain Abstraction}}},
  booktitle = {2014 {{IEEE}} 28th {{International Parallel}} and {{Distributed Processing Symposium}}},
  author = {Strout, Michelle Mills and Luporini, Fabio and Krieger, Christopher D. and Bertolli, Carlo and Bercea, Gheorghe-Teodor and Olschanowsky, Catherine and Ramanujam, J. and Kelly, Paul H. J.},
  date = {2014-05},
  pages = {1136--1145},
  publisher = {IEEE},
  location = {Phoenix, AZ, USA},
  doi = {10.1109/IPDPS.2014.118},
  url = {https://ieeexplore.ieee.org/document/6877342},
  urldate = {2021-06-03},
  abstract = {Many scientific applications are organized in a data parallel way: as sequences of parallel and/or reduction loops. This exposes parallelism well, but does not convert data reuse between loops into data locality. This paper focuses on this issue in parallel loops whose loop-to-loop dependence structure is data-dependent due to indirect references such as A[B[i]]. Such references are a common occurrence in sparse matrix computations, molecular dynamics simulations, and unstructured-mesh computational fluid dynamics (CFD). Previously, sparse tiling approaches were developed for individual benchmarks to group iterations across such loops to improve data locality. These approaches were shown to benefit applications such as moldyn, Gauss-Seidel, and the sparse matrix powers kernel, however the run-time routines for performing sparse tiling were hand coded per application. In this paper, we present a generalized full sparse tiling algorithm that uses the newly developed loop chain abstraction as input, improves inter-loop data locality, and creates a task graph to expose shared-memory parallelism at runtime. We evaluate the overhead and performance impact of the generalized full sparse tiling algorithm on two codes: a sparse Jacobi iterative solver and the Airfoil CFD benchmark.},
  eventtitle = {2014 {{IEEE International Parallel}} \& {{Distributed Processing Symposium}} ({{IPDPS}})},
  isbn = {978-1-4799-3800-1 978-1-4799-3799-8},
  langid = {english},
  keywords = {loop-chain,sparse-tiling},
  file = {/home/connor/.local/share/zotero/storage/FZICGBZD/Strout et al_2014_Generalizing Run-Time Tiling with the Loop Chain Abstraction.pdf}
}

@article{stroutSparsePolyhedralFramework2018,
  title = {The {{Sparse Polyhedral Framework}}: {{Composing Compiler-Generated Inspector-Executor Code}}},
  shorttitle = {The {{Sparse Polyhedral Framework}}},
  author = {Strout, Michelle Mills and Hall, Mary and Olschanowsky, Catherine},
  date = {2018-11},
  journaltitle = {Proceedings of the IEEE},
  volume = {106},
  number = {11},
  pages = {1921--1934},
  issn = {1558-2256},
  doi = {10.1109/JPROC.2018.2857721},
  abstract = {Irregular applications such as big graph analysis, material simulations, molecular dynamics simulations, and finite element analysis have performance problems due to their use of sparse data structures. Inspector-executor strategies improve sparse computation performance through parallelization and data locality optimizations. An inspector reschedules and reorders data at runtime, and an executor is a transformed version of the original computation that uses the newly reorganized schedules and data structures. Inspector-executor transformations are commonly written in a domain-specific or even application-specific fashion. Significant progress has been made in incorporating such inspector-executor transformations into existing compiler transformation frameworks, thus enabling their use with compile-time transformations. However, composing inspector-executor transformations in a general way has only been done in the context of the Sparse Polyhedral Framework (SPF). Though SPF enables the general composition of such transformations, the resulting inspector and executor performance suffers due to missed specialization opportunities. This paper reviews the history and current state of the art for inspector-executor strategies and reviews how the SPF enables the composition of inspector-executor transformations. Further, it describes a research vision to combine this generality in SPF with specialization to achieve composable and high performance inspectors and executors, producing a powerful compiler framework for sparse matrix computations.},
  eventtitle = {Proceedings of the {{IEEE}}},
  keywords = {Dynamic compiler,High performance computing,Intermediate representations,irregular computations,Optimization,program optimization and parallelization,Runtime,sparse matrices,Sparse matrices},
  file = {/home/connor/OneDrive/AppData/Zotero/Strout et al_2018_The Sparse Polyhedral Framework.pdf;/home/connor/.local/share/zotero/storage/GF69FP84/8436444.html}
}

@article{sulyokImprovingLocalityUnstructured2018,
  title = {Improving {{Locality}} of {{Unstructured Mesh Algorithms}} on {{GPUs}}},
  author = {Sulyok, András Attila and Balogh, Gábor Dániel and Reguly, István Zoltán and Mudalige, R},
  date = {2018},
  abstract = {To most efficiently utilize modern parallel architectures, the memory access patterns of algorithms must make heavy use of the cache architecture: successively accessed data must be close in memory (spatial locality) and one piece of data must be reused as many times as possible (temporal locality).},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/JYIJ4MBD/Sulyok et al. - Improving Locality of Unstructured Mesh Algorithms.pdf}
}

@thesis{sunAbstractionsPerformanceOptimisations2021,
  title = {Abstractions and Performance Optimisations for Finite Element Methods},
  author = {Sun, Tianjiao},
  date = {2021},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/7W3IIEDU/Sun et al. - Abstractions and performance optimisations for ﬁni.pdf}
}

@article{sunStudyVectorizationMatrixfree2020,
  title = {A Study of Vectorization for Matrix-Free Finite Element Methods},
  author = {Sun, Tianjiao and Mitchell, Lawrence and Kulkarni, Kaushik and Klöckner, Andreas and Ham, David A. and Kelly, Paul H. J.},
  date = {2020-11},
  journaltitle = {The International Journal of High Performance Computing Applications},
  shortjournal = {The International Journal of High Performance Computing Applications},
  volume = {34},
  number = {6},
  pages = {629--644},
  issn = {1094-3420, 1741-2846},
  doi = {10.1177/1094342020945005},
  url = {http://journals.sagepub.com/doi/10.1177/1094342020945005},
  urldate = {2020-10-13},
  abstract = {Vectorization is increasingly important to achieve high performance on modern hardware with SIMD instructions. Assembly of matrices and vectors in the finite element method, which is characterized by iterating a local assembly kernel over unstructured meshes, poses difficulties to effective vectorization. Maintaining a user-friendly high-level interface with a suitable degree of abstraction while generating efficient, vectorized code for the finite element method is a challenge for numerical software systems and libraries. In this work, we study cross-element vectorization in the finite element framework Firedrake via code transformation and demonstrate the efficacy of such an approach by evaluating a wide range of matrix-free operators spanning different polynomial degrees and discretizations on two recent CPUs using three mainstream compilers. Our experiments show that our approaches for cross-element vectorization achieve 30\% of theoretical peak performance for many examples of practical significance, and exceed 50\% for cases with high arithmetic intensities, with consistent speed-up over (intra-element) vectorization restricted to the local assembly kernels.},
  langid = {english},
  keywords = {firedrake,gem,intrinsics,matrix-free,tsfc,ufl,vectorisation},
  file = {/home/connor/Obsidian/30 Literature notes/sunStudyVectorizationMatrixfree2020 - Extracted Annotations (24022021, 143917)The data objects can be directly defined on the mesh entities, or indirectl.md;/home/connor/Obsidian/30 Literature notes/sunStudyVectorizationMatrixfree2020 - Summary.md;/home/connor/Obsidian/30 Literature notes/sunStudyVectorizationMatrixfree2020-zotero.md;/home/connor/Obsidian/30 Literature notes/sunStudyVectorizationMatrixfree2020.md;/home/connor/Obsidian/30 Literature notes/Zotero/sunStudyVectorizationMatrixfree2020 - Extracted Annotations (24022021, 143917)The data objects can be directly defined on the mesh entities, or indirectl.md;/home/connor/Obsidian/30 Literature notes/Zotero/sunStudyVectorizationMatrixfree2020 - Summary.md;/home/connor/Obsidian/30 Literature notes/Zotero/sunStudyVectorizationMatrixfree2020-zotero.md;/home/connor/OneDrive/AppData/Zotero/Sun et al_2020_A study of vectorization for matrix-free finite element methods.pdf}
}

@unpublished{tanEfficientInteractionsPython2021,
  title = {Toward {{Efficient Interactions}} between {{Python}} and {{Native Libraries}}},
  author = {Tan, Jialiang and Chen, Yu and Liu, Zhenming and Ren, Bin and Song, Shuaiwen Leon and Shen, Xipeng and Liu, Xu},
  date = {2021-06-10},
  eprint = {2107.00064},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.1145/3468264.3468541},
  url = {http://arxiv.org/abs/2107.00064},
  urldate = {2021-07-02},
  abstract = {Python has become a popular programming language because of its excellent programmability. Many modern software packages utilize Python for high-level algorithm design and depend on native libraries written in C/C++/Fortran for efficient computation kernels. Interaction between Python code and native libraries introduces performance losses because of the abstraction lying on the boundary of Python and native libraries. On the one side, Python code, typically run with interpretation, is disjoint from its execution behavior. On the other side, native libraries do not include program semantics to understand algorithm defects.},
  langid = {english},
  keywords = {native-code,performance-analysis,python},
  file = {/home/connor/.local/share/zotero/storage/HJUGWYH6/Tan et al. - 2021 - Toward Efficient Interactions between Python and N.pdf}
}

@report{tautgesMOABMeshOrientedDatabase2004,
  type = {SAND2004-1592},
  title = {{{MOAB}}: {{A Mesh-Oriented Database}}},
  author = {Tautges, T. J. and Meyers, R. and Merkley, K. and Stimpson, C. and Ernst, C.},
  date = {2004-04},
  institution = {Sandia National Laboratories}
}

@online{timalsinaTetrahedralizationHexahedralComplex2022,
  title = {Tetrahedralization of a {{Hexahedral Complex}}},
  author = {Timalsina, Aman and Knepley, Matthew G.},
  date = {2022-08-15},
  eprint = {2208.07128},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2208.07128},
  urldate = {2022-08-25},
  abstract = {Two important classes of three-dimensional elements in computational meshes are hexahedra and tetrahedra. While several efficient methods exist that convert a hexahedral element to a tetrahedral elements, the existing algorithm for tetrahedralization of a hexahedral complex is the marching tetrahedron algorithm which limits pre-selection of face divisions. We generalize a procedure for tetrahedralizing triangular prisms to tetrahedralizing cubes, and combine it with certain heuristics to design an algorithm that can triangulate any hexahedra.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Computational Geometry,Mathematics - Numerical Analysis},
  file = {/home/connor/.local/share/zotero/storage/IS49WH2M/Timalsina and Knepley - 2022 - Tetrahedralization of a Hexahedral Complex.pdf}
}

@book{trefethenNumericalLinearAlgebra1997,
  title = {Numerical Linear Algebra},
  author = {Trefethen, Lloyd N. and Bau, David},
  date = {1997},
  publisher = {{Society for Industrial and Applied Mathematics}},
  location = {Philadelphia},
  isbn = {978-0-89871-361-9},
  pagetotal = {361},
  keywords = {{Algebras, Linear},Numerical calculations},
  file = {/home/connor/.local/share/zotero/storage/YFFU4YLY/Trefethen_Bau_1997_Numerical linear algebra.pdf}
}

@manual{trilinos-website,
  type = {manual},
  title = {The {{Trilinos Project Website}}},
  author = {Team, The Trilinos Project},
  keywords = {trilinos}
}

@article{uphoffAnotherTensorToolbox2020,
  title = {Yet {{Another Tensor Toolbox}} for {{Discontinuous Galerkin Methods}} and {{Other Applications}}},
  author = {Uphoff, Carsten and Bader, Michael},
  date = {2020-11-13},
  journaltitle = {ACM Transactions on Mathematical Software},
  shortjournal = {ACM Trans. Math. Softw.},
  volume = {46},
  number = {4},
  pages = {1--40},
  issn = {0098-3500, 1557-7295},
  doi = {10.1145/3406835},
  url = {https://dl.acm.org/doi/10.1145/3406835},
  urldate = {2022-03-14},
  abstract = {The numerical solution of partial differential equations is at the heart of many grand challenges in supercomputing. Solvers based on high-order discontinuous Galerkin (DG) discretisation have been shown to scale on large supercomputers with excellent performance and efficiency if the implementation exploits all levels of parallelism and is tailored to the specific architecture. However, every year new supercomputers emerge and the list of hardware-specific considerations grows simultaneously with the list of desired features in a DG code. Thus, we believe that a sustainable DG code needs an abstraction layer to implement the numerical scheme in a suitable language. We explore the possibility to abstract the numerical scheme as small tensor operations, describe them in a domain-specific language (DSL) resembling the Einstein notation, and to map them to small General Matrix-Matrix Multiplication routines. The compiler for our DSL implements classic optimisations that are used for large tensor contractions, and we present novel optimisation techniques such as               equivalent sparsity patterns               and optimal index permutations for temporary tensors. Our application examples, which include the earthquake simulation software SeisSol, show that the generated kernels achieve over 50\% peak performance of a recent 48-core Skylake system while the DSL considerably simplifies the implementation.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/KFP4SSDL/Uphoff and Bader - 2020 - Yet Another Tensor Toolbox for Discontinuous Galer.pdf}
}

@article{uphoffFlexibleModelExtension,
  title = {Flexible Model Extension and Optimisation for Earthquake Simulations at Extreme Scales},
  author = {Uphoff, Carsten},
  pages = {227},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/7PTEBG2Y/Uphoff - Flexible model extension and optimisation for eart.pdf}
}

@article{vankaBlockimplicitMultigridSolution1986,
  title = {Block-Implicit Multigrid Solution of {{Navier-Stokes}} Equations in Primitive Variables},
  author = {Vanka, S.P},
  date = {1986-07},
  journaltitle = {Journal of Computational Physics},
  shortjournal = {Journal of Computational Physics},
  volume = {65},
  number = {1},
  pages = {138--158},
  issn = {00219991},
  doi = {10.1016/0021-9991(86)90008-2},
  url = {https://linkinghub.elsevier.com/retrieve/pii/0021999186900082},
  urldate = {2022-11-09},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/6NT6T6RV/Vanka - 1986 - Block-implicit multigrid solution of Navier-Stokes.pdf}
}

@online{vasilacheComposableModularCode2022,
  title = {Composable and {{Modular Code Generation}} in {{MLIR}}: {{A Structured}} and {{Retargetable Approach}} to {{Tensor Compiler Construction}}},
  shorttitle = {Composable and {{Modular Code Generation}} in {{MLIR}}},
  author = {Vasilache, Nicolas and Zinenko, Oleksandr and Bik, Aart J. C. and Ravishankar, Mahesh and Raoux, Thomas and Belyaev, Alexander and Springer, Matthias and Gysi, Tobias and Caballero, Diego and Herhut, Stephan and Laurenzo, Stella and Cohen, Albert},
  date = {2022-02-07},
  eprint = {2202.03293},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2202.03293},
  urldate = {2022-08-19},
  abstract = {Despite significant investment in software infrastructure, machine learning systems, runtimes and compilers do not compose properly. We propose a new design aiming at providing unprecedented degrees of modularity, composability and genericity. This paper discusses a structured approach to the construction of domain-specific code generators for tensor compilers, with the stated goal of improving the productivity of both compiler engineers and end-users. The approach leverages the natural structure of tensor algebra. It has been the main driver for the design of progressive lowering paths in \textbackslash MLIR. The proposed abstractions and transformations span data structures and control flow with both functional (SSA form) and imperative (side-effecting) semantics. We discuss the implications of this infrastructure on compiler construction and present preliminary experimental results.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Programming Languages},
  file = {/home/connor/.local/share/zotero/storage/XR9XWN5I/Vasilache et al. - 2022 - Composable and Modular Code Generation in MLIR A .pdf}
}

@online{voroninMonolithicMultigridPreconditioners2024,
  title = {Monolithic {{Multigrid Preconditioners}} for {{High-Order Discretizations}} of {{Stokes Equations}}},
  author = {Voronin, Alexey and Harper, Graham and MacLachlan, Scott and Olson, Luke N. and Tuminaro, Raymond S.},
  date = {2024-07-09},
  eprint = {2407.07253},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/2407.07253},
  urldate = {2024-07-16},
  abstract = {This work introduces and assesses the efficiency of a monolithic phMG multigrid framework designed for high-order discretizations of stationary Stokes systems using Taylor-Hood and Scott-Vogelius elements. The proposed approach integrates coarsening in both approximation order (p) and mesh resolution (h), to address the computational and memory efficiency challenges that are often encountered in conventional high-order numerical simulations. Our numerical results reveal that phMG offers significant improvements over traditional spatial-coarsening-only multigrid (hMG) techniques for problems discretized with Taylor-Hood elements across a variety of problem sizes and discretization orders. In particular, the phMG method exhibits superior performance in reducing setup and solve times, particularly when dealing with higher discretization orders and unstructured problem domains. For Scott-Vogelius discretizations, while monolithic phMG delivers low iteration counts and competitive solve phase timings, it exhibits a discernibly slower setup phase when compared to a multilevel (non-monolithic) full-block-factorization (FBF) preconditioner where phMG is employed only for the velocity unknowns. This is primarily due to the setup costs of the larger mixed-field relaxation patches with monolithic phMG versus the patch setup costs with a single unknown type for FBF.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Mathematics - Numerical Analysis},
  file = {/home/connor/.local/share/zotero/storage/I3N5W3RB/Voronin et al. - 2024 - Monolithic Multigrid Preconditioners for High-Orde.pdf}
}

@book{wallworkAnisotropicGoalOrientedMesh2020,
  title = {Anisotropic {{Goal-Oriented Mesh Adaptation}} in {{Firedrake}}},
  author = {Wallwork, Joseph and Barral, Nicolas and Ham, D. and Piggott, Matthew},
  date = {2020-02-06},
  doi = {10.5281/zenodo.3653373},
  abstract = {We consider metric-based mesh adaptation methods for steady-state partial differential equations (PDEs), solved using the finite element method in Firedrake. In this work, a number of mesh-adaptive methods are implemented within this framework, each enabling accurate approximation of a scalar quantity of interest (QoI). Through the QoI we define adjoint equations, with which we may gain understanding of its sensitivities to aspects of the PDE solution. Dual weighted residual type error estimation techniques are utilised in order to enable a goal-oriented strategy. Isotropic and anisotropic approaches are considered, both of which are able to achieve the same relative error in approximating the QoI as with uniform refinement, but using fewer elements. For validation purposes, we compare QoI values resulting from these approaches against analytical values which may be extracted for a particular advection-diffusion based test case. Potential applications in desalination plant outfall modelling are discussed.},
  file = {/home/connor/OneDrive/AppData/Zotero/Wallwork et al_2020_Anisotropic Goal-Oriented Mesh Adaptation in Firedrake.pdf}
}

@article{wechsungShapeOptimisationRobust,
  title = {Shape {{Optimisation}} and {{Robust Solvers}} for {{Incompressible Flow}}},
  author = {Wechsung, Florian},
  pages = {185},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/7P8AK23H/Wechsung - Shape Optimisation and Robust Solvers for Incompre.pdf}
}

@software{wechsungTinyASMBlockJacobiImplementation,
  title = {{{TinyASM}}: {{A Block-Jacobi}} Implementation for {{PETSc}} and {{Firedrake}} Focussed on Efficiently Inverting and Then Applying Small Dense Matrices.},
  author = {Wechsung, Florian},
  url = {https://github.com/florianwechsung/TinyASM}
}

@article{williamsRooflineInsightfulVisual2009,
  title = {Roofline: An Insightful Visual Performance Model for Multicore Architectures},
  shorttitle = {Roofline},
  author = {Williams, Samuel and Waterman, Andrew and Patterson, David},
  date = {2009-04},
  journaltitle = {Communications of the ACM},
  shortjournal = {Commun. ACM},
  volume = {52},
  number = {4},
  pages = {65--76},
  issn = {0001-0782, 1557-7317},
  doi = {10.1145/1498765.1498785},
  url = {https://dl.acm.org/doi/10.1145/1498765.1498785},
  urldate = {2022-09-20},
  abstract = {The Roofline model offers insight on how to improve the performance of software and hardware.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/LFX7YZEH/Williams et al. - 2009 - Roofline an insightful visual performance model f.pdf}
}

@article{WOLFSONPOU201984,
  title = {Modeling the Asynchronous {{Jacobi}} Method without Communication Delays},
  author = {Wolfson-Pou, Jordi and Chow, Edmond},
  date = {2019},
  journaltitle = {Journal of Parallel and Distributed Computing},
  volume = {128},
  pages = {84--98},
  issn = {0743-7315},
  doi = {10.1016/j.jpdc.2019.02.002},
  url = {https://www.sciencedirect.com/science/article/pii/S0743731518304751},
  abstract = {Asynchronous iterative methods for solving linear systems are gaining renewed interest due to the high cost of synchronization points in massively parallel codes. Historically, theory on asynchronous iterative methods has focused on asymptotic behavior, while the transient behavior remains poorly understood. In this paper, we study a model of the asynchronous Jacobi method without communication delays, which we call simplified asynchronous Jacobi. Simplified asynchronous Jacobi can be used to model asynchronous Jacobi implemented in shared memory or distributed memory with fast communication networks. Our analysis uses the idea of a propagation matrix, which is similar in concept to an iteration matrix. We show that simplified asynchronous Jacobi can continue to reduce the residual when some processes are slower than other processes. We also show that simplified asynchronous Jacobi can converge when synchronous Jacobi does not. We verify our analysis of simplified asynchronous Jacobi using results from asynchronous Jacobi implemented in shared and distributed memory.},
  keywords = {Asynchronous,Gauss–Seidel,Iterative solvers,Jacobi,Remote memory access,Sparse linear systems},
  file = {/home/connor/.local/share/zotero/storage/X8XB4U8S/Wolfson-Pou and Chow - 2019 - Modeling the asynchronous Jacobi method without co.pdf}
}

@article{wozniakInterlanguageParallelScripting2015,
  title = {Toward {{Interlanguage Parallel Scripting}} for {{Distributed-Memory Scientific Computing}}},
  author = {Wozniak, Justin M. and Armstrong, Timothy G. and Maheshwari, Ketan C. and Katz, Daniel S. and Wilde, Michael and Foster, Ian T.},
  date = {2015-09},
  journaltitle = {2015 IEEE International Conference on Cluster Computing},
  eprint = {2107.02841},
  eprinttype = {arXiv},
  pages = {482--485},
  doi = {10.1109/CLUSTER.2015.74},
  url = {http://arxiv.org/abs/2107.02841},
  urldate = {2021-07-08},
  abstract = {Scripting languages such as Python and R have been widely adopted as tools for the productive development of scientific software because of the power and expressiveness of the languages and available libraries. However, deploying scripted applications on large-scale parallel computer systems such as the IBM Blue Gene/Q or Cray XE6 is a challenge because of issues including operating system limitations, interoperability challenges, parallel filesystem overheads due to the small file system accesses common in scripted approaches, and other issues. We present here a new approach to these problems in which the Swift scripting system is used to integrate highlevel scripts written in Python, R, and Tcl, with native code developed in C, C++, and Fortran, by linking Swift to the library interfaces to the script interpreters. In this approach, Swift handles data management, movement, and marshaling among distributed-memory processes without direct user manipulation of low-level communication libraries such as MPI. We present a technique to efficiently launch scripted applications on large-scale supercomputers using a hierarchical programming model.},
  langid = {english},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},distributed-memory,scripting,swift},
  file = {/home/connor/.local/share/zotero/storage/I4XNW2TT/Wozniak et al_2015_Toward Interlanguage Parallel Scripting for Distributed-Memory Scientific.pdf}
}

@article{xuCopyandpatchCompilationFast2021,
  title = {Copy-and-Patch Compilation: A Fast Compilation Algorithm for High-Level Languages and Bytecode},
  shorttitle = {Copy-and-Patch Compilation},
  author = {Xu, Haoran and Kjolstad, Fredrik},
  date = {2021-10-20},
  journaltitle = {Proceedings of the ACM on Programming Languages},
  shortjournal = {Proc. ACM Program. Lang.},
  volume = {5},
  pages = {1--30},
  issn = {2475-1421},
  doi = {10.1145/3485513},
  url = {https://dl.acm.org/doi/10.1145/3485513},
  urldate = {2024-06-18},
  abstract = {HAORAN XU, Stanford University, USA FREDRIK KJOLSTAD, Stanford University, USA Fast compilation is important when compilation occurs at runtime, such as query compilers in modern database systems and WebAssembly virtual machines in modern browsers. We present copy-and-patch, an extremely fast compilation technique that also produces good quality code. It is capable of lowering both high-level languages and low-level bytecode programs to binary code, by stitching together code from a large library of binary implementation variants. We call these binary implementations stencils because they have holes where missing values must be inserted during code generation. We show how to construct a stencil library and describe the copy-and-patch algorithm that generates optimized binary code. We demonstrate two use cases of copy-and-patch: a compiler for a high-level C-like language intended for metaprogramming and a compiler for WebAssembly. Our high-level language compiler has negligible compilation cost: it produces code from an AST in less time than it takes to construct the AST. We have implemented an SQL database query compiler on top of this metaprogramming system and show that on TPC-H database benchmarks, copy-and-patch generates code two orders of magnitude faster than LLVM -O0 and three orders of magnitude faster than higher optimization levels. The generated code runs an order of magnitude faster than interpretation and 14\% faster than LLVM -O0. Our WebAssembly compiler generates code 4.9×ś6.5× faster than Liftoff, the WebAssembly baseline compiler in Google Chrome. The generated code also outperforms Liftoff’s by 39\%ś63\% on the Coremark and PolyBenchC WebAssembly benchmarks. CCS Concepts: • Software and its engineering → Just-in-time compilers; Domain specific languages.},
  issue = {OOPSLA},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/BERX5WTE/Xu and Kjolstad - 2021 - Copy-and-patch compilation a fast compilation alg.pdf}
}

@unpublished{yadavDISTALDistributedTensor2022,
  title = {{{DISTAL}}: {{The Distributed Tensor Algebra Compiler}}},
  shorttitle = {{{DISTAL}}},
  author = {Yadav, Rohan and Aiken, Alex and Kjolstad, Fredrik},
  date = {2022-03-17},
  eprint = {2203.08069},
  eprinttype = {arXiv},
  eprintclass = {cs},
  doi = {10.1145/3519939.3523437},
  url = {http://arxiv.org/abs/2203.08069},
  urldate = {2022-03-18},
  abstract = {We introduce DISTAL, a compiler for dense tensor algebra that targets modern distributed and heterogeneous systems. DISTAL lets users independently describe how tensors and computation map onto target machines through separate format and scheduling languages. The combination of choices for data and computation distribution creates a large design space that includes many algorithms from both the past (e.g., Cannon's algorithm) and the present (e.g., COSMA). DISTAL compiles a tensor algebra domain specific language to a distributed task-based runtime system and supports nodes with multi-core CPUs and multiple GPUs. Code generated by DISTAL is competitive with optimized codes for matrix multiply on 256 nodes of the Lassen supercomputer and outperforms existing systems by between 1.8x to 3.7x (with a 45.7x outlier) on higher order tensor operations.},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Programming Languages},
  file = {/home/connor/OneDrive/AppData/Zotero/Yadav et al_2022_DISTAL.pdf;/home/connor/.local/share/zotero/storage/CTGBFYBB/2203.html}
}

@online{yadavSpDISTALCompilingDistributed2022,
  title = {{{SpDISTAL}}: {{Compiling Distributed Sparse Tensor Computations}}},
  shorttitle = {{{SpDISTAL}}},
  author = {Yadav, Rohan and Aiken, Alex and Kjolstad, Fredrik},
  date = {2022-07-28},
  eprint = {2207.13901},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2207.13901},
  urldate = {2022-08-10},
  abstract = {We introduce SpDISTAL, a compiler for sparse tensor algebra that targets distributed systems. SpDISTAL combines separate descriptions of tensor algebra expressions, sparse data structures, data distribution, and computation distribution. Thus, it enables distributed execution of sparse tensor algebra expressions with a wide variety of sparse data structures and data distributions. SpDISTAL is implemented as a C++ library that targets a distributed task-based runtime system and can generate code for nodes with both multi-core CPUs and multiple GPUs. SpDISTAL generates distributed code that achieves performance competitive with hand-written distributed functions for specific sparse tensor algebra expressions and that outperforms general interpretation-based systems by one to two orders of magnitude.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing},Computer Science - Programming Languages},
  file = {/home/connor/.local/share/zotero/storage/J9GHUE8M/Yadav et al. - 2022 - SpDISTAL Compiling Distributed Sparse Tensor Comp.pdf}
}

@article{yashchukMultiscaleFiniteElement,
  title = {A Multiscale Finite Element Framework for Additive Manufacturing Process Modeling},
  author = {Yashchuk, Ivan},
  pages = {56},
  abstract = {This thesis describes a finite element framework for solving partial differential equations with highly varying spatial coefficients. The goal is to model the heat transfer in a heterogeneous powder medium of the selective laser melting process. An operator based framework is developed and the implementation details are discussed. The main idea of the work is based on the two level domain decomposition and construction of special operators to transfer the system between the coarse and fine levels. The system of equations is solved on a coarse level and the solution is transferred to the fine level. The operators are computed using Localized Orthogonal Decomposition (LOD) method. The method is applied to several numerical experiments and an optimal convergence rates in the H1 and L2 norms are observed. The computational efficiency of LOD is studied and its limitations are discussed.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/I4AGY7W2/Yashchuk - A multiscale finite element framework for additive.pdf}
}

@article{yuMeshTaichiCompilerEfficient2022,
  title = {{{MeshTaichi}}: {{A Compiler}} for {{Efficient Mesh-Based Operations}}},
  shorttitle = {{{MeshTaichi}}},
  author = {Yu, Chang and Xu, Yi and Kuang, Ye and Hu, Yuanming and Liu, Tiantian},
  date = {2022-12},
  journaltitle = {ACM Transactions on Graphics},
  shortjournal = {ACM Trans. Graph.},
  volume = {41},
  number = {6},
  pages = {1--17},
  issn = {0730-0301, 1557-7368},
  doi = {10.1145/3550454.3555430},
  url = {https://dl.acm.org/doi/10.1145/3550454.3555430},
  urldate = {2024-08-15},
  abstract = {Meshes are an indispensable representation in many graphics applications because they provide conformal spatial discretizations. However, mesh-based operations are often slow due to unstructured memory access patterns. We propose MeshTaichi, a novel mesh compiler that provides an intuitive programming model for efficient mesh-based operations. Our programming model hides the complex indexing system from users and allows users to write mesh-based operations using reference-style neighborhood queries. Our compiler achieves its high performance by exploiting data locality. We partition input meshes and prepare the wanted relations by inspecting users' code during compile time. During run time, we further utilize on-chip memory (shared memory on GPU and L1 cache on CPU) to access the wanted attributes of mesh elements efficiently. Our compiler decouples low-level optimization options with computations, so that users can explore different localized data attributes and different memory orderings without changing their computation code. As a result, users can write concise code using our programming model to generate efficient mesh-based computations on both CPU and GPU backends. We test MeshTaichi on a variety of physically-based simulation and geometry processing applications with both triangle and tetrahedron meshes. MeshTaichi achieves a consistent speedup ranging from 1.4× to 6×, compared to state-of-the-art mesh data structures and compilers.},
  langid = {english},
  file = {/home/connor/.local/share/zotero/storage/IYKP3APY/Yu et al. - 2022 - MeshTaichi A Compiler for Efficient Mesh-Based Op.pdf}
}

@unpublished{zhangPetscSFScalableCommunication2021,
  title = {The {{PetscSF Scalable Communication Layer}}},
  author = {Zhang, Junchao and Brown, Jed and Balay, Satish and Faibussowitsch, Jacob and Knepley, Matthew and Marin, Oana and Mills, Richard Tran and Munson, Todd and Smith, Barry F. and Zampini, Stefano},
  date = {2021-05-21},
  eprint = {2102.13018},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2102.13018},
  urldate = {2021-11-11},
  abstract = {PetscSF, the communication component of the Portable, Extensible Toolkit for Scientific Computation (PETSc), is designed to provide PETSc's communication infrastructure suitable for exascale computers that utilize GPUs and other accelerators. PetscSF provides a simple application programming interface (API) for managing common communication patterns in scientific computations by using a star-forest graph representation. PetscSF supports several implementations based on MPI and NVSHMEM, whose selection is based on the characteristics of the application or the target architecture. An efficient and portable model for network and intra-node communication is essential for implementing large-scale applications. The Message Passing Interface, which has been the de facto standard for distributed memory systems, has developed into a large complex API that does not yet provide high performance on the emerging heterogeneous CPU-GPU-based exascale systems. In this paper, we discuss the design of PetscSF, how it can overcome some difficulties of working directly with MPI on GPUs, and we demonstrate its performance, scalability, and novel features.},
  keywords = {{65F10, 65F50, 68N99, 68W10},{Computer Science - Distributed, Parallel, and Cluster Computing},C.2,G.4},
  file = {/home/connor/OneDrive/AppData/Zotero/Zhang et al_2021_The PetscSF Scalable Communication Layer.pdf;/home/connor/.local/share/zotero/storage/AFYNCH9U/2102.html}
}

@online{zhaoPolyhedralSpecificationCode2022,
  title = {Polyhedral {{Specification}} and {{Code Generation}} of {{Sparse Tensor Contraction}} with {{Co-Iteration}}},
  author = {Zhao, Tuowen and Popoola, Tobi and Hall, Mary and Olschanowsky, Catherine and Strout, Michelle Mills},
  date = {2022-08-24},
  eprint = {2208.11858},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2208.11858},
  urldate = {2022-08-30},
  abstract = {This paper presents a code generator for sparse tensor contraction computations. It leverages a mathematical representation of loop nest computations in the sparse polyhedral framework (SPF), which extends the polyhedral model to support non-affine computations, such as arise in sparse tensors. SPF is extended to perform layout specification, optimization, and code generation of sparse tensor code: 1) we develop a polyhedral layout specification that decouples iteration spaces for layout and computation; and, 2) we develop efficient co-iteration of sparse tensors by combining polyhedra scanning over the layout of one sparse tensor with the synthesis of code to find corresponding elements in other tensors through an SMT solver. We compare the generated code with that produced by a state-of-the-art tensor compiler, TACO. We achieve on average 1.63× faster parallel performance than TACO on sparse-sparse co-iteration and describe how to improve that to 2.72× average speedup by switching the find algorithms. We also demonstrate that decoupling iteration spaces of layout and computation enables additional layout and computation combinations to be supported. CCS Concepts: • Software and its engineering → Source code generation; Domain specific languages.},
  langid = {english},
  pubstate = {prepublished},
  keywords = {Computer Science - Performance,Computer Science - Programming Languages},
  file = {/home/connor/.local/share/zotero/storage/2W4HESQL/Zhao et al. - 2022 - Polyhedral Specification and Code Generation of Sp.pdf}
}

@inproceedings{zhouFrustratedMPIThreads2023,
  title = {Frustrated with {{MPI}}+{{Threads}}? {{Try MPIxThreads}}!},
  shorttitle = {Frustrated with {{MPI}}+{{Threads}}?},
  booktitle = {Proceedings of the 30th {{European MPI Users}}' {{Group Meeting}}},
  author = {Zhou, Hui and Raffenetti, Ken and Zhang, Junchao and Guo, Yanfei and Thakur, Rajeev},
  date = {2023-09-11},
  eprint = {2401.16551},
  eprinttype = {arXiv},
  eprintclass = {cs},
  pages = {1--10},
  doi = {10.1145/3615318.3615320},
  url = {http://arxiv.org/abs/2401.16551},
  urldate = {2024-02-21},
  abstract = {MPI+Threads, embodied by the MPI/OpenMP hybrid programming model, is a parallel programming paradigm where threads are used for on-node shared-memory parallelization and MPI is used for multi-node distributed-memory parallelization. OpenMP provides an incremental approach to parallelize code, while MPI, with its isolated address space and explicit messaging API, affords straightforward paths to obtain good parallel performance. However, MPI+Threads is not an ideal solution. Since MPI is unaware of the thread context, it cannot be used for interthread communication. This results in duplicated efforts to create separate and sometimes nested solutions for similar parallel tasks. In addition, because the MPI library is required to obey message-ordering semantics, mixing threads and MPI via MPI\_THREAD\_MULTIPLE can easily result in miserable performance due to accidental serializations. We propose a new MPI extension, MPIX Thread Communicator (threadcomm), that allows threads to be assigned distinct MPI ranks within thread parallel regions. The threadcomm extension combines both MPI processes and OpenMP threads to form a unified parallel environment. We show that this MPI×Threads (MPI Multiply Threads) paradigm allows OpenMP and MPI to work together in a complementary way to achieve both cleaner codes and better performance.},
  langid = {english},
  keywords = {{Computer Science - Distributed, Parallel, and Cluster Computing}},
  file = {/home/connor/.local/share/zotero/storage/2G9UPMSY/Zhou et al. - 2023 - Frustrated with MPI+Threads Try MPIxThreads!.pdf}
}
